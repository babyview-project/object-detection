{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplar montages for top/bottom variable categories\n",
    "\n",
    "**Purpose:** Visualize exemplars for the most and least variable categories: montages of 10â€“12 cropped exemplars per category, ordered by distance-to-centroid so spread is visible.\n",
    "\n",
    "**Configs:**\n",
    "- **bv_clip** / **bv_dinov3:** Uses variability CSV + grouped BV embeddings; picks one crop per (subject_id, age_mo) from metadata and cropped images dir.\n",
    "- **things_clip** / **things_dinov3:** Uses variability CSV + per-category .npy embeddings; images from `things_images_dir/{category}/{stem}.jpg` (or by index).\n",
    "\n",
    "**Output:** One montage image (and optional distances .txt) per selected category, for top N and bottom N variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tqdm import tqdm\n",
    "\n",
    "SCRIPT_DIR = Path(\".\").resolve()\n",
    "\n",
    "config = \"bv_clip\"  # bv_clip | bv_dinov3 | things_clip | things_dinov3\n",
    "variability_csv = None   # default: {config}_within_category_variability.csv\n",
    "grouped_embeddings_dir = None\n",
    "metadata_csv = Path(\"/home/j7yang/babyview-projects/vss2026/object-detection/frame_data/merged_frame_detections_with_metadata.csv\")\n",
    "cropped_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_all_cropped_by_class\")\n",
    "things_images_dir = None  # required for things_* configs\n",
    "out_dir = None\n",
    "top = 20\n",
    "bottom = 20\n",
    "n_exemplars = 12\n",
    "cell_size = (128, 128)\n",
    "n_cols = 4\n",
    "\n",
    "EXCLUDED_SUBJECT = \"00270001\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "GROUPED_EMBEDDINGS_BASE = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings\")\n",
    "DEFAULT_GROUPED_EMBEDDINGS = {\n",
    "    \"bv_clip\": GROUPED_EMBEDDINGS_BASE / \"clip_embeddings_grouped_by_age-mo_normalized\",\n",
    "    \"bv_dinov3\": GROUPED_EMBEDDINGS_BASE / \"facebook_dinov3-vitb16-pretrain-lvd1689m_grouped_by_age-mo_normalized\",\n",
    "}\n",
    "THINGS_BASE = Path(\"/ccn2/dataset/babyview/outputs_20250312\")\n",
    "THINGS_EMBEDDINGS = {\n",
    "    \"things_clip\": THINGS_BASE / \"things_bv_overlapping_categories_corrected/embeddings/image_embeddings/clip_image_embeddings_npy_by_category\",\n",
    "    \"things_dinov3\": THINGS_BASE / \"image_embeddings/things_bv_overlapping_categories_corrected/facebook_dinov3-vitb16-pretrain-lvd1689m\",\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers: crop dir, THINGS image by index, loaders, montage"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_category_crop_dir(cropped_dir, cat_name):\n",
    "    cat_lower = cat_name.strip().lower()\n",
    "    direct = cropped_dir / cat_name\n",
    "    if direct.exists() and direct.is_dir():\n",
    "        return direct\n",
    "    for p in cropped_dir.iterdir():\n",
    "        if p.is_dir() and p.name.lower() == cat_lower:\n",
    "            return p\n",
    "    return cropped_dir / cat_name\n",
    "\n",
    "\n",
    "_things_image_list_cache = {}\n",
    "\n",
    "def get_things_image_by_index(things_images_dir, cat_name, index):\n",
    "    key = (Path(things_images_dir), cat_name)\n",
    "    if key not in _things_image_list_cache:\n",
    "        cat_dir = get_category_crop_dir(things_images_dir, cat_name)\n",
    "        paths = []\n",
    "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "            paths.extend(cat_dir.glob(ext))\n",
    "        paths = sorted(paths, key=lambda p: p.name)\n",
    "        _things_image_list_cache[key] = paths\n",
    "    paths = _things_image_list_cache[key]\n",
    "    if index < 0 or index >= len(paths):\n",
    "        return None\n",
    "    return paths[index]\n",
    "\n",
    "\n",
    "def load_grouped_embeddings_and_ids(grouped_dir, categories_set, excluded_subject=None, min_exemplars=2):\n",
    "    grouped_dir = Path(grouped_dir)\n",
    "    category_embeddings = {}\n",
    "    category_exemplar_ids = {}\n",
    "    for cat_folder in sorted(grouped_dir.iterdir()):\n",
    "        if not cat_folder.is_dir():\n",
    "            continue\n",
    "        cat_name = cat_folder.name\n",
    "        if categories_set is not None and cat_name not in categories_set:\n",
    "            continue\n",
    "        embs, ids = [], []\n",
    "        for f in cat_folder.glob(\"*.npy\"):\n",
    "            stem = f.stem\n",
    "            parts = stem.split(\"_\")\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            subject_id, age_mo = parts[0], None\n",
    "            try:\n",
    "                age_mo = int(parts[1])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if excluded_subject and subject_id == excluded_subject:\n",
    "                continue\n",
    "            try:\n",
    "                e = np.load(f)\n",
    "                e = np.asarray(e, dtype=np.float64).flatten()\n",
    "                embs.append(e)\n",
    "                ids.append((subject_id, age_mo))\n",
    "            except Exception:\n",
    "                continue\n",
    "        if len(embs) >= min_exemplars:\n",
    "            category_embeddings[cat_name] = np.array(embs)\n",
    "            category_exemplar_ids[cat_name] = ids\n",
    "    return category_embeddings, category_exemplar_ids\n",
    "\n",
    "\n",
    "def load_things_embeddings_and_ids(embeddings_dir, categories_set, min_exemplars=2):\n",
    "    from load_things_embeddings import load_things_dinov3_from_dir\n",
    "    return load_things_dinov3_from_dir(Path(embeddings_dir), allowed_categories=categories_set, min_exemplars=min_exemplars)\n",
    "\n",
    "\n",
    "def build_exemplar_to_crop_lookup(metadata_csv, usecols=None, chunksize=500_000):\n",
    "    if usecols is None:\n",
    "        usecols = [\"class_name\", \"subject_id\", \"age_mo\", \"original_embedding_name\"]\n",
    "    lookup = {}\n",
    "    for chunk in tqdm(\n",
    "        pd.read_csv(metadata_csv, usecols=usecols, chunksize=chunksize, dtype={\"subject_id\": str, \"class_name\": str},\n",
    "                    na_values=[], keep_default_na=False),\n",
    "        desc=\"Metadata chunks\", unit=\"chunk\",\n",
    "    ):\n",
    "        chunk = chunk.dropna(subset=[\"class_name\", \"subject_id\", \"age_mo\", \"original_embedding_name\"])\n",
    "        chunk[\"subject_id_norm\"] = chunk[\"subject_id\"].str.strip().str.lstrip(\"S\")\n",
    "        chunk[\"age_mo_int\"] = pd.to_numeric(chunk[\"age_mo\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "        chunk = chunk[chunk[\"age_mo_int\"] >= 0]\n",
    "        for _, row in chunk.iterrows():\n",
    "            key = (str(row[\"class_name\"]).strip().lower(), row[\"subject_id_norm\"], row[\"age_mo_int\"])\n",
    "            if key not in lookup:\n",
    "                stem = str(row[\"original_embedding_name\"]).strip()\n",
    "                if stem.endswith(\".npy\"):\n",
    "                    stem = stem[:-4]\n",
    "                lookup[key] = stem\n",
    "    return lookup\n",
    "\n",
    "\n",
    "def make_montage_with_labels(images, labels, n_cols, cell_size, label_height=24):\n",
    "    if not images:\n",
    "        return None\n",
    "    n = len(images)\n",
    "    n_rows = (n + n_cols - 1) // n_cols\n",
    "    total_h = n_rows * (cell_size[1] + label_height)\n",
    "    total_w = n_cols * cell_size[0]\n",
    "    out = Image.new(\"RGB\", (total_w, total_h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(out)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 12)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "    for idx, img in enumerate(images):\n",
    "        row, col = idx // n_cols, idx % n_cols\n",
    "        if img.size != (cell_size[0], cell_size[1]):\n",
    "            img = img.resize((cell_size[0], cell_size[1]), Image.Resampling.LANCZOS)\n",
    "        r0 = row * (cell_size[1] + label_height)\n",
    "        c0 = col * cell_size[0]\n",
    "        out.paste(img, (c0, r0))\n",
    "        if idx < len(labels):\n",
    "            draw.text((c0 + 2, r0 + cell_size[1] + 2), f\"d={labels[idx]}\", fill=(0, 0, 0), font=font)\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load variability CSV and select top/bottom categories"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "variability_csv = variability_csv or (SCRIPT_DIR / f\"{config}_within_category_variability.csv\")\n",
    "out_dir = out_dir or (SCRIPT_DIR / (\"exemplar_montages\" if config == \"bv_clip\" else f\"exemplar_montages_{config}\"))\n",
    "out_dir = Path(out_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "var_df = pd.read_csv(variability_csv)\n",
    "var_df = var_df.sort_values(\"mean_dist_to_centroid\", ascending=False).reset_index(drop=True)\n",
    "top_cats = var_df.head(top)[\"category\"].tolist()\n",
    "bottom_cats = var_df.tail(bottom)[\"category\"].tolist()\n",
    "selected_categories = [(c, \"top\", i + 1) for i, c in enumerate(top_cats)] + [\n",
    "    (c, \"bottom\", i + 1) for i, c in enumerate(bottom_cats)\n",
    "]\n",
    "categories_set = set(c[0] for c in selected_categories)\n",
    "print(f\"Selected {len(selected_categories)} categories (top {top} + bottom {bottom}).\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings and (for BV) crop lookup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "is_bv = config.startswith(\"bv_\")\n",
    "print(f\"Loading embeddings for {config}...\")\n",
    "if is_bv:\n",
    "    grouped_dir = grouped_embeddings_dir or DEFAULT_GROUPED_EMBEDDINGS[config]\n",
    "    category_embeddings, category_exemplar_ids = load_grouped_embeddings_and_ids(\n",
    "        grouped_dir, categories_set, excluded_subject=EXCLUDED_SUBJECT, min_exemplars=2\n",
    "    )\n",
    "    print(\"Building exemplar -> crop lookup from metadata...\")\n",
    "    lookup = build_exemplar_to_crop_lookup(metadata_csv)\n",
    "    things_images_dir = None\n",
    "else:\n",
    "    embeddings_dir = THINGS_EMBEDDINGS[config]\n",
    "    category_embeddings, category_exemplar_ids = load_things_embeddings_and_ids(\n",
    "        embeddings_dir, categories_set, min_exemplars=2\n",
    "    )\n",
    "    lookup = None\n",
    "    things_images_dir = things_images_dir\n",
    "    if things_images_dir is None or not Path(things_images_dir).exists():\n",
    "        print(\"Warning: things_images_dir not set or missing. THINGS montages need images at {dir}/{category}/{stem}.jpg\")\n",
    "        things_images_dir = None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and save montages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for cat_name, rank_type, rank_idx in tqdm(selected_categories, desc=\"Montages\"):\n",
    "    if cat_name not in category_embeddings:\n",
    "        continue\n",
    "    X = category_embeddings[cat_name]\n",
    "    ids = category_exemplar_ids[cat_name]\n",
    "    centroid = X.mean(axis=0)\n",
    "    dists = np.linalg.norm(X - centroid, axis=1)\n",
    "    order = np.argsort(dists)\n",
    "    n_show = min(n_exemplars, len(order))\n",
    "    indices = np.linspace(0, len(order) - 1, n_show, dtype=int) if len(order) > n_show else np.arange(len(order))\n",
    "    selected_idx = order[indices]\n",
    "\n",
    "    images, labels = [], []\n",
    "    cat_key_lower = cat_name.strip().lower()\n",
    "    for i in selected_idx:\n",
    "        exemplar_id, age_mo = ids[i]\n",
    "        d = float(dists[i])\n",
    "        if is_bv:\n",
    "            key = (cat_key_lower, exemplar_id, int(age_mo))\n",
    "            stem = lookup.get(key) or lookup.get((cat_name, exemplar_id, int(age_mo)))\n",
    "            if stem is None:\n",
    "                continue\n",
    "            cat_dir = get_category_crop_dir(cropped_dir, cat_name)\n",
    "            crop_path = cat_dir / f\"{stem}.jpg\"\n",
    "        else:\n",
    "            if things_images_dir is None:\n",
    "                continue\n",
    "            crop_path = get_things_image_by_index(things_images_dir, cat_name, i)\n",
    "        if crop_path is None or not crop_path.exists():\n",
    "            continue\n",
    "        try:\n",
    "            img = Image.open(crop_path).convert(\"RGB\")\n",
    "            images.append(img)\n",
    "            labels.append(f\"{d:.1f}\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not images:\n",
    "        continue\n",
    "    n_cols_use = min(n_cols, len(images))\n",
    "    montage = make_montage_with_labels(images, labels, n_cols_use, cell_size)\n",
    "    if montage is None:\n",
    "        continue\n",
    "    rank_label = f\"{rank_type}{rank_idx:02d}\"\n",
    "    out_name = f\"exemplar_montage_{rank_label}_{cat_name}.png\"\n",
    "    montage.save(out_dir / out_name)\n",
    "    with open(out_dir / f\"exemplar_montage_{rank_label}_{cat_name}_distances.txt\", \"w\") as f:\n",
    "        f.write(\"dist_to_centroid (left-to-right, top-to-bottom)\\n\")\n",
    "        f.write(\"\\n\".join(labels))\n",
    "\n",
    "print(f\"Saved montages to {out_dir}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
