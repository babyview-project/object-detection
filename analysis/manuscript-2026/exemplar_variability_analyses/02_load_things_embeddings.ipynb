{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load THINGS embeddings\n",
    "\n",
    "**Purpose:** Load THINGS embeddings for within-category variability analyses.\n",
    "\n",
    "Both DinoV3 and CLIP use a directory-of-.npy layout: `{dir}/{category}/*.npy` (one .npy per exemplar).\n",
    "\n",
    "**Paths (per-exemplar):**\n",
    "- **DinoV3:** `.../image_embeddings/.../facebook_dinov3-vitb16-pretrain-lvd1689m`\n",
    "- **CLIP:** `.../clip_image_embeddings_npy_by_category` (folder per category, .npy per exemplar)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Default paths (per-image exemplars, not averaged)\n",
    "THINGS_DINOV3_DIR = Path(\"/ccn2/dataset/babyview/outputs_20250312/image_embeddings/things_bv_overlapping_categories_corrected/facebook_dinov3-vitb16-pretrain-lvd1689m\")\n",
    "THINGS_CLIP_DOCS = Path(\"/ccn2/dataset/babyview/outputs_20250312/things_bv_overlapping_categories_corrected/embeddings/image_embeddings/clip_image_embeddings_doc_normalized_filtered-by-clip-26.docs\")\n",
    "THINGS_CLIP_NPY_DIR = Path(\"/ccn2/dataset/babyview/outputs_20250312/things_bv_overlapping_categories_corrected/embeddings/image_embeddings/clip_image_embeddings_npy_by_category\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic: count .npy files per category\n",
    "\n",
    "Use this to verify the per-exemplar layout before loading."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def count_npy_per_category(dir_path, max_categories=10):\n",
    "    \"\"\"\n",
    "    Count .npy files per category folder (recursive **/*.npy).\n",
    "    Returns list of (category_name, count).\n",
    "    \"\"\"\n",
    "    dir_path = Path(dir_path)\n",
    "    if not dir_path.exists():\n",
    "        return []\n",
    "    out = []\n",
    "    for cat_folder in sorted(dir_path.iterdir()):\n",
    "        if not cat_folder.is_dir():\n",
    "            continue\n",
    "        n = len(list(cat_folder.glob(\"**/*.npy\")))\n",
    "        out.append((cat_folder.name, n))\n",
    "        if len(out) >= max_categories:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "# Example: inspect first 10 categories for CLIP by category\n",
    "count_npy_per_category(THINGS_CLIP_NPY_DIR, max_categories=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load THINGS DinoV3 from directory\n",
    "\n",
    "Layout: `{dir_path}/{category}/*.npy` (one .npy per image).\n",
    "Returns `(category_embeddings, category_exemplar_ids)` in the same format as the BV loader."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_things_dinov3_from_dir(\n",
    "    dir_path,\n",
    "    allowed_categories=None,\n",
    "    min_exemplars=2,\n",
    "):\n",
    "    dir_path = Path(dir_path)\n",
    "    if not dir_path.exists():\n",
    "        raise FileNotFoundError(f\"THINGS DinoV3 dir not found: {dir_path}\")\n",
    "    category_embeddings = {}\n",
    "    category_exemplar_ids = {}\n",
    "    for cat_folder in sorted(dir_path.iterdir()):\n",
    "        if not cat_folder.is_dir():\n",
    "            continue\n",
    "        cat_name = cat_folder.name\n",
    "        if allowed_categories is not None and cat_name not in allowed_categories:\n",
    "            continue\n",
    "        embs = []\n",
    "        ids = []\n",
    "        for f in sorted(cat_folder.glob(\"**/*.npy\")):\n",
    "            try:\n",
    "                e = np.load(f)\n",
    "                e = np.asarray(e, dtype=np.float64).flatten()\n",
    "                embs.append(e)\n",
    "                ids.append((f.stem, None))\n",
    "            except Exception:\n",
    "                continue\n",
    "        if len(embs) >= min_exemplars:\n",
    "            category_embeddings[cat_name] = np.array(embs)\n",
    "            category_exemplar_ids[cat_name] = ids\n",
    "    return category_embeddings, category_exemplar_ids"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load THINGS CLIP\n",
    "\n",
    "**Option 1:** From a .docs file using vislearnlabpy `EmbeddingStore` (requires `conda activate vislearnlabpy`).\n",
    "\n",
    "**Option 2:** From directory â€” same layout as DinoV3; uses `load_things_dinov3_from_dir`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_things_clip_from_docs(\n",
    "    docs_path,\n",
    "    allowed_categories=None,\n",
    "    min_exemplars=2,\n",
    "):\n",
    "    \"\"\"Load THINGS CLIP from .docs file (vislearnlabpy EmbeddingStore).\"\"\"\n",
    "    from vislearnlabpy.embeddings.embedding_store import EmbeddingStore\n",
    "\n",
    "    docs_path = Path(docs_path)\n",
    "    if not docs_path.exists():\n",
    "        raise FileNotFoundError(f\"THINGS CLIP .docs not found: {docs_path}\")\n",
    "    store = EmbeddingStore.from_doc(str(docs_path))\n",
    "    embeddings = np.array(store.EmbeddingList.normed_embedding)\n",
    "    categories = np.array(store.EmbeddingList.text)\n",
    "    cat_to_rows = defaultdict(list)\n",
    "    for i, cat in enumerate(categories):\n",
    "        c = str(cat).strip().lower() if cat is not None else \"\"\n",
    "        if allowed_categories is not None and c not in allowed_categories:\n",
    "            continue\n",
    "        cat_to_rows[c].append(i)\n",
    "    category_embeddings = {}\n",
    "    category_exemplar_ids = {}\n",
    "    for cat, indices in cat_to_rows.items():\n",
    "        if len(indices) < min_exemplars:\n",
    "            continue\n",
    "        X = embeddings[indices].astype(np.float64)\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1, -1)\n",
    "        category_embeddings[cat] = X\n",
    "        category_exemplar_ids[cat] = [(f\"{cat}_{i}\", None) for i in range(len(indices))]\n",
    "    return category_embeddings, category_exemplar_ids\n",
    "\n",
    "\n",
    "def load_things_clip_from_dir(\n",
    "    dir_path,\n",
    "    allowed_categories=None,\n",
    "    min_exemplars=2,\n",
    "):\n",
    "    \"\"\"Load THINGS CLIP from directory: same layout as DinoV3.\"\"\"\n",
    "    return load_things_dinov3_from_dir(dir_path, allowed_categories, min_exemplars)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: load THINGS embeddings (optional)\n",
    "\n",
    "Uncomment and set `allowed_categories` if you want to test loading a subset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# allowed = None  # or e.g. {\"cat\", \"dog\", \"car\"}\n",
    "# things_embeddings, things_ids = load_things_dinov3_from_dir(\n",
    "#     THINGS_DINOV3_DIR, allowed_categories=allowed, min_exemplars=2\n",
    "# )\n",
    "# print(f\"Loaded {len(things_embeddings)} categories\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
