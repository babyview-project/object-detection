{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Within-category kNN diversity for BV exemplars\n",
    "\n",
    "**Purpose:** For each category we have N BV exemplars. For each exemplar we compute the **mean distance to its k nearest neighbors** (within that category, excluding self).\n",
    "\n",
    "**Interpretation:**\n",
    "- **Low mean kNN distance** → micro-structure: exemplars form local clusters (e.g. every 5–10 exemplars are similar in views, format), so each point has close neighbors.\n",
    "- **High mean kNN distance** → no consistent local structure; exemplars are more uniformly spread.\n",
    "\n",
    "So we get a category-level \"kNN diversity\" (mean over exemplars of their mean-kNN-distance). **Lower = more micro-structure; higher = more uniform spread.**\n",
    "\n",
    "**Outputs:**\n",
    "1. Per-category summary CSV: category, n_exemplars, k, mean_knn_dist, std_knn_dist, median_knn_dist.\n",
    "2. Optional per-exemplar CSV: category, subject_id, age_mo, mean_knn_dist, rank_within_cat.\n",
    "\n",
    "Compare with centroid-based spread (`mean_bv_to_bv_centroid`): a category can have large overall spread but low mean_knn_dist (micro-structure) or high spread and high mean_knn_dist (no local consistency). See `visualize_bv_knn_diversity.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "SCRIPT_DIR = Path(\".\").resolve()\n",
    "\n",
    "embedding = \"clip\"   # \"clip\" or \"dinov3\"\n",
    "k_list = [5]         # e.g. [5, 10] for multi-k summary\n",
    "save_exemplar_csv = False\n",
    "out_dir = SCRIPT_DIR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BV embeddings (reuse from centroid script)\n",
    "\n",
    "We try to import from `bv_to_things_centroid_distances`; if not available (e.g. running notebook alone), we define a minimal loader and config."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "try:\n",
    "    from bv_to_things_centroid_distances import (\n",
    "        load_allowed_categories,\n",
    "        load_bv_embeddings,\n",
    "        EXCLUDED_SUBJECT,\n",
    "        MIN_EXEMPLARS,\n",
    "    )\n",
    "except ImportError:\n",
    "    GROUPED_EMBEDDINGS_BASE = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings\")\n",
    "    GROUPED_EMBEDDINGS_DIRS = {\n",
    "        \"clip\": GROUPED_EMBEDDINGS_BASE / \"clip_embeddings_grouped_by_age-mo_normalized\",\n",
    "        \"dinov3\": GROUPED_EMBEDDINGS_BASE / \"facebook_dinov3-vitb16-pretrain-lvd1689m_grouped_by_age-mo_normalized\",\n",
    "    }\n",
    "    CATEGORIES_FILE = SCRIPT_DIR / \"../../../data/things_bv_overlap_categories_exclude_zero_precisions.txt\"\n",
    "    EXCLUDED_SUBJECT = \"00270001\"\n",
    "    MIN_EXEMPLARS = 2\n",
    "\n",
    "    def load_allowed_categories():\n",
    "        if not CATEGORIES_FILE.exists():\n",
    "            return None\n",
    "        with open(CATEGORIES_FILE) as f:\n",
    "            return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "    def load_bv_embeddings(embedding_type, allowed_categories, excluded_subject, min_exemplars=2):\n",
    "        grouped_dir = GROUPED_EMBEDDINGS_DIRS[embedding_type]\n",
    "        if not grouped_dir.exists():\n",
    "            raise FileNotFoundError(f\"BV grouped dir not found: {grouped_dir}\")\n",
    "        category_embeddings = {}\n",
    "        category_exemplar_ids = {}\n",
    "        for cat_folder in sorted(grouped_dir.iterdir()):\n",
    "            if not cat_folder.is_dir():\n",
    "                continue\n",
    "            cat_name = cat_folder.name\n",
    "            if allowed_categories is not None and cat_name not in allowed_categories:\n",
    "                continue\n",
    "            embs, ids = [], []\n",
    "            for f in cat_folder.glob(\"*.npy\"):\n",
    "                stem = f.stem\n",
    "                parts = stem.split(\"_\")\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "                subject_id, age_mo = parts[0], None\n",
    "                try:\n",
    "                    age_mo = int(parts[1])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                if excluded_subject and subject_id == excluded_subject:\n",
    "                    continue\n",
    "                try:\n",
    "                    e = np.load(f)\n",
    "                    e = np.asarray(e, dtype=np.float64).flatten()\n",
    "                    embs.append(e)\n",
    "                    ids.append((subject_id, age_mo))\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if len(embs) >= min_exemplars:\n",
    "                category_embeddings[cat_name] = np.array(embs)\n",
    "                category_exemplar_ids[cat_name] = ids\n",
    "        return category_embeddings, category_exemplar_ids"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN mean distance per exemplar\n",
    "\n",
    "For each row in X we compute mean L2 distance to its k nearest neighbors (excluding self), using k+1 neighbors and dropping the first (self)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_knn_mean_distances(X, k):\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    n = X.shape[0]\n",
    "    n_neighbors = min(k + 1, n)\n",
    "    if n_neighbors < 2:\n",
    "        return np.full(n, np.nan)\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, metric=\"euclidean\", algorithm=\"auto\")\n",
    "    nn.fit(X)\n",
    "    distances, _ = nn.kneighbors(X)\n",
    "    mean_knn = np.mean(distances[:, 1:], axis=1)\n",
    "    return mean_knn\n",
    "\n",
    "\n",
    "def run_knn_per_category(bv_embeddings, bv_ids, categories, k):\n",
    "    summary_rows = []\n",
    "    exemplar_rows = []\n",
    "    for cat in tqdm(categories, desc=\"kNN per category\"):\n",
    "        X = bv_embeddings[cat]\n",
    "        id_list = bv_ids[cat]\n",
    "        n = X.shape[0]\n",
    "        effective_k = min(k, n - 1)\n",
    "        if effective_k < 1:\n",
    "            summary_rows.append({\n",
    "                \"category\": cat, \"n_exemplars\": n, \"k\": k, \"effective_k\": 0,\n",
    "                \"mean_knn_dist\": np.nan, \"std_knn_dist\": np.nan, \"median_knn_dist\": np.nan,\n",
    "            })\n",
    "            continue\n",
    "        mean_knn = compute_knn_mean_distances(X, effective_k)\n",
    "        summary_rows.append({\n",
    "            \"category\": cat, \"n_exemplars\": n, \"k\": k, \"effective_k\": effective_k,\n",
    "            \"mean_knn_dist\": float(np.nanmean(mean_knn)),\n",
    "            \"std_knn_dist\": float(np.nanstd(mean_knn)),\n",
    "            \"median_knn_dist\": float(np.nanmedian(mean_knn)),\n",
    "        })\n",
    "        for i, (sid, age_mo) in enumerate(id_list):\n",
    "            exemplar_rows.append({\n",
    "                \"category\": cat, \"subject_id\": sid, \"age_mo\": age_mo,\n",
    "                \"mean_knn_dist\": float(mean_knn[i]),\n",
    "            })\n",
    "    return summary_rows, exemplar_rows"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run for each k and save"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "out_dir = Path(out_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "allowed = load_allowed_categories()\n",
    "print(f\"Using {len(allowed) if allowed else 'all'} categories\")\n",
    "\n",
    "print(\"Loading BV embeddings...\")\n",
    "bv_embeddings, bv_ids = load_bv_embeddings(\n",
    "    embedding, allowed_categories=allowed, excluded_subject=EXCLUDED_SUBJECT, min_exemplars=MIN_EXEMPLARS\n",
    ")\n",
    "categories = sorted(bv_embeddings.keys())\n",
    "print(f\"Categories: {len(categories)}\")\n",
    "\n",
    "all_summary = []\n",
    "for k in k_list:\n",
    "    prefix = f\"bv_within_category_knn_{embedding}_k{k}\"\n",
    "    summary_rows, exemplar_rows = run_knn_per_category(bv_embeddings, bv_ids, categories, k)\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df = summary_df.sort_values(\"mean_knn_dist\", ascending=True).reset_index(drop=True)\n",
    "    summary_path = out_dir / f\"{prefix}_summary.csv\"\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"Saved {prefix}: {summary_path}\")\n",
    "\n",
    "    if save_exemplar_csv:\n",
    "        exemplar_df = pd.DataFrame(exemplar_rows)\n",
    "        exemplar_df[\"rank_within_cat\"] = exemplar_df.groupby(\"category\")[\"mean_knn_dist\"].rank(\n",
    "            method=\"first\", ascending=True\n",
    "        ).astype(int)\n",
    "        exemplar_path = out_dir / f\"{prefix}_per_exemplar.csv\"\n",
    "        exemplar_df.to_csv(exemplar_path, index=False)\n",
    "        print(f\"Saved per-exemplar: {exemplar_path}\")\n",
    "\n",
    "    all_summary.append(summary_df.assign(k_used=k))\n",
    "\n",
    "if len(k_list) > 1:\n",
    "    combined = pd.concat(all_summary, ignore_index=True)\n",
    "    combined_path = out_dir / f\"bv_within_category_knn_{embedding}_multi_k_summary.csv\"\n",
    "    combined.to_csv(combined_path, index=False)\n",
    "    print(f\"Saved combined multi-k summary: {combined_path}\")\n",
    "\n",
    "print(\"Done. Lower mean_knn_dist = more micro-structure; higher = more uniform spread.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
