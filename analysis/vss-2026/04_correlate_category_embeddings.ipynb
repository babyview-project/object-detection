{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Correlate Category Embeddings\n",
    "\n",
    "This notebook correlates category-level average embeddings between two embedding files (e.g., bv_clip and things_clip).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This step:\n",
    "1. Loads category average embeddings from two sources\n",
    "2. Finds matching categories between the two sets\n",
    "3. Computes correlations (Pearson, Spearman, Cosine) for each category\n",
    "4. Reports summary statistics and top/bottom categories\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This step requires:\n",
    "- Output from Step 2 (e.g., bv_clip and things_clip category average embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Please update the paths below according to your setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Please review and update paths as needed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS FOR YOUR SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Input CSV files with category embeddings\n",
    "# Each CSV should have category names as the first column (index) and embedding dimensions as columns\n",
    "CSV_FILE1 = \"./bv_dino_filtered_zscored_hierarchical_163cats/normalized_filtered_embeddings.csv\"\n",
    "CSV_FILE2 = \"./things_dino_filtered_zscored_hierarchical_163cats/normalized_filtered_embeddings.csv\"\n",
    "\n",
    "# Category include file (optional - set to None to include all categories)\n",
    "CATEGORY_INCLUDE_FILE = \"/home/j7yang/babyview-projects/vss2026/object-detection/data/things_bv_overlap_categories_exclude_zero_precisions.txt\"  # Path to file with categories to include (one per line)\n",
    "\n",
    "# Output directory for correlation results\n",
    "OUTPUT_DIR = \"./correlation_results_12102025\"  # Directory to save correlation results\n",
    "OUTPUT_FILENAME = 'bv_things_dino_category_embeddings_correlations.txt'  # Output filename\n",
    "\n",
    "print(\"Configuration loaded. Please review and update paths as needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate Category Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CORRELATING CATEGORY EMBEDDINGS\n",
      "============================================================\n",
      "Loading embeddings 1 from bv_clip_filtered_zscored_hierarchical_163cats/normalized_filtered_embeddings.csv...\n",
      "  Categories: 163, Embedding dim: 512\n",
      "Loading embeddings 2 from things_clip_filtered_zscored_hierarchical_163cats/normalized_filtered_embeddings.csv...\n",
      "  Categories: 163, Embedding dim: 512\n",
      "After filtering by include file: 163 categories\n",
      "\n",
      "Matching categories: 163\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "Categories analyzed: 163\n",
      "\n",
      "Pearson Correlation:\n",
      "  Mean:   0.419263\n",
      "  Std:    0.142948\n",
      "  Median: 0.419869\n",
      "  Min:    -0.005119\n",
      "  Max:    0.754053\n",
      "\n",
      "Spearman Correlation:\n",
      "  Mean:   0.403240\n",
      "  Std:    0.140519\n",
      "  Median: 0.400799\n",
      "\n",
      "Kendall Correlation:\n",
      "  Mean:   0.279106\n",
      "  Std:    0.102047\n",
      "  Median: 0.274730\n",
      "\n",
      "Cosine Similarity:\n",
      "  Mean:   0.419337\n",
      "  Std:    0.143091\n",
      "  Median: 0.418913\n",
      "\n",
      "\n",
      "Top 10 categories by Pearson correlation:\n",
      "   1. zebra                          r=0.754053, cos=0.754306\n",
      "   2. mouth                          r=0.712486, cos=0.713844\n",
      "   3. giraffe                        r=0.707449, cos=0.707370\n",
      "   4. cloud                          r=0.688712, cos=0.689434\n",
      "   5. cracker                        r=0.682365, cos=0.682495\n",
      "   6. pasta                          r=0.655449, cos=0.655426\n",
      "   7. stick                          r=0.654088, cos=0.654247\n",
      "   8. helicopter                     r=0.639610, cos=0.639613\n",
      "   9. tricycle                       r=0.638672, cos=0.638645\n",
      "  10. shoe                           r=0.638592, cos=0.638018\n",
      "\n",
      "Bottom 10 categories by Pearson correlation:\n",
      "  154. mop                            r=0.178568, cos=0.177597\n",
      "  155. elephant                       r=0.178229, cos=0.177640\n",
      "  156. can                            r=0.175951, cos=0.174994\n",
      "  157. soap                           r=0.164377, cos=0.164704\n",
      "  158. slipper                        r=0.154991, cos=0.155281\n",
      "  159. raisin                         r=0.143375, cos=0.140958\n",
      "  160. bear                           r=0.141129, cos=0.141072\n",
      "  161. belt                           r=0.111263, cos=0.111759\n",
      "  162. watch                          r=0.045011, cos=0.044281\n",
      "  163. nail                           r=-0.005119, cos=-0.003982\n",
      "\n",
      "Results saved to: correlation_results_12102025/bv_things_clip_category_embeddings_correlations.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CORRELATING CATEGORY EMBEDDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "csv1_path = Path(CSV_FILE1)\n",
    "csv2_path = Path(CSV_FILE2)\n",
    "\n",
    "if not csv1_path.exists():\n",
    "    print(f\"Error: {csv1_path} not found. Please check the path.\")\n",
    "elif not csv2_path.exists():\n",
    "    print(f\"Error: {csv2_path} not found. Please check the path.\")\n",
    "else:\n",
    "    # Load CSV files\n",
    "    print(f\"Loading embeddings 1 from {csv1_path}...\")\n",
    "    df1 = pd.read_csv(csv1_path, index_col=0)\n",
    "    categories1 = df1.index.tolist()\n",
    "    embeddings1 = df1.values\n",
    "    print(f\"  Categories: {len(categories1)}, Embedding dim: {embeddings1.shape[1]}\")\n",
    "    \n",
    "    print(f\"Loading embeddings 2 from {csv2_path}...\")\n",
    "    df2 = pd.read_csv(csv2_path, index_col=0)\n",
    "    categories2 = df2.index.tolist()\n",
    "    embeddings2 = df2.values\n",
    "    print(f\"  Categories: {len(categories2)}, Embedding dim: {embeddings2.shape[1]}\")\n",
    "    \n",
    "    # Check embedding dimensions\n",
    "    if embeddings1.shape[1] != embeddings2.shape[1]:\n",
    "        print(f\"Warning: Embedding dimensions differ: {embeddings1.shape[1]} vs {embeddings2.shape[1]}\")\n",
    "        min_dim = min(embeddings1.shape[1], embeddings2.shape[1])\n",
    "        embeddings1 = embeddings1[:, :min_dim]\n",
    "        embeddings2 = embeddings2[:, :min_dim]\n",
    "        print(f\"  Using first {min_dim} dimensions\")\n",
    "    \n",
    "    # Find matching categories\n",
    "    categories1_set = set(categories1)\n",
    "    categories2_set = set(categories2)\n",
    "    matching_categories = sorted(categories1_set & categories2_set)\n",
    "    \n",
    "    # Filter by category include file if provided\n",
    "    if CATEGORY_INCLUDE_FILE is not None:\n",
    "        include_file_path = Path(CATEGORY_INCLUDE_FILE)\n",
    "        if include_file_path.exists():\n",
    "            with open(include_file_path, 'r') as f:\n",
    "                included_categories = set(line.strip() for line in f if line.strip())\n",
    "            matching_categories = [cat for cat in matching_categories if cat in included_categories]\n",
    "            print(f\"After filtering by include file: {len(matching_categories)} categories\")\n",
    "        else:\n",
    "            print(f\"Warning: Category include file not found: {include_file_path}\")\n",
    "            print(\"Proceeding with all matching categories.\")\n",
    "    \n",
    "    print(f\"\\nMatching categories: {len(matching_categories)}\")\n",
    "    \n",
    "    if len(matching_categories) == 0:\n",
    "        print(\"Error: No matching categories found!\")\n",
    "    else:\n",
    "        # Create mapping from category to index\n",
    "        cat_to_idx1 = {cat: idx for idx, cat in enumerate(categories1)}\n",
    "        cat_to_idx2 = {cat: idx for idx, cat in enumerate(categories2)}\n",
    "        \n",
    "        # Compute correlations for each matching category\n",
    "        per_category_results = []\n",
    "        all_pearson_rs = []\n",
    "        all_spearman_rs = []\n",
    "        all_kendall_rs = []\n",
    "        all_cosine_sims = []\n",
    "        \n",
    "        for cat in matching_categories:\n",
    "            idx1 = cat_to_idx1[cat]\n",
    "            idx2 = cat_to_idx2[cat]\n",
    "            \n",
    "            vec1 = embeddings1[idx1]\n",
    "            vec2 = embeddings2[idx2]\n",
    "            \n",
    "            # Remove NaN/Inf\n",
    "            mask = np.isfinite(vec1) & np.isfinite(vec2)\n",
    "            vec1_clean = vec1[mask]\n",
    "            vec2_clean = vec2[mask]\n",
    "            \n",
    "            if len(vec1_clean) >= 3:\n",
    "                pearson_r, pearson_p = pearsonr(vec1_clean, vec2_clean)\n",
    "                spearman_r, spearman_p = spearmanr(vec1_clean, vec2_clean)\n",
    "                kendall_r, kendall_p = kendalltau(vec1_clean, vec2_clean)\n",
    "            else:\n",
    "                pearson_r, pearson_p = np.nan, np.nan\n",
    "                spearman_r, spearman_p = np.nan, np.nan\n",
    "                kendall_r, kendall_p = np.nan, np.nan\n",
    "            \n",
    "            # Cosine similarity\n",
    "            if len(vec1_clean) > 0:\n",
    "                vec1_2d = vec1_clean.reshape(1, -1)\n",
    "                vec2_2d = vec2_clean.reshape(1, -1)\n",
    "                cosine_sim = cosine_similarity(vec1_2d, vec2_2d)[0, 0]\n",
    "            else:\n",
    "                cosine_sim = np.nan\n",
    "            \n",
    "            per_category_results.append({\n",
    "                'category': cat,\n",
    "                'pearson_r': pearson_r,\n",
    "                'spearman_r': spearman_r,\n",
    "                'kendall_r': kendall_r,\n",
    "                'cosine_similarity': cosine_sim\n",
    "            })\n",
    "            \n",
    "            if not np.isnan(pearson_r):\n",
    "                all_pearson_rs.append(pearson_r)\n",
    "            if not np.isnan(spearman_r):\n",
    "                all_spearman_rs.append(spearman_r)\n",
    "            if not np.isnan(kendall_r):\n",
    "                all_kendall_rs.append(kendall_r)\n",
    "            if not np.isnan(cosine_sim):\n",
    "                all_cosine_sims.append(cosine_sim)\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Categories analyzed: {len(matching_categories)}\")\n",
    "        print(f\"\\nPearson Correlation:\")\n",
    "        print(f\"  Mean:   {np.nanmean(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Std:    {np.nanstd(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Median: {np.nanmedian(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Min:    {np.nanmin(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Max:    {np.nanmax(all_pearson_rs):.6f}\")\n",
    "        print(f\"\\nSpearman Correlation:\")\n",
    "        print(f\"  Mean:   {np.nanmean(all_spearman_rs):.6f}\")\n",
    "        print(f\"  Std:    {np.nanstd(all_spearman_rs):.6f}\")\n",
    "        print(f\"  Median: {np.nanmedian(all_spearman_rs):.6f}\")\n",
    "        print(f\"\\nKendall Correlation:\")\n",
    "        print(f\"  Mean:   {np.nanmean(all_kendall_rs):.6f}\")\n",
    "        print(f\"  Std:    {np.nanstd(all_kendall_rs):.6f}\")\n",
    "        print(f\"  Median: {np.nanmedian(all_kendall_rs):.6f}\")\n",
    "        print(f\"\\nCosine Similarity:\")\n",
    "        print(f\"  Mean:   {np.nanmean(all_cosine_sims):.6f}\")\n",
    "        print(f\"  Std:    {np.nanstd(all_cosine_sims):.6f}\")\n",
    "        print(f\"  Median: {np.nanmedian(all_cosine_sims):.6f}\")\n",
    "        \n",
    "        # Top and bottom categories\n",
    "        sorted_results = sorted(per_category_results, \n",
    "                              key=lambda x: x['pearson_r'] if not np.isnan(x['pearson_r']) else -np.inf, \n",
    "                              reverse=True)\n",
    "        \n",
    "        print(f\"\\n\\nTop 10 categories by Pearson correlation:\")\n",
    "        for i, result in enumerate(sorted_results[:10], 1):\n",
    "            print(f\"  {i:2d}. {result['category']:<30} r={result['pearson_r']:.6f}, cos={result['cosine_similarity']:.6f}\")\n",
    "        \n",
    "        print(f\"\\nBottom 10 categories by Pearson correlation:\")\n",
    "        for i, result in enumerate(sorted_results[-10:], len(sorted_results)-9):\n",
    "            print(f\"  {i:2d}. {result['category']:<30} r={result['pearson_r']:.6f}, cos={result['cosine_similarity']:.6f}\")\n",
    "\n",
    "        # Save results to output directory\n",
    "        output_dir = Path(OUTPUT_DIR)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Create results text file\n",
    "        results_file = output_dir / OUTPUT_FILENAME\n",
    "        with open(results_file, 'w') as f:\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"CATEGORY EMBEDDING CORRELATION RESULTS\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\\n\")\n",
    "            f.write(f\"CSV File 1: {csv1_path}\\n\")\n",
    "            f.write(f\"CSV File 2: {csv2_path}\\n\\n\")\n",
    "            f.write(f\"Categories 1: {len(categories1)}, Embedding dim: {embeddings1.shape[1]}\\n\")\n",
    "            f.write(f\"Categories 2: {len(categories2)}, Embedding dim: {embeddings2.shape[1]}\\n\")\n",
    "            if CATEGORY_INCLUDE_FILE is not None:\n",
    "                f.write(f\"Category include file: {CATEGORY_INCLUDE_FILE}\\n\")\n",
    "            f.write(f\"Matching categories: {len(matching_categories)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"SUMMARY STATISTICS\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(f\"Categories analyzed: {len(matching_categories)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Pearson Correlation:\\n\")\n",
    "            f.write(f\"  Mean:   {np.nanmean(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.nanstd(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.nanmedian(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.nanmin(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.nanmax(all_pearson_rs):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Spearman Correlation:\\n\")\n",
    "            f.write(f\"  Mean:   {np.nanmean(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.nanstd(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.nanmedian(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.nanmin(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.nanmax(all_spearman_rs):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Kendall Correlation:\\n\")\n",
    "            f.write(f\"  Mean:   {np.nanmean(all_kendall_rs):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.nanstd(all_kendall_rs):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.nanmedian(all_kendall_rs):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.nanmin(all_kendall_rs):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.nanmax(all_kendall_rs):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Cosine Similarity:\\n\")\n",
    "            f.write(f\"  Mean:   {np.nanmean(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.nanstd(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.nanmedian(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.nanmin(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.nanmax(all_cosine_sims):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"TOP 10 CATEGORIES BY PEARSON CORRELATION\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            for i, result in enumerate(sorted_results[:10], 1):\n",
    "                f.write(f\"  {i:2d}. {result['category']:<30} pearson_r={result['pearson_r']:.6f}, spearman_r={result['spearman_r']:.6f}, kendall_r={result['kendall_r']:.6f}, cosine={result['cosine_similarity']:.6f}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "            f.write(\"BOTTOM 10 CATEGORIES BY PEARSON CORRELATION\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            for i, result in enumerate(sorted_results[-10:], len(sorted_results)-9):\n",
    "                f.write(f\"  {i:2d}. {result['category']:<30} pearson_r={result['pearson_r']:.6f}, spearman_r={result['spearman_r']:.6f}, kendall_r={result['kendall_r']:.6f}, cosine={result['cosine_similarity']:.6f}\\n\")\n",
    "        \n",
    "        print(f\"\\nResults saved to: {results_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vislearnlabpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
