{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Correlate Category Embeddings\n",
    "\n",
    "This notebook correlates category-level average embeddings between two embedding files (e.g., bv_clip and things_clip).\n",
    "\n",
    "## Overview\n",
    "\n",
    "This step:\n",
    "1. Loads category average embeddings from two sources\n",
    "2. Finds matching categories between the two sets\n",
    "3. Computes correlations (Pearson, Spearman, Cosine) for each category\n",
    "4. Reports summary statistics and top/bottom categories\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This step requires:\n",
    "- Output from Step 2 (e.g., bv_clip and things_clip category average embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Please update the paths below according to your setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Please review and update paths as needed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS FOR YOUR SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Input directories from Step 2\n",
    "AVG_CAT_EMB_PATH1 = \"./bv_clip_rdm_results_26/category_average_embeddings.npz\"  # bv_clip embeddings output directory\n",
    "AVG_CAT_EMB_PATH2 = \"../../data/things_clip_embeddings.npz\"  # things_clip embeddings output directory\n",
    "\n",
    "# Output directory for correlation results\n",
    "OUTPUT_DIR = \"./correlation_results_12102025\"  # Directory to save correlation results\n",
    "OUTPUT_FILENAME = 'bv_things_clip_category_embeddings_correlations.txt'  # Output filename\n",
    "\n",
    "print(\"Configuration loaded. Please review and update paths as needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate Category Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CORRELATING CATEGORY EMBEDDINGS\n",
      "============================================================\n",
      "Loading embeddings 1 from bv_clip_rdm_results_26/category_average_embeddings.npz...\n",
      "  Found categories under key 'categories'\n",
      "  Categories: 291, Embedding dim: 512\n",
      "Loading embeddings 2 from ../../data/things_clip_embeddings.npz...\n",
      "  Found categories under key 'labels'\n",
      "  Categories: 205, Embedding dim: 512\n",
      "\n",
      "Matching categories: 205\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "Categories analyzed: 205\n",
      "\n",
      "Pearson Correlation:\n",
      "  Mean:   0.738748\n",
      "  Std:    0.058235\n",
      "  Median: 0.731409\n",
      "  Min:    0.483288\n",
      "  Max:    0.866345\n",
      "\n",
      "Spearman Correlation:\n",
      "  Mean:   0.313609\n",
      "  Std:    0.108621\n",
      "  Median: 0.309980\n",
      "\n",
      "Cosine Similarity:\n",
      "  Mean:   0.738715\n",
      "  Std:    0.058269\n",
      "  Median: 0.731800\n",
      "\n",
      "\n",
      "Top 10 categories by Pearson correlation:\n",
      "   1. cloud                          r=0.866345, cos=0.866445\n",
      "   2. stick                          r=0.865384, cos=0.865511\n",
      "   3. rock                           r=0.863378, cos=0.863799\n",
      "   4. tree                           r=0.854524, cos=0.854646\n",
      "   5. paper                          r=0.850181, cos=0.850099\n",
      "   6. slide                          r=0.849322, cos=0.849533\n",
      "   7. swing                          r=0.848575, cos=0.848515\n",
      "   8. zebra                          r=0.844745, cos=0.844523\n",
      "   9. giraffe                        r=0.844194, cos=0.844238\n",
      "  10. finger                         r=0.843874, cos=0.843923\n",
      "\n",
      "Bottom 10 categories by Pearson correlation:\n",
      "  196. turkey                         r=0.646077, cos=0.646461\n",
      "  197. nut                            r=0.643673, cos=0.643876\n",
      "  198. wolf                           r=0.639932, cos=0.640366\n",
      "  199. ant                            r=0.629434, cos=0.629778\n",
      "  200. popsicle                       r=0.599230, cos=0.599344\n",
      "  201. watch                          r=0.597485, cos=0.597071\n",
      "  202. bug                            r=0.596182, cos=0.597101\n",
      "  203. raisin                         r=0.595778, cos=0.595052\n",
      "  204. train                          r=0.585604, cos=0.585432\n",
      "  205. car                            r=0.483288, cos=0.483619\n",
      "\n",
      "Results saved to: correlation_results_12102025/bv_things_clip_category_embeddings_correlations.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CORRELATING CATEGORY EMBEDDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "embeddings1_path = Path(AVG_CAT_EMB_PATH1)\n",
    "embeddings2_path = Path(AVG_CAT_EMB_PATH2)\n",
    "\n",
    "if not embeddings1_path.exists():\n",
    "    print(f\"Error: {embeddings1_path} not found. Please run Step 1 first.\")\n",
    "elif not embeddings2_path.exists():\n",
    "    print(f\"Error: {embeddings2_path} not found. Please run Step 1.2 first.\")\n",
    "else:\n",
    "    # Load embeddings\n",
    "    print(f\"Loading embeddings 1 from {embeddings1_path}...\")\n",
    "    data1 = np.load(embeddings1_path)\n",
    "    embeddings1 = data1['embeddings']\n",
    "    # Try multiple possible key names for categories\n",
    "    available_keys1 = list(data1.keys())\n",
    "    categories1 = None\n",
    "    for key_name in ['categories', 'category', 'labels', 'label']:\n",
    "        if key_name in available_keys1:\n",
    "            categories1 = [str(cat) for cat in data1[key_name]]\n",
    "            print(f\"  Found categories under key '{key_name}'\")\n",
    "            break\n",
    "    if categories1 is None:\n",
    "        raise KeyError(f\"No category/label key found in {embeddings1_path}. Available keys: {available_keys1}\")\n",
    "    print(f\"  Categories: {len(categories1)}, Embedding dim: {embeddings1.shape[1]}\")\n",
    "    \n",
    "    print(f\"Loading embeddings 2 from {embeddings2_path}...\")\n",
    "    data2 = np.load(embeddings2_path)\n",
    "    embeddings2 = data2['embeddings']\n",
    "    # Try multiple possible key names for categories\n",
    "    available_keys2 = list(data2.keys())\n",
    "    categories2 = None\n",
    "    for key_name in ['categories', 'category', 'labels', 'label']:\n",
    "        if key_name in available_keys2:\n",
    "            categories2 = [str(cat) for cat in data2[key_name]]\n",
    "            print(f\"  Found categories under key '{key_name}'\")\n",
    "            break\n",
    "    if categories2 is None:\n",
    "        raise KeyError(f\"No category/label key found in {embeddings2_path}. Available keys: {available_keys2}\")\n",
    "    print(f\"  Categories: {len(categories2)}, Embedding dim: {embeddings2.shape[1]}\")\n",
    "    \n",
    "    # Check embedding dimensions\n",
    "    if embeddings1.shape[1] != embeddings2.shape[1]:\n",
    "        print(f\"Warning: Embedding dimensions differ: {embeddings1.shape[1]} vs {embeddings2.shape[1]}\")\n",
    "        min_dim = min(embeddings1.shape[1], embeddings2.shape[1])\n",
    "        embeddings1 = embeddings1[:, :min_dim]\n",
    "        embeddings2 = embeddings2[:, :min_dim]\n",
    "        print(f\"  Using first {min_dim} dimensions\")\n",
    "    \n",
    "    # Find matching categories\n",
    "    categories1_set = set(categories1)\n",
    "    categories2_set = set(categories2)\n",
    "    matching_categories = sorted(categories1_set & categories2_set)\n",
    "    \n",
    "    print(f\"\\nMatching categories: {len(matching_categories)}\")\n",
    "    \n",
    "    if len(matching_categories) == 0:\n",
    "        print(\"Error: No matching categories found!\")\n",
    "    else:\n",
    "        # Create mapping from category to index\n",
    "        cat_to_idx1 = {cat: idx for idx, cat in enumerate(categories1)}\n",
    "        cat_to_idx2 = {cat: idx for idx, cat in enumerate(categories2)}\n",
    "        \n",
    "        # Compute correlations for each matching category\n",
    "        per_category_results = []\n",
    "        all_pearson_rs = []\n",
    "        all_spearman_rs = []\n",
    "        all_cosine_sims = []\n",
    "        \n",
    "        for cat in matching_categories:\n",
    "            idx1 = cat_to_idx1[cat]\n",
    "            idx2 = cat_to_idx2[cat]\n",
    "            \n",
    "            vec1 = embeddings1[idx1]\n",
    "            vec2 = embeddings2[idx2]\n",
    "            \n",
    "            # Remove NaN/Inf\n",
    "            mask = np.isfinite(vec1) & np.isfinite(vec2)\n",
    "            vec1_clean = vec1[mask]\n",
    "            vec2_clean = vec2[mask]\n",
    "            \n",
    "            if len(vec1_clean) >= 3:\n",
    "                pearson_r, pearson_p = pearsonr(vec1_clean, vec2_clean)\n",
    "                spearman_r, spearman_p = spearmanr(vec1_clean, vec2_clean)\n",
    "            else:\n",
    "                pearson_r, pearson_p = np.nan, np.nan\n",
    "                spearman_r, spearman_p = np.nan, np.nan\n",
    "            \n",
    "            # Cosine similarity\n",
    "            if len(vec1_clean) > 0:\n",
    "                vec1_2d = vec1_clean.reshape(1, -1)\n",
    "                vec2_2d = vec2_clean.reshape(1, -1)\n",
    "                cosine_sim = cosine_similarity(vec1_2d, vec2_2d)[0, 0]\n",
    "            else:\n",
    "                cosine_sim = np.nan\n",
    "            \n",
    "            per_category_results.append({\n",
    "                'category': cat,\n",
    "                'pearson_r': pearson_r,\n",
    "                'spearman_r': spearman_r,\n",
    "                'cosine_similarity': cosine_sim\n",
    "            })\n",
    "            \n",
    "            if not np.isnan(pearson_r):\n",
    "                all_pearson_rs.append(pearson_r)\n",
    "            if not np.isnan(spearman_r):\n",
    "                all_spearman_rs.append(spearman_r)\n",
    "            if not np.isnan(cosine_sim):\n",
    "                all_cosine_sims.append(cosine_sim)\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Categories analyzed: {len(matching_categories)}\")\n",
    "        print(f\"\\nPearson Correlation:\")\n",
    "        print(f\"  Mean:   {np.nanmean(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Std:    {np.nanstd(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Median: {np.nanmedian(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Min:    {np.nanmin(all_pearson_rs):.6f}\")\n",
    "        print(f\"  Max:    {np.nanmax(all_pearson_rs):.6f}\")\n",
    "        print(f\"\\nSpearman Correlation:\")\n",
    "        print(f\"  Mean:   {np.nanmean(all_spearman_rs):.6f}\")\n",
    "        print(f\"  Std:    {np.nanstd(all_spearman_rs):.6f}\")\n",
    "        print(f\"  Median: {np.nanmedian(all_spearman_rs):.6f}\")\n",
    "        print(f\"\\nCosine Similarity:\")\n",
    "        print(f\"  Mean:   {np.nanmean(all_cosine_sims):.6f}\")\n",
    "        print(f\"  Std:    {np.nanstd(all_cosine_sims):.6f}\")\n",
    "        print(f\"  Median: {np.nanmedian(all_cosine_sims):.6f}\")\n",
    "        \n",
    "        # Top and bottom categories\n",
    "        sorted_results = sorted(per_category_results, \n",
    "                              key=lambda x: x['pearson_r'] if not np.isnan(x['pearson_r']) else -np.inf, \n",
    "                              reverse=True)\n",
    "        \n",
    "        print(f\"\\n\\nTop 10 categories by Pearson correlation:\")\n",
    "        for i, result in enumerate(sorted_results[:10], 1):\n",
    "            print(f\"  {i:2d}. {result['category']:<30} r={result['pearson_r']:.6f}, cos={result['cosine_similarity']:.6f}\")\n",
    "        \n",
    "        print(f\"\\nBottom 10 categories by Pearson correlation:\")\n",
    "        for i, result in enumerate(sorted_results[-10:], len(sorted_results)-9):\n",
    "            print(f\"  {i:2d}. {result['category']:<30} r={result['pearson_r']:.6f}, cos={result['cosine_similarity']:.6f}\")\n",
    "\n",
    "        # Save results to output directory\n",
    "        output_dir = Path(OUTPUT_DIR)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Create results text file\n",
    "        results_file = output_dir / OUTPUT_FILENAME\n",
    "        with open(results_file, 'w') as f:\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"CATEGORY EMBEDDING CORRELATION RESULTS\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\\n\")\n",
    "            f.write(f\"Embeddings 1: {embeddings1_path}\\n\")\n",
    "            f.write(f\"Embeddings 2: {embeddings2_path}\\n\\n\")\n",
    "            f.write(f\"Categories 1: {len(categories1)}, Embedding dim: {embeddings1.shape[1]}\\n\")\n",
    "            f.write(f\"Categories 2: {len(categories2)}, Embedding dim: {embeddings2.shape[1]}\\n\")\n",
    "            f.write(f\"Matching categories: {len(matching_categories)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"SUMMARY STATISTICS\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(f\"Categories analyzed: {len(matching_categories)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Pearson Correlation:\\n\")\n",
    "            f.write(f\"  Mean:   {np.nanmean(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.nanstd(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.nanmedian(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.nanmin(all_pearson_rs):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.nanmax(all_pearson_rs):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Spearman Correlation:\\n\")\n",
    "            f.write(f\"  Mean:   {np.nanmean(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.nanstd(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.nanmedian(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.nanmin(all_spearman_rs):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.nanmax(all_spearman_rs):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Cosine Similarity:\\n\")\n",
    "            f.write(f\"  Mean:   {np.nanmean(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Std:    {np.nanstd(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Median: {np.nanmedian(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Min:    {np.nanmin(all_cosine_sims):.6f}\\n\")\n",
    "            f.write(f\"  Max:    {np.nanmax(all_cosine_sims):.6f}\\n\\n\")\n",
    "            \n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"TOP 10 CATEGORIES BY PEARSON CORRELATION\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            for i, result in enumerate(sorted_results[:10], 1):\n",
    "                f.write(f\"  {i:2d}. {result['category']:<30} pearson_r={result['pearson_r']:.6f}, spearman_r={result['spearman_r']:.6f}, cosine={result['cosine_similarity']:.6f}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "            f.write(\"BOTTOM 10 CATEGORIES BY PEARSON CORRELATION\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            for i, result in enumerate(sorted_results[-10:], len(sorted_results)-9):\n",
    "                f.write(f\"  {i:2d}. {result['category']:<30} pearson_r={result['pearson_r']:.6f}, spearman_r={result['spearman_r']:.6f}, cosine={result['cosine_similarity']:.6f}\\n\")\n",
    "        \n",
    "        print(f\"\\nResults saved to: {results_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vislearnlabpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
