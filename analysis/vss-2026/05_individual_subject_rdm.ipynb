{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Individual Subject RDM Analysis\n",
        "\n",
        "This notebook creates Representational Dissimilarity Matrices (RDMs) for each individual subject.\n",
        "Each subject's RDM shows the similarity structure of object categories based on their averaged embeddings.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This analysis:\n",
        "1. Loads grouped embeddings (averaged by category, subject, and age_mo)\n",
        "2. Aggregates embeddings per subject across all age_mo (weighted average if multiple age bins)\n",
        "3. Computes RDM for each subject using cosine distance\n",
        "4. Handles data density differences between subjects\n",
        "5. Visualizes and saves individual subject RDMs\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Data density handling**: Subjects with more data get more reliable RDMs\n",
        "- **Missing category handling**: Only includes categories present for each subject\n",
        "- **Weighted averaging**: If a subject has multiple age_mo bins, embeddings are weighted by sample count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set matplotlib backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo\")\n",
        "output_dir = Path(\"individual_subject_rdms\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Categories file (optional - to filter to specific categories)\n",
        "categories_file = Path(\"../../data/things_bv_overlap_categories_exclude_zero_precisions.txt\")\n",
        "\n",
        "# Minimum categories required per subject to compute RDM\n",
        "min_categories_per_subject = 10\n",
        "\n",
        "# Whether to weight by sample count when aggregating across age_mo\n",
        "weight_by_sample_count = True\n",
        "\n",
        "print(f\"Embeddings directory: {embeddings_dir}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Min categories per subject: {min_categories_per_subject}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Category List (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load allowed categories if file exists\n",
        "allowed_categories = None\n",
        "if categories_file.exists():\n",
        "    print(f\"Loading categories from {categories_file}...\")\n",
        "    with open(categories_file, 'r') as f:\n",
        "        allowed_categories = set(line.strip() for line in f if line.strip())\n",
        "    print(f\"Loaded {len(allowed_categories)} categories\")\n",
        "else:\n",
        "    print(f\"Categories file not found, using all categories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_subject_embeddings(embeddings_dir, allowed_categories=None):\n",
        "    \"\"\"\n",
        "    Load embeddings organized by subject and category.\n",
        "    \n",
        "    Returns:\n",
        "        subject_embeddings: dict[subject_id][category] = {\n",
        "            'embedding': np.array,  # averaged embedding\n",
        "            'age_mo': int,  # age in months\n",
        "            'sample_count': int  # number of embeddings averaged\n",
        "        }\n",
        "    \"\"\"\n",
        "    subject_embeddings = defaultdict(lambda: defaultdict(dict))\n",
        "    \n",
        "    # Get all category folders\n",
        "    category_folders = [f for f in embeddings_dir.iterdir() if f.is_dir()]\n",
        "    \n",
        "    if allowed_categories:\n",
        "        category_folders = [f for f in category_folders if f.name in allowed_categories]\n",
        "    \n",
        "    print(f\"Loading embeddings from {len(category_folders)} categories...\")\n",
        "    \n",
        "    for category_folder in tqdm(category_folders, desc=\"Loading categories\"):\n",
        "        category = category_folder.name\n",
        "        \n",
        "        # Get all embedding files in this category\n",
        "        embedding_files = list(category_folder.glob(\"*.npy\"))\n",
        "        \n",
        "        for emb_file in embedding_files:\n",
        "            # Parse filename: {subject_id}_{age_mo}_month_level_avg.npy\n",
        "            filename = emb_file.stem  # without .npy\n",
        "            parts = filename.split('_')\n",
        "            \n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            \n",
        "            # Extract subject_id and age_mo\n",
        "            # Format: S00560001_16_month_level_avg\n",
        "            subject_id = parts[0]\n",
        "            age_mo = int(parts[1]) if parts[1].isdigit() else None\n",
        "            \n",
        "            if age_mo is None:\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                embedding = np.load(emb_file)\n",
        "                \n",
        "                # Store embedding with metadata\n",
        "                # If subject already has this category at this age_mo, we'll average them later\n",
        "                key = (category, age_mo)\n",
        "                if key not in subject_embeddings[subject_id][category]:\n",
        "                    subject_embeddings[subject_id][category][key] = {\n",
        "                        'embedding': embedding,\n",
        "                        'age_mo': age_mo,\n",
        "                        'sample_count': 1  # We don't have this info, assume 1\n",
        "                    }\n",
        "                else:\n",
        "                    # Average if duplicate\n",
        "                    existing = subject_embeddings[subject_id][category][key]\n",
        "                    n_existing = existing['sample_count']\n",
        "                    n_new = 1\n",
        "                    existing['embedding'] = (existing['embedding'] * n_existing + embedding) / (n_existing + n_new)\n",
        "                    existing['sample_count'] += n_new\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {emb_file}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    return subject_embeddings\n",
        "\n",
        "# Load embeddings\n",
        "subject_embeddings_raw = load_subject_embeddings(embeddings_dir, allowed_categories)\n",
        "print(f\"\\nLoaded embeddings for {len(subject_embeddings_raw)} subjects\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregate Embeddings Per Subject\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_subject_embeddings(subject_embeddings_raw, weight_by_sample_count=True):\n",
        "    \"\"\"\n",
        "    Aggregate embeddings per subject across age_mo bins.\n",
        "    \n",
        "    For each subject-category pair, if there are multiple age_mo bins,\n",
        "    compute a weighted average.\n",
        "    \"\"\"\n",
        "    subject_embeddings_agg = {}\n",
        "    \n",
        "    for subject_id, categories in tqdm(subject_embeddings_raw.items(), desc=\"Aggregating subjects\"):\n",
        "        subject_embeddings_agg[subject_id] = {}\n",
        "        \n",
        "        for category, age_data in categories.items():\n",
        "            # Get all age_mo bins for this subject-category pair\n",
        "            embeddings_list = []\n",
        "            weights_list = []\n",
        "            \n",
        "            for (cat, age_mo), data in age_data.items():\n",
        "                embeddings_list.append(data['embedding'])\n",
        "                if weight_by_sample_count:\n",
        "                    weights_list.append(data['sample_count'])\n",
        "                else:\n",
        "                    weights_list.append(1.0)\n",
        "            \n",
        "            if len(embeddings_list) == 0:\n",
        "                continue\n",
        "            \n",
        "            # Compute weighted average\n",
        "            embeddings_array = np.array(embeddings_list)\n",
        "            weights_array = np.array(weights_list)\n",
        "            weights_array = weights_array / weights_array.sum()  # Normalize weights\n",
        "            \n",
        "            # Weighted average\n",
        "            aggregated = np.average(embeddings_array, axis=0, weights=weights_array)\n",
        "            \n",
        "            subject_embeddings_agg[subject_id][category] = aggregated\n",
        "    \n",
        "    return subject_embeddings_agg\n",
        "\n",
        "# Aggregate embeddings\n",
        "subject_embeddings = aggregate_subject_embeddings(\n",
        "    subject_embeddings_raw, \n",
        "    weight_by_sample_count=weight_by_sample_count\n",
        ")\n",
        "\n",
        "print(f\"\\nAggregated embeddings for {len(subject_embeddings)} subjects\")\n",
        "\n",
        "# Show category counts per subject\n",
        "category_counts = {sid: len(cats) for sid, cats in subject_embeddings.items()}\n",
        "print(f\"\\nCategory counts per subject:\")\n",
        "print(f\"  Min: {min(category_counts.values())}\")\n",
        "print(f\"  Max: {max(category_counts.values())}\")\n",
        "print(f\"  Mean: {np.mean(list(category_counts.values())):.1f}\")\n",
        "print(f\"  Median: {np.median(list(category_counts.values())):.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize Embeddings\n",
        "\n",
        "Before computing RDMs, we normalize embeddings using z-score normalization (mean=0, std=1) to ensure fair comparisons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global normalization: normalize across ALL embeddings from ALL subjects\n",
        "print(\"Computing global normalization statistics across all subjects...\")\n",
        "\n",
        "# Collect all embeddings from all subjects\n",
        "all_embeddings_list = []\n",
        "for subject_id, categories in subject_embeddings.items():\n",
        "    for cat, embedding in categories.items():\n",
        "        all_embeddings_list.append(embedding)\n",
        "\n",
        "# Stack all embeddings\n",
        "all_embeddings_matrix = np.array(all_embeddings_list)\n",
        "print(f\"  Collected {len(all_embeddings_list)} embeddings from {len(subject_embeddings)} subjects\")\n",
        "\n",
        "# Compute global mean and std across all embeddings\n",
        "global_mean = all_embeddings_matrix.mean(axis=0)\n",
        "global_std = all_embeddings_matrix.std(axis=0) + 1e-10  # Add small epsilon to avoid division by zero\n",
        "\n",
        "print(f\"  Global mean shape: {global_mean.shape}\")\n",
        "print(f\"  Global std shape: {global_std.shape}\")\n",
        "print(f\"  Global mean range: [{global_mean.min():.4f}, {global_mean.max():.4f}]\")\n",
        "print(f\"  Global std range: [{global_std.min():.4f}, {global_std.max():.4f}]\")\n",
        "\n",
        "# Apply global normalization to each subject's embeddings\n",
        "print(\"\\nApplying global normalization to each subject...\")\n",
        "subject_embeddings_normalized = {}\n",
        "\n",
        "for subject_id, categories in tqdm(subject_embeddings.items(), desc=\"Normalizing\"):\n",
        "    subject_embeddings_normalized[subject_id] = {}\n",
        "    \n",
        "    for cat, embedding in categories.items():\n",
        "        # Apply global normalization: (x - global_mean) / global_std\n",
        "        normalized_embedding = (embedding - global_mean) / global_std\n",
        "        subject_embeddings_normalized[subject_id][cat] = normalized_embedding\n",
        "\n",
        "print(f\"Normalized embeddings for {len(subject_embeddings_normalized)} subjects using global statistics\")\n",
        "\n",
        "def compute_subject_rdm(subject_embeddings_dict, categories_list):\n",
        "    \"\"\"\n",
        "    Compute RDM for a single subject.\n",
        "    \n",
        "    Args:\n",
        "        subject_embeddings_dict: dict[category] = embedding array (should be normalized)\n",
        "        categories_list: list of categories to include (in order)\n",
        "    \n",
        "    Returns:\n",
        "        rdm: numpy array of shape (n_categories, n_categories)\n",
        "        available_categories: list of categories actually present\n",
        "    \"\"\"\n",
        "    # Filter to categories that exist for this subject\n",
        "    available_categories = [cat for cat in categories_list if cat in subject_embeddings_dict]\n",
        "    \n",
        "    if len(available_categories) < 2:\n",
        "        return None, available_categories\n",
        "    \n",
        "    # Build embedding matrix (already normalized)\n",
        "    embedding_matrix = np.array([subject_embeddings_dict[cat] for cat in available_categories])\n",
        "    \n",
        "    # Compute cosine similarity\n",
        "    similarity_matrix = cosine_similarity(embedding_matrix)\n",
        "    \n",
        "    # Convert to distance (RDM)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    np.fill_diagonal(distance_matrix, 0)  # Ensure diagonal is 0\n",
        "    \n",
        "    # Make symmetric (in case of numerical errors)\n",
        "    distance_matrix = (distance_matrix + distance_matrix.T) / 2\n",
        "    \n",
        "    return distance_matrix, available_categories\n",
        "\n",
        "# Get all unique categories across all subjects\n",
        "all_categories = set()\n",
        "for subject_id, categories in subject_embeddings_normalized.items():\n",
        "    all_categories.update(categories.keys())\n",
        "\n",
        "all_categories = sorted(list(all_categories))\n",
        "print(f\"Total unique categories across all subjects: {len(all_categories)}\")\n",
        "\n",
        "# Compute RDMs for each subject using normalized embeddings\n",
        "subject_rdms = {}\n",
        "subject_rdm_categories = {}\n",
        "\n",
        "for subject_id, categories in tqdm(subject_embeddings_normalized.items(), desc=\"Computing RDMs\"):\n",
        "    if len(categories) < min_categories_per_subject:\n",
        "        continue\n",
        "    \n",
        "    rdm, available_cats = compute_subject_rdm(categories, all_categories)\n",
        "    \n",
        "    if rdm is not None:\n",
        "        subject_rdms[subject_id] = rdm\n",
        "        subject_rdm_categories[subject_id] = available_cats\n",
        "\n",
        "print(f\"\\nComputed RDMs for {len(subject_rdms)} subjects\")\n",
        "print(f\"  (Excluded {len(subject_embeddings_normalized) - len(subject_rdms)} subjects with < {min_categories_per_subject} categories)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Individual Subject RDMs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Individual Subject RDMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save RDMs\n",
        "print(\"Saving individual subject RDMs...\")\n",
        "\n",
        "for subject_id, rdm in tqdm(subject_rdms.items(), desc=\"Saving RDMs\"):\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    # Save as numpy array\n",
        "    np.save(output_dir / f\"rdm_{subject_id}.npy\", rdm)\n",
        "    \n",
        "    # Save as CSV with category labels\n",
        "    rdm_df = pd.DataFrame(rdm, index=categories, columns=categories)\n",
        "    rdm_df.to_csv(output_dir / f\"rdm_{subject_id}.csv\")\n",
        "    \n",
        "    # Save metadata\n",
        "    metadata = {\n",
        "        'subject_id': subject_id,\n",
        "        'n_categories': len(categories),\n",
        "        'categories': categories,\n",
        "        'mean_distance': float(rdm.mean()),\n",
        "        'std_distance': float(rdm.std())\n",
        "    }\n",
        "    \n",
        "    metadata_df = pd.DataFrame([metadata])\n",
        "    metadata_df.to_csv(output_dir / f\"metadata_{subject_id}.csv\", index=False)\n",
        "\n",
        "print(f\"\\nSaved RDMs to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary dataframe\n",
        "summary_data = []\n",
        "\n",
        "for subject_id, rdm in subject_rdms.items():\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    summary_data.append({\n",
        "        'subject_id': subject_id,\n",
        "        'n_categories': len(categories),\n",
        "        'mean_distance': float(rdm.mean()),\n",
        "        'std_distance': float(rdm.std()),\n",
        "        'min_distance': float(rdm[rdm > 0].min()) if (rdm > 0).any() else np.nan,\n",
        "        'max_distance': float(rdm.max())\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df = summary_df.sort_values('n_categories', ascending=False)\n",
        "summary_df.to_csv(output_dir / \"summary_statistics.csv\", index=False)\n",
        "\n",
        "print(\"Summary statistics:\")\n",
        "print(summary_df.describe())\n",
        "print(f\"\\nSaved summary to {output_dir / 'summary_statistics.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Sample RDMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a few sample RDMs\n",
        "n_samples = min(6, len(subject_rdms))\n",
        "sample_subjects = list(subject_rdms.keys())[:n_samples]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, subject_id in enumerate(sample_subjects):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    im = ax.imshow(rdm, cmap='viridis', aspect='auto')\n",
        "    ax.set_title(f\"{subject_id}\\n({len(categories)} categories)\", fontsize=10)\n",
        "    ax.set_xlabel('Category')\n",
        "    ax.set_ylabel('Category')\n",
        "    plt.colorbar(im, ax=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"sample_rdms.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved sample RDM visualization to {output_dir / 'sample_rdms.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Density Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze data density across subjects\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Category count distribution\n",
        "axes[0].hist([len(cats) for cats in subject_rdm_categories.values()], bins=20, edgecolor='black')\n",
        "axes[0].set_xlabel('Number of Categories per Subject')\n",
        "axes[0].set_ylabel('Number of Subjects')\n",
        "axes[0].set_title('Data Density: Categories per Subject')\n",
        "axes[0].axvline(min_categories_per_subject, color='red', linestyle='--', label=f'Min threshold ({min_categories_per_subject})')\n",
        "axes[0].legend()\n",
        "\n",
        "# Mean distance vs category count\n",
        "mean_distances = [subject_rdms[sid].mean() for sid in subject_rdms.keys()]\n",
        "n_categories = [len(subject_rdm_categories[sid]) for sid in subject_rdms.keys()]\n",
        "\n",
        "axes[1].scatter(n_categories, mean_distances, alpha=0.6)\n",
        "axes[1].set_xlabel('Number of Categories')\n",
        "axes[1].set_ylabel('Mean RDM Distance')\n",
        "axes[1].set_title('RDM Distance vs Data Density')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"data_density_analysis.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved data density analysis to {output_dir / 'data_density_analysis.png'}\")\n",
        "plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
