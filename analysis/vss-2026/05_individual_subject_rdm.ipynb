{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Individual Subject RDM Analysis\n",
        "\n",
        "This notebook creates Representational Dissimilarity Matrices (RDMs) for each individual subject.\n",
        "Each subject's RDM shows the similarity structure of object categories based on their averaged embeddings.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This analysis:\n",
        "1. Loads grouped embeddings (averaged by category, subject, and age_mo)\n",
        "2. Aggregates embeddings per subject across all age_mo (weighted average if multiple age bins)\n",
        "3. Computes RDM for each subject using cosine distance\n",
        "4. Handles data density differences between subjects\n",
        "5. Visualizes and saves individual subject RDMs\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Data density handling**: Subjects with more data get more reliable RDMs\n",
        "- **Missing category handling**: Only includes categories present for each subject\n",
        "- **Weighted averaging**: If a subject has multiple age_mo bins, embeddings are weighted by sample count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
        "from scipy.spatial.distance import squareform\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set matplotlib backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CDI path: ../../data/cdi_words.csv\n",
            "Use clustering: True\n"
          ]
        }
      ],
      "source": [
        "# CDI words CSV file (required for category type organization)\n",
        "cdi_path = Path(\"../../data/cdi_words.csv\")\n",
        "\n",
        "# Hierarchical clustering options\n",
        "use_clustering = True  # Enable hierarchical clustering within category groups\n",
        "save_dendrograms = True  # Save dendrogram plots for each category group\n",
        "\n",
        "print(f\"CDI path: {cdi_path}\")\n",
        "print(f\"Use clustering: {use_clustering}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded!\n"
          ]
        }
      ],
      "source": [
        "def load_category_types(cdi_path):\n",
        "    \"\"\"Load category type information from CDI words CSV\"\"\"\n",
        "    print(f\"Loading category types from {cdi_path}...\")\n",
        "    cdi_df = pd.read_csv(cdi_path)\n",
        "    \n",
        "    category_types = {}\n",
        "    for _, row in cdi_df.iterrows():\n",
        "        category_types[row['uni_lemma']] = {\n",
        "            'is_animate': bool(row.get('is_animate', 0)),\n",
        "            'is_bodypart': bool(row.get('is_bodypart', 0)),\n",
        "            'is_small': bool(row.get('is_small', 0)),\n",
        "            'is_big': bool(row.get('is_big', 0))\n",
        "        }\n",
        "    \n",
        "    print(f\"Loaded type information for {len(category_types)} categories\")\n",
        "    return category_types\n",
        "\n",
        "def cluster_categories_within_group(group_categories, cat_to_embedding, save_dendrogram=False, output_dir=None, group_name=None):\n",
        "    \"\"\"\n",
        "    Perform hierarchical clustering within a group of categories.\n",
        "    \n",
        "    Args:\n",
        "        group_categories: List of category names in the group\n",
        "        cat_to_embedding: Dictionary mapping category names to embeddings\n",
        "        save_dendrogram: Whether to save dendrogram plot (default: False)\n",
        "        output_dir: Output directory for saving dendrogram (required if save_dendrogram=True)\n",
        "        group_name: Name of the group for saving dendrogram (required if save_dendrogram=True)\n",
        "    \n",
        "    Returns:\n",
        "        List of category names reordered according to clustering dendrogram\n",
        "    \"\"\"\n",
        "    if len(group_categories) <= 1:\n",
        "        return group_categories, None\n",
        "    \n",
        "    # Get embeddings for this group\n",
        "    group_embeddings = np.array([cat_to_embedding[cat].flatten() for cat in group_categories])\n",
        "    \n",
        "    # Normalize embeddings (z-score normalization per embedding)\n",
        "    normalized_embeddings = (group_embeddings - group_embeddings.mean(axis=0)) / (group_embeddings.std(axis=0) + 1e-10)\n",
        "    \n",
        "    # Compute distance matrix (1 - cosine similarity)\n",
        "    similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    np.fill_diagonal(distance_matrix, 0)\n",
        "    \n",
        "    # Convert to condensed form for linkage\n",
        "    condensed_distances = squareform(distance_matrix)\n",
        "    \n",
        "    # Perform hierarchical clustering\n",
        "    linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "    \n",
        "    # Get optimal leaf ordering for better visualization\n",
        "    try:\n",
        "        linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "    except:\n",
        "        # If optimal leaf ordering fails, use original linkage\n",
        "        pass\n",
        "    \n",
        "    # Extract the order from the dendrogram\n",
        "    dendro_dict = dendrogram(linkage_matrix, no_plot=True)\n",
        "    leaf_order = dendro_dict['leaves']\n",
        "    \n",
        "    # Reorder categories according to clustering\n",
        "    clustered_categories = [group_categories[i] for i in leaf_order]\n",
        "    \n",
        "    # Save dendrogram if requested\n",
        "    if save_dendrogram and output_dir is not None and group_name is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        dendrogram(linkage_matrix, \n",
        "                  labels=group_categories,\n",
        "                  leaf_rotation=90,\n",
        "                  leaf_font_size=10)\n",
        "        plt.title(f'Hierarchical Clustering Dendrogram: {group_name.upper()}\\\\n({len(group_categories)} categories)',\n",
        "                 fontsize=16, pad=20)\n",
        "        plt.xlabel('Category', fontsize=12)\n",
        "        plt.ylabel('Distance', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save as PNG\n",
        "        output_path_png = output_dir / f'dendrogram_{group_name}.png'\n",
        "        plt.savefig(output_path_png, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_png}\")\n",
        "        \n",
        "        # Save as PDF\n",
        "        output_path_pdf = output_dir / f'dendrogram_{group_name}.pdf'\n",
        "        plt.savefig(output_path_pdf, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_pdf}\")\n",
        "        \n",
        "        plt.close()\n",
        "    \n",
        "    return clustered_categories, linkage_matrix\n",
        "\n",
        "print(\"Helper functions loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo\n",
            "Output directory: individual_subject_rdms\n",
            "Min categories per subject: 10\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo\")\n",
        "output_dir = Path(\"individual_subject_rdms\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Categories file (optional - to filter to specific categories)\n",
        "categories_file = Path(\"../../data/things_bv_overlap_categories_exclude_zero_precisions.txt\")\n",
        "\n",
        "# Minimum categories required per subject to compute RDM\n",
        "min_categories_per_subject = 10\n",
        "\n",
        "# Whether to weight by sample count when aggregating across age_mo\n",
        "weight_by_sample_count = True\n",
        "\n",
        "print(f\"Embeddings directory: {embeddings_dir}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Min categories per subject: {min_categories_per_subject}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Category List (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading categories from ../../data/things_bv_overlap_categories_exclude_zero_precisions.txt...\n",
            "Loaded 163 categories\n"
          ]
        }
      ],
      "source": [
        "# Load allowed categories if file exists\n",
        "allowed_categories = None\n",
        "if categories_file.exists():\n",
        "    print(f\"Loading categories from {categories_file}...\")\n",
        "    with open(categories_file, 'r') as f:\n",
        "        allowed_categories = set(line.strip() for line in f if line.strip())\n",
        "    print(f\"Loaded {len(allowed_categories)} categories\")\n",
        "else:\n",
        "    print(f\"Categories file not found, using all categories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embeddings from 163 categories...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading categories: 100%|██████████| 163/163 [00:01<00:00, 121.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded embeddings for 32 subjects\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def load_subject_embeddings(embeddings_dir, allowed_categories=None):\n",
        "    \"\"\"\n",
        "    Load embeddings organized by subject and category.\n",
        "    \n",
        "    Returns:\n",
        "        subject_embeddings: dict[subject_id][category] = {\n",
        "            'embedding': np.array,  # averaged embedding\n",
        "            'age_mo': int,  # age in months\n",
        "            'sample_count': int  # number of embeddings averaged\n",
        "        }\n",
        "    \"\"\"\n",
        "    subject_embeddings = defaultdict(lambda: defaultdict(dict))\n",
        "    \n",
        "    # Get all category folders\n",
        "    category_folders = [f for f in embeddings_dir.iterdir() if f.is_dir()]\n",
        "    \n",
        "    if allowed_categories:\n",
        "        category_folders = [f for f in category_folders if f.name in allowed_categories]\n",
        "    \n",
        "    print(f\"Loading embeddings from {len(category_folders)} categories...\")\n",
        "    \n",
        "    for category_folder in tqdm(category_folders, desc=\"Loading categories\"):\n",
        "        category = category_folder.name\n",
        "        \n",
        "        # Get all embedding files in this category\n",
        "        embedding_files = list(category_folder.glob(\"*.npy\"))\n",
        "        \n",
        "        for emb_file in embedding_files:\n",
        "            # Parse filename: {subject_id}_{age_mo}_month_level_avg.npy\n",
        "            filename = emb_file.stem  # without .npy\n",
        "            parts = filename.split('_')\n",
        "            \n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            \n",
        "            # Extract subject_id and age_mo\n",
        "            # Format: S00560001_16_month_level_avg\n",
        "            subject_id = parts[0]\n",
        "            age_mo = int(parts[1]) if parts[1].isdigit() else None\n",
        "            \n",
        "            if age_mo is None:\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                embedding = np.load(emb_file)\n",
        "                \n",
        "                # Store embedding with metadata\n",
        "                # If subject already has this category at this age_mo, we'll average them later\n",
        "                key = (category, age_mo)\n",
        "                if key not in subject_embeddings[subject_id][category]:\n",
        "                    subject_embeddings[subject_id][category][key] = {\n",
        "                        'embedding': embedding,\n",
        "                        'age_mo': age_mo,\n",
        "                        'sample_count': 1  # We don't have this info, assume 1\n",
        "                    }\n",
        "                else:\n",
        "                    # Average if duplicate\n",
        "                    existing = subject_embeddings[subject_id][category][key]\n",
        "                    n_existing = existing['sample_count']\n",
        "                    n_new = 1\n",
        "                    existing['embedding'] = (existing['embedding'] * n_existing + embedding) / (n_existing + n_new)\n",
        "                    existing['sample_count'] += n_new\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {emb_file}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    return subject_embeddings\n",
        "\n",
        "# Load embeddings\n",
        "subject_embeddings_raw = load_subject_embeddings(embeddings_dir, allowed_categories)\n",
        "print(f\"\\nLoaded embeddings for {len(subject_embeddings_raw)} subjects\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregate Embeddings Per Subject\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Aggregating subjects: 100%|██████████| 32/32 [00:00<00:00, 235.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aggregated embeddings for 32 subjects\n",
            "\n",
            "Category counts per subject:\n",
            "  Min: 55\n",
            "  Max: 162\n",
            "  Mean: 145.3\n",
            "  Median: 154.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def aggregate_subject_embeddings(subject_embeddings_raw, weight_by_sample_count=True):\n",
        "    \"\"\"\n",
        "    Aggregate embeddings per subject across age_mo bins.\n",
        "    \n",
        "    For each subject-category pair, if there are multiple age_mo bins,\n",
        "    compute a weighted average.\n",
        "    \"\"\"\n",
        "    subject_embeddings_agg = {}\n",
        "    \n",
        "    for subject_id, categories in tqdm(subject_embeddings_raw.items(), desc=\"Aggregating subjects\"):\n",
        "        subject_embeddings_agg[subject_id] = {}\n",
        "        \n",
        "        for category, age_data in categories.items():\n",
        "            # Get all age_mo bins for this subject-category pair\n",
        "            embeddings_list = []\n",
        "            weights_list = []\n",
        "            \n",
        "            for (cat, age_mo), data in age_data.items():\n",
        "                embeddings_list.append(data['embedding'])\n",
        "                if weight_by_sample_count:\n",
        "                    weights_list.append(data['sample_count'])\n",
        "                else:\n",
        "                    weights_list.append(1.0)\n",
        "            \n",
        "            if len(embeddings_list) == 0:\n",
        "                continue\n",
        "            \n",
        "            # Compute weighted average\n",
        "            embeddings_array = np.array(embeddings_list)\n",
        "            weights_array = np.array(weights_list)\n",
        "            weights_array = weights_array / weights_array.sum()  # Normalize weights\n",
        "            \n",
        "            # Weighted average\n",
        "            aggregated = np.average(embeddings_array, axis=0, weights=weights_array)\n",
        "            \n",
        "            subject_embeddings_agg[subject_id][category] = aggregated\n",
        "    \n",
        "    return subject_embeddings_agg\n",
        "\n",
        "# Aggregate embeddings\n",
        "subject_embeddings = aggregate_subject_embeddings(\n",
        "    subject_embeddings_raw, \n",
        "    weight_by_sample_count=weight_by_sample_count\n",
        ")\n",
        "\n",
        "print(f\"\\nAggregated embeddings for {len(subject_embeddings)} subjects\")\n",
        "\n",
        "# Show category counts per subject\n",
        "category_counts = {sid: len(cats) for sid, cats in subject_embeddings.items()}\n",
        "print(f\"\\nCategory counts per subject:\")\n",
        "print(f\"  Min: {min(category_counts.values())}\")\n",
        "print(f\"  Max: {max(category_counts.values())}\")\n",
        "print(f\"  Mean: {np.mean(list(category_counts.values())):.1f}\")\n",
        "print(f\"  Median: {np.median(list(category_counts.values())):.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize Embeddings\n",
        "\n",
        "Before computing RDMs, we normalize embeddings using z-score normalization (mean=0, std=1) to ensure fair comparisons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NOTE: Category organization code has been moved to after normalization.\n",
        "# This cell is kept for reference but is no longer executed.\n",
        "# See the normalization cell for the organization code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing global normalization statistics across all subjects...\n",
            "  Collected 4651 embeddings from 32 subjects\n",
            "  Global mean shape: (512,)\n",
            "  Global std shape: (512,)\n",
            "  Global mean range: [-9.0121, 1.2518]\n",
            "  Global std range: [0.0573, 0.6508]\n",
            "\n",
            "Applying global normalization to each subject...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Normalizing:   0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Normalizing: 100%|██████████| 32/32 [00:00<00:00, 2028.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized embeddings for 32 subjects using global statistics\n",
            "Loading category types from ../../data/cdi_words.csv...\n",
            "Loaded type information for 295 categories\n",
            "Total unique categories across all subjects: 163\n",
            "\n",
            "Organizing categories by type and applying hierarchical clustering...\n",
            "  Organized into: 19 animals, 14 bodyparts, 32 big objects, 96 small objects, 2 others\n",
            "\n",
            "Applying hierarchical clustering within groups...\n",
            "  Clustering animals (19 categories)...\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_animals.png\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_animals.pdf\n",
            "  Clustering bodyparts (14 categories)...\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_bodyparts.png\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_bodyparts.pdf\n",
            "  Clustering big_objects (32 categories)...\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_big_objects.png\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_big_objects.pdf\n",
            "  Clustering small_objects (96 categories)...\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_small_objects.png\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_small_objects.pdf\n",
            "  Clustering others (2 categories)...\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_others.png\n",
            "    Saved dendrogram to individual_subject_rdms/dendrogram_others.pdf\n",
            "\n",
            "Final ordered category list: 163 categories\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing RDMs: 100%|██████████| 32/32 [00:00<00:00, 1342.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computed RDMs for 32 subjects\n",
            "  (Excluded 0 subjects with < 10 categories)\n",
            "\n",
            "Reorganizing individual subject RDMs according to new category ordering...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reorganizing RDMs: 100%|██████████| 32/32 [00:00<00:00, 2988.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reorganized RDMs for 32 subjects\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Global normalization: normalize across ALL embeddings from ALL subjects\n",
        "print(\"Computing global normalization statistics across all subjects...\")\n",
        "\n",
        "# Collect all embeddings from all subjects\n",
        "all_embeddings_list = []\n",
        "for subject_id, categories in subject_embeddings.items():\n",
        "    for cat, embedding in categories.items():\n",
        "        all_embeddings_list.append(embedding)\n",
        "\n",
        "# Stack all embeddings\n",
        "all_embeddings_matrix = np.array(all_embeddings_list)\n",
        "print(f\"  Collected {len(all_embeddings_list)} embeddings from {len(subject_embeddings)} subjects\")\n",
        "\n",
        "# Compute global mean and std across all embeddings\n",
        "# Flatten embeddings first to ensure consistent 1D shape\n",
        "all_embeddings_matrix_flat = np.array([emb.flatten() for emb in all_embeddings_list])\n",
        "global_mean = all_embeddings_matrix_flat.mean(axis=0)\n",
        "global_std = all_embeddings_matrix_flat.std(axis=0) + 1e-10  # Add small epsilon to avoid division by zero\n",
        "\n",
        "print(f\"  Global mean shape: {global_mean.shape}\")\n",
        "print(f\"  Global std shape: {global_std.shape}\")\n",
        "print(f\"  Global mean range: [{global_mean.min():.4f}, {global_mean.max():.4f}]\")\n",
        "print(f\"  Global std range: [{global_std.min():.4f}, {global_std.max():.4f}]\")\n",
        "\n",
        "# Apply global normalization to each subject's embeddings\n",
        "print(\"\\nApplying global normalization to each subject...\")\n",
        "subject_embeddings_normalized = {}\n",
        "\n",
        "for subject_id, categories in tqdm(subject_embeddings.items(), desc=\"Normalizing\"):\n",
        "    subject_embeddings_normalized[subject_id] = {}\n",
        "    \n",
        "    for cat, embedding in categories.items():\n",
        "        # Apply global normalization: (x - global_mean) / global_std\n",
        "        normalized_embedding = (embedding - global_mean) / global_std\n",
        "        # Flatten to ensure 1D array (in case embedding has shape (1, 512) instead of (512,))\n",
        "        normalized_embedding = normalized_embedding.flatten()\n",
        "        subject_embeddings_normalized[subject_id][cat] = normalized_embedding\n",
        "\n",
        "print(f\"Normalized embeddings for {len(subject_embeddings_normalized)} subjects using global statistics\")\n",
        "\n",
        "## Organize Categories and Apply Hierarchical Clustering\n",
        "\n",
        "# Load category types for organization\n",
        "if cdi_path.exists():\n",
        "    category_types = load_category_types(cdi_path)\n",
        "else:\n",
        "    print(f\"Warning: CDI path {cdi_path} not found. Skipping category organization.\")\n",
        "    category_types = {}\n",
        "\n",
        "# Get all unique categories across all subjects (needed for organization)\n",
        "all_categories = set()\n",
        "for subject_id, categories in subject_embeddings_normalized.items():\n",
        "    all_categories.update(categories.keys())\n",
        "\n",
        "all_categories = sorted(list(all_categories))\n",
        "print(f\"Total unique categories across all subjects: {len(all_categories)}\")\n",
        "\n",
        "# Organize categories by broad types and apply hierarchical clustering\n",
        "print(\"\\nOrganizing categories by type and applying hierarchical clustering...\")\n",
        "\n",
        "# Get a representative set of embeddings for clustering (use first subject with most categories)\n",
        "# We'll use the average embeddings across all subjects for each category\n",
        "representative_embeddings = {}\n",
        "for cat in all_categories:\n",
        "    cat_embeddings = []\n",
        "    for subject_id, categories in subject_embeddings_normalized.items():\n",
        "        if cat in categories:\n",
        "            cat_embeddings.append(categories[cat])\n",
        "    if len(cat_embeddings) > 0:\n",
        "        # Average across subjects for this category\n",
        "        representative_embeddings[cat] = np.mean(cat_embeddings, axis=0)\n",
        "\n",
        "# Organize by type\n",
        "organized = {\n",
        "    'animals': [],\n",
        "    'bodyparts': [],\n",
        "    'big_objects': [],\n",
        "    'small_objects': [],\n",
        "    'others': []\n",
        "}\n",
        "\n",
        "for cat in all_categories:\n",
        "    if cat not in category_types:\n",
        "        organized['others'].append(cat)\n",
        "        continue\n",
        "    \n",
        "    types = category_types[cat]\n",
        "    if types['is_animate']:\n",
        "        organized['animals'].append(cat)\n",
        "    elif types['is_bodypart']:\n",
        "        organized['bodyparts'].append(cat)\n",
        "    elif types['is_big']:\n",
        "        organized['big_objects'].append(cat)\n",
        "    elif types['is_small']:\n",
        "        organized['small_objects'].append(cat)\n",
        "    else:\n",
        "        organized['others'].append(cat)\n",
        "\n",
        "print(f\"  Organized into: {len(organized['animals'])} animals, {len(organized['bodyparts'])} bodyparts, \"\n",
        "      f\"{len(organized['big_objects'])} big objects, {len(organized['small_objects'])} small objects, \"\n",
        "      f\"{len(organized['others'])} others\")\n",
        "\n",
        "# Apply hierarchical clustering within each group\n",
        "if use_clustering:\n",
        "    print(\"\\nApplying hierarchical clustering within groups...\")\n",
        "    for key in organized:\n",
        "        if len(organized[key]) > 1:\n",
        "            # Filter to categories that have representative embeddings\n",
        "            group_cats = [cat for cat in organized[key] if cat in representative_embeddings]\n",
        "            if len(group_cats) > 1:\n",
        "                print(f\"  Clustering {key} ({len(group_cats)} categories)...\")\n",
        "                organized[key], _ = cluster_categories_within_group(\n",
        "                    group_cats,\n",
        "                    representative_embeddings,\n",
        "                    save_dendrogram=save_dendrograms,\n",
        "                    output_dir=output_dir,\n",
        "                    group_name=key\n",
        "                )\n",
        "            else:\n",
        "                organized[key] = group_cats\n",
        "        else:\n",
        "            organized[key] = [cat for cat in organized[key] if cat in representative_embeddings]\n",
        "else:\n",
        "    for key in organized:\n",
        "        organized[key] = sorted([cat for cat in organized[key] if cat in representative_embeddings])\n",
        "\n",
        "# Create ordered list of categories\n",
        "ordered_categories = (\n",
        "    organized['animals'] +\n",
        "    organized['bodyparts'] +\n",
        "    organized['big_objects'] +\n",
        "    organized['small_objects'] +\n",
        "    organized['others']\n",
        ")\n",
        "\n",
        "print(f\"\\nFinal ordered category list: {len(ordered_categories)} categories\")\n",
        "\n",
        "def compute_subject_rdm(subject_embeddings_dict, categories_list):\n",
        "    \"\"\"\n",
        "    Compute RDM for a single subject.\n",
        "    \n",
        "    Args:\n",
        "        subject_embeddings_dict: dict[category] = embedding array (should be normalized)\n",
        "        categories_list: list of categories to include (in order)\n",
        "    \n",
        "    Returns:\n",
        "        rdm: numpy array of shape (n_categories, n_categories)\n",
        "        available_categories: list of categories actually present\n",
        "    \"\"\"\n",
        "    # Filter to categories that exist for this subject\n",
        "    available_categories = [cat for cat in categories_list if cat in subject_embeddings_dict]\n",
        "    \n",
        "    if len(available_categories) < 2:\n",
        "        return None, available_categories\n",
        "    \n",
        "    # Build embedding matrix (already normalized)\n",
        "    # Flatten each embedding to ensure 1D (in case they have shape (1, 512) instead of (512,))\n",
        "    embedding_matrix = np.array([subject_embeddings_dict[cat].flatten() for cat in available_categories])\n",
        "    \n",
        "    # Ensure 2D shape: (n_categories, embedding_dim)\n",
        "    if embedding_matrix.ndim != 2:\n",
        "        raise ValueError(f\"Expected 2D embedding matrix, got shape {embedding_matrix.shape}\")\n",
        "    \n",
        "    # Compute cosine similarity\n",
        "    similarity_matrix = cosine_similarity(embedding_matrix)\n",
        "    \n",
        "    # Convert to distance (RDM)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    np.fill_diagonal(distance_matrix, 0)  # Ensure diagonal is 0\n",
        "    \n",
        "    # Make symmetric (in case of numerical errors)\n",
        "    distance_matrix = (distance_matrix + distance_matrix.T) / 2\n",
        "    \n",
        "    return distance_matrix, available_categories\n",
        "\n",
        "# Compute RDMs for each subject using normalized embeddings\n",
        "# Note: all_categories is already defined in the organization cell above\n",
        "subject_rdms = {}\n",
        "subject_rdm_categories = {}\n",
        "\n",
        "for subject_id, categories in tqdm(subject_embeddings_normalized.items(), desc=\"Computing RDMs\"):\n",
        "    if len(categories) < min_categories_per_subject:\n",
        "        continue\n",
        "    \n",
        "    rdm, available_cats = compute_subject_rdm(categories, all_categories)\n",
        "    \n",
        "    if rdm is not None:\n",
        "        subject_rdms[subject_id] = rdm\n",
        "        subject_rdm_categories[subject_id] = available_cats\n",
        "\n",
        "print(f\"\\nComputed RDMs for {len(subject_rdms)} subjects\")\n",
        "print(f\"  (Excluded {len(subject_embeddings_normalized) - len(subject_rdms)} subjects with < {min_categories_per_subject} categories)\")\n",
        "\n",
        "# Reorganize each subject's RDM according to the new ordering\n",
        "print(\"\\nReorganizing individual subject RDMs according to new category ordering...\")\n",
        "subject_rdms_reorganized = {}\n",
        "subject_rdm_categories_reorganized = {}\n",
        "subject_group_boundaries = {}  # Store group boundaries for visual separators\n",
        "\n",
        "for subject_id in tqdm(subject_rdms.keys(), desc=\"Reorganizing RDMs\"):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    # Create mapping from old index to new index (only for categories present in this subject)\n",
        "    old_to_new_index = {cat: i for i, cat in enumerate(available_cats)}\n",
        "    \n",
        "    # Get the ordered list of categories for this subject (subset of ordered_categories)\n",
        "    subject_ordered_cats = [cat for cat in ordered_categories if cat in available_cats]\n",
        "    \n",
        "    # Create new indices for reorganized RDM\n",
        "    new_indices = [available_cats.index(cat) for cat in subject_ordered_cats]\n",
        "    \n",
        "    # Reorganize the RDM\n",
        "    rdm_reorganized = rdm[np.ix_(new_indices, new_indices)]\n",
        "    \n",
        "    # Compute group boundaries for this subject\n",
        "    group_boundaries = []\n",
        "    current_idx = 0\n",
        "    for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "        group_cats = [cat for cat in organized[group_name] if cat in subject_ordered_cats]\n",
        "        if len(group_cats) > 0:\n",
        "            group_start = current_idx\n",
        "            group_end = current_idx + len(group_cats)\n",
        "            group_boundaries.append({\n",
        "                'name': group_name,\n",
        "                'start': group_start,\n",
        "                'end': group_end,\n",
        "                'categories': group_cats\n",
        "            })\n",
        "            current_idx = group_end\n",
        "    \n",
        "    subject_rdms_reorganized[subject_id] = rdm_reorganized\n",
        "    subject_rdm_categories_reorganized[subject_id] = subject_ordered_cats\n",
        "    subject_group_boundaries[subject_id] = group_boundaries\n",
        "\n",
        "# Update the main dictionaries\n",
        "subject_rdms = subject_rdms_reorganized\n",
        "subject_rdm_categories = subject_rdm_categories_reorganized\n",
        "\n",
        "print(f\"Reorganized RDMs for {len(subject_rdms)} subjects\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Individual Subject RDMs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Individual Subject RDMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting 32 individual subject RDMs...\n",
            "Color scale range: [0.2053, 1.4904]\n",
            "\n",
            "Saved all individual RDM visualization to individual_subject_rdms/all_individual_rdms.png\n",
            "Saved all individual RDM visualization (coolwarm) to individual_subject_rdms/all_individual_rdms_coolwarm.png\n",
            "\n",
            "Saving individual RDM plots...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving individual RDMs:  69%|██████▉   | 22/32 [03:13<01:21,  8.19s/it]"
          ]
        }
      ],
      "source": [
        "## Visualize All Individual Subject RDMs\n",
        "\n",
        "# Plot all individual subject RDMs in a grid\n",
        "n_subjects = len(subject_rdms)\n",
        "subject_ids = list(subject_rdms.keys())\n",
        "\n",
        "# Calculate grid dimensions\n",
        "n_cols = 6  # Number of columns\n",
        "n_rows = int(np.ceil(n_subjects / n_cols))\n",
        "\n",
        "# Create figure with appropriate size\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "axes = axes.flatten() if n_subjects > 1 else [axes]\n",
        "\n",
        "# Find global min/max for consistent color scale across all RDMs\n",
        "all_rdm_values = []\n",
        "for rdm in subject_rdms.values():\n",
        "    all_rdm_values.extend(rdm.flatten())\n",
        "vmin = np.percentile(all_rdm_values, 1)  # Use 1st percentile to exclude outliers\n",
        "vmax = np.percentile(all_rdm_values, 99)  # Use 99th percentile to exclude outliers\n",
        "\n",
        "print(f\"Plotting {n_subjects} individual subject RDMs...\")\n",
        "print(f\"Color scale range: [{vmin:.4f}, {vmax:.4f}]\")\n",
        "\n",
        "for idx, subject_id in enumerate(subject_ids):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    im = ax.imshow(rdm, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    ax.set_title(f\"{subject_id}\\n({len(categories)} cats)\", fontsize=9, pad=5)\n",
        "    ax.set_xlabel('Category', fontsize=7)\n",
        "    ax.set_ylabel('Category', fontsize=7)\n",
        "    ax.tick_params(labelsize=6)\n",
        "    \n",
        "    # Add colorbar for each subplot\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(n_subjects, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle(f'All Individual Subject RDMs (n={n_subjects})', fontsize=16, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"all_individual_rdms.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"\\nSaved all individual RDM visualization to {output_dir / 'all_individual_rdms.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Also create a version with coolwarm colormap\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "axes = axes.flatten() if n_subjects > 1 else [axes]\n",
        "\n",
        "for idx, subject_id in enumerate(subject_ids):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    im = ax.imshow(rdm, cmap='coolwarm', aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    ax.set_title(f\"{subject_id}\\n({len(categories)} cats)\", fontsize=9, pad=5)\n",
        "    ax.set_xlabel('Category', fontsize=7)\n",
        "    ax.set_ylabel('Category', fontsize=7)\n",
        "    ax.tick_params(labelsize=6)\n",
        "    \n",
        "    # Add colorbar for each subplot\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(n_subjects, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle(f'All Individual Subject RDMs (n={n_subjects}) - Coolwarm', fontsize=16, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"all_individual_rdms_coolwarm.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved all individual RDM visualization (coolwarm) to {output_dir / 'all_individual_rdms_coolwarm.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Save each individual RDM separately with category names as axis labels\n",
        "print(\"\\nSaving individual RDM plots...\")\n",
        "individual_rdm_dir = output_dir / \"individual_rdm_plots\"\n",
        "individual_rdm_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Find global min/max for consistent color scale\n",
        "all_rdm_values = []\n",
        "for rdm in subject_rdms.values():\n",
        "    all_rdm_values.extend(rdm.flatten())\n",
        "vmin = np.percentile(all_rdm_values, 1)\n",
        "vmax = np.percentile(all_rdm_values, 99)\n",
        "\n",
        "for subject_id in tqdm(subject_rdms.keys(), desc=\"Saving individual RDMs\"):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    # Determine figure size based on number of categories\n",
        "    n_cats = len(categories)\n",
        "    fig_size = max(10, n_cats * 0.3)\n",
        "    \n",
        "    # Set font size for category labels (adaptive) - much larger for readability\n",
        "    if n_cats <= 50:\n",
        "        label_fontsize = 12\n",
        "        tick_fontsize = 20\n",
        "    elif n_cats <= 100:\n",
        "        label_fontsize = 10\n",
        "        tick_fontsize = 18\n",
        "    else:\n",
        "        label_fontsize = 8\n",
        "        tick_fontsize = 16\n",
        "    \n",
        "    # Create figure with viridis colormap\n",
        "    fig, ax = plt.subplots(figsize=(fig_size, fig_size))\n",
        "    im = ax.imshow(rdm, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    \n",
        "    # Add visual separators between category groups\n",
        "    group_boundaries = subject_group_boundaries.get(subject_id, [])\n",
        "    for boundary in group_boundaries:\n",
        "        # Draw vertical line\n",
        "        if boundary['start'] > 0:  # Don't draw line at the very start\n",
        "            ax.axvline(x=boundary['start'] - 0.5, color='white', linewidth=2, linestyle='--', alpha=0.7)\n",
        "        # Draw horizontal line\n",
        "        if boundary['start'] > 0:  # Don't draw line at the very start\n",
        "            ax.axhline(y=boundary['start'] - 0.5, color='white', linewidth=2, linestyle='--', alpha=0.7)\n",
        "    \n",
        "    # Set category names as axis labels\n",
        "    ax.set_xticks(range(len(categories)))\n",
        "    ax.set_yticks(range(len(categories)))\n",
        "    ax.set_xticklabels(categories, rotation=90, ha='right', fontsize=tick_fontsize)\n",
        "    ax.set_yticklabels(categories, fontsize=tick_fontsize)\n",
        "    \n",
        "    ax.set_xlabel('Category', fontsize=label_fontsize)\n",
        "    ax.set_ylabel('Category', fontsize=label_fontsize)\n",
        "    ax.set_title(f'RDM: {subject_id}\\n({n_cats} categories)', fontsize=14, pad=10)\n",
        "    \n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    cbar.set_label('Distance (1 - Cosine Similarity)', fontsize=12)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save as PNG only\n",
        "    output_path_png = individual_rdm_dir / f\"rdm_{subject_id}.png\"\n",
        "    plt.savefig(output_path_png, dpi=200, bbox_inches='tight')\n",
        "    \n",
        "    plt.close()\n",
        "    \n",
        "    # Create and save individual dendrogram for this subject\n",
        "    if len(categories) > 1:\n",
        "        # Get embeddings for this subject's categories\n",
        "        subject_embeddings = {cat: subject_embeddings_normalized[subject_id][cat] \n",
        "                             for cat in categories if cat in subject_embeddings_normalized[subject_id]}\n",
        "        \n",
        "        if len(subject_embeddings) > 1:\n",
        "            # Build embedding matrix\n",
        "            embedding_matrix = np.array([subject_embeddings[cat].flatten() for cat in categories])\n",
        "            \n",
        "            # Normalize embeddings\n",
        "            normalized_embeddings = (embedding_matrix - embedding_matrix.mean(axis=0)) / (embedding_matrix.std(axis=0) + 1e-10)\n",
        "            \n",
        "            # Compute distance matrix\n",
        "            similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "            distance_matrix = 1 - similarity_matrix\n",
        "            np.fill_diagonal(distance_matrix, 0)\n",
        "            \n",
        "            # Convert to condensed form for linkage\n",
        "            condensed_distances = squareform(distance_matrix)\n",
        "            \n",
        "            # Perform hierarchical clustering\n",
        "            linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "            \n",
        "            # Get optimal leaf ordering\n",
        "            try:\n",
        "                linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "            # Create dendrogram\n",
        "            plt.figure(figsize=(max(16, len(categories) * 0.5), 10))\n",
        "            dendrogram(linkage_matrix, \n",
        "                      labels=categories,\n",
        "                      leaf_rotation=90,\n",
        "                      leaf_font_size=max(8, min(14, 200 // len(categories))))\n",
        "            plt.title(f'Individual Subject Dendrogram: {subject_id}\\n({len(categories)} categories)',\n",
        "                     fontsize=16, pad=20)\n",
        "            plt.xlabel('Category', fontsize=14)\n",
        "            plt.ylabel('Distance', fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            \n",
        "            # Save dendrogram\n",
        "            dendrogram_dir = individual_rdm_dir / \"dendrograms\"\n",
        "            dendrogram_dir.mkdir(exist_ok=True, parents=True)\n",
        "            dendrogram_path = dendrogram_dir / f\"dendrogram_{subject_id}.png\"\n",
        "            plt.savefig(dendrogram_path, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "            plt.close()\n",
        "\n",
        "print(f\"\\nSaved {len(subject_rdms)} individual RDM plots to {individual_rdm_dir}\")\n",
        "print(f\"  Each subject has 1 RDM file: rdm_{subject_id}.png\")\n",
        "print(f\"  Individual dendrograms saved to {individual_rdm_dir / 'dendrograms'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving individual subject RDMs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving RDMs: 100%|██████████| 32/32 [00:01<00:00, 27.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved RDMs to individual_subject_rdms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Save RDMs\n",
        "print(\"Saving individual subject RDMs...\")\n",
        "\n",
        "for subject_id, rdm in tqdm(subject_rdms.items(), desc=\"Saving RDMs\"):\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    # Save as numpy array\n",
        "    np.save(output_dir / f\"rdm_{subject_id}.npy\", rdm)\n",
        "    \n",
        "    # Save as CSV with category labels\n",
        "    rdm_df = pd.DataFrame(rdm, index=categories, columns=categories)\n",
        "    rdm_df.to_csv(output_dir / f\"rdm_{subject_id}.csv\")\n",
        "    \n",
        "    # Save metadata\n",
        "    metadata = {\n",
        "        'subject_id': subject_id,\n",
        "        'n_categories': len(categories),\n",
        "        'categories': categories,\n",
        "        'mean_distance': float(rdm.mean()),\n",
        "        'std_distance': float(rdm.std())\n",
        "    }\n",
        "    \n",
        "    metadata_df = pd.DataFrame([metadata])\n",
        "    metadata_df.to_csv(output_dir / f\"metadata_{subject_id}.csv\", index=False)\n",
        "\n",
        "print(f\"\\nSaved RDMs to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary statistics:\n",
            "       n_categories  mean_distance  std_distance  min_distance  max_distance\n",
            "count     32.000000      32.000000     32.000000     32.000000     32.000000\n",
            "mean     145.343750       0.965700      0.267005      0.038118      1.607634\n",
            "std       23.350913       0.018806      0.015772      0.017234      0.058626\n",
            "min       55.000000       0.914233      0.239251      0.006570      1.408912\n",
            "25%      140.750000       0.958276      0.249782      0.026638      1.575900\n",
            "50%      154.500000       0.969105      0.270802      0.039205      1.623180\n",
            "75%      160.000000       0.980300      0.279752      0.048356      1.636637\n",
            "max      162.000000       0.990634      0.290838      0.092241      1.689233\n",
            "\n",
            "Saved summary to individual_subject_rdms/summary_statistics.csv\n"
          ]
        }
      ],
      "source": [
        "# Create summary dataframe\n",
        "summary_data = []\n",
        "\n",
        "for subject_id, rdm in subject_rdms.items():\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    summary_data.append({\n",
        "        'subject_id': subject_id,\n",
        "        'n_categories': len(categories),\n",
        "        'mean_distance': float(rdm.mean()),\n",
        "        'std_distance': float(rdm.std()),\n",
        "        'min_distance': float(rdm[rdm > 0].min()) if (rdm > 0).any() else np.nan,\n",
        "        'max_distance': float(rdm.max())\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df = summary_df.sort_values('n_categories', ascending=False)\n",
        "summary_df.to_csv(output_dir / \"summary_statistics.csv\", index=False)\n",
        "\n",
        "print(\"Summary statistics:\")\n",
        "print(summary_df.describe())\n",
        "print(f\"\\nSaved summary to {output_dir / 'summary_statistics.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Sample RDMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved sample RDM visualization to individual_subject_rdms/sample_rdms.png\n"
          ]
        }
      ],
      "source": [
        "# Visualize a few sample RDMs\n",
        "n_samples = min(6, len(subject_rdms))\n",
        "sample_subjects = list(subject_rdms.keys())[:n_samples]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, subject_id in enumerate(sample_subjects):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    categories = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    im = ax.imshow(rdm, cmap='viridis', aspect='auto')\n",
        "    ax.set_title(f\"{subject_id}\\n({len(categories)} categories)\", fontsize=10)\n",
        "    ax.set_xlabel('Category')\n",
        "    ax.set_ylabel('Category')\n",
        "    plt.colorbar(im, ax=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"sample_rdms.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved sample RDM visualization to {output_dir / 'sample_rdms.png'}\")\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Density Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved data density analysis to individual_subject_rdms/data_density_analysis.png\n"
          ]
        }
      ],
      "source": [
        "# Analyze data density across subjects\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Category count distribution\n",
        "axes[0].hist([len(cats) for cats in subject_rdm_categories.values()], bins=20, edgecolor='black')\n",
        "axes[0].set_xlabel('Number of Categories per Subject')\n",
        "axes[0].set_ylabel('Number of Subjects')\n",
        "axes[0].set_title('Data Density: Categories per Subject')\n",
        "axes[0].axvline(min_categories_per_subject, color='red', linestyle='--', label=f'Min threshold ({min_categories_per_subject})')\n",
        "axes[0].legend()\n",
        "\n",
        "# Mean distance vs category count\n",
        "mean_distances = [subject_rdms[sid].mean() for sid in subject_rdms.keys()]\n",
        "n_categories = [len(subject_rdm_categories[sid]) for sid in subject_rdms.keys()]\n",
        "\n",
        "axes[1].scatter(n_categories, mean_distances, alpha=0.6)\n",
        "axes[1].set_xlabel('Number of Categories')\n",
        "axes[1].set_ylabel('Mean RDM Distance')\n",
        "axes[1].set_title('RDM Distance vs Data Density')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"data_density_analysis.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved data density analysis to {output_dir / 'data_density_analysis.png'}\")\n",
        "plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vislearnlabpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
