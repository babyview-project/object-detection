{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2: Filter, Normalize, and Reorganize RDM\n",
        "\n",
        "This notebook filters out low-quality categories and reorganizes the RDM by category type with optional hierarchical clustering.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This step:\n",
        "1. Loads category average embeddings from Step 1\n",
        "2. Filters categories based on inclusion/exclusion lists\n",
        "3. Normalize, computes and saves filtered RDM matrices\n",
        "4. Organizes categories by type (animals, bodyparts, big objects, small objects)\n",
        "5. Optionally applies hierarchical clustering within each group\n",
        "6. Saves reorganized RDM matrices\n",
        "7. Creates visualizations\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "This step requires:\n",
        "- Output from Step 1 (CLIP or DINOV3 average category embeddings)\n",
        "- CDI words CSV file for category type information\n",
        "- Inclusion or exclusion list file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
        "from scipy.spatial.distance import squareform\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set matplotlib backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded!\n"
          ]
        }
      ],
      "source": [
        "def load_category_types(cdi_path):\n",
        "    \"\"\"Load category type information from CDI words CSV\"\"\"\n",
        "    print(f\"Loading category types from {cdi_path}...\")\n",
        "    cdi_df = pd.read_csv(cdi_path)\n",
        "    \n",
        "    category_types = {}\n",
        "    for _, row in cdi_df.iterrows():\n",
        "        category_types[row['uni_lemma']] = {\n",
        "            'is_animate': bool(row.get('is_animate', 0)),\n",
        "            'is_bodypart': bool(row.get('is_bodypart', 0)),\n",
        "            'is_small': bool(row.get('is_small', 0)),\n",
        "            'is_big': bool(row.get('is_big', 0))\n",
        "        }\n",
        "    \n",
        "    print(f\"Loaded type information for {len(category_types)} categories\")\n",
        "    return category_types\n",
        "\n",
        "def cluster_categories_within_group(group_categories, cat_to_embedding, save_dendrogram=False, output_dir=None, group_name=None):\n",
        "    \"\"\"\n",
        "    Perform hierarchical clustering within a group of categories.\n",
        "    \n",
        "    Args:\n",
        "        group_categories: List of category names in the group\n",
        "        cat_to_embedding: Dictionary mapping category names to embeddings\n",
        "        save_dendrogram: Whether to save dendrogram plot (default: False)\n",
        "        output_dir: Output directory for saving dendrogram (required if save_dendrogram=True)\n",
        "        group_name: Name of the group for saving dendrogram (required if save_dendrogram=True)\n",
        "    \n",
        "    Returns:\n",
        "        List of category names reordered according to clustering dendrogram\n",
        "    \"\"\"\n",
        "    if len(group_categories) <= 1:\n",
        "        return group_categories, None\n",
        "    \n",
        "    # Get embeddings for this group\n",
        "    group_embeddings = np.array([cat_to_embedding[cat] for cat in group_categories])\n",
        "    \n",
        "    # Normalize embeddings\n",
        "    normalized_embeddings = (group_embeddings - group_embeddings.mean(axis=0)) / (group_embeddings.std(axis=0) + 1e-10)\n",
        "    \n",
        "    # Compute distance matrix (1 - cosine similarity)\n",
        "    similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    np.fill_diagonal(distance_matrix, 0)\n",
        "    \n",
        "    # Convert to condensed form for linkage\n",
        "    condensed_distances = squareform(distance_matrix)\n",
        "    \n",
        "    # Perform hierarchical clustering\n",
        "    linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "    \n",
        "    # Get optimal leaf ordering for better visualization\n",
        "    try:\n",
        "        linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "    except:\n",
        "        # If optimal leaf ordering fails, use original linkage\n",
        "        pass\n",
        "    \n",
        "    # Extract the order from the dendrogram\n",
        "    dendro_dict = dendrogram(linkage_matrix, no_plot=True)\n",
        "    leaf_order = dendro_dict['leaves']\n",
        "    \n",
        "    # Reorder categories according to clustering\n",
        "    clustered_categories = [group_categories[i] for i in leaf_order]\n",
        "    \n",
        "    # Save dendrogram if requested\n",
        "    if save_dendrogram and output_dir is not None and group_name is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        dendrogram(linkage_matrix, \n",
        "                  labels=group_categories,\n",
        "                  leaf_rotation=90,\n",
        "                  leaf_font_size=10)\n",
        "        plt.title(f'Hierarchical Clustering Dendrogram: {group_name.upper()}\\n({len(group_categories)} categories)',\n",
        "                 fontsize=16, pad=20)\n",
        "        plt.xlabel('Category', fontsize=12)\n",
        "        plt.ylabel('Distance', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save as PNG\n",
        "        output_path_png = output_dir / f'dendrogram_{group_name}.png'\n",
        "        plt.savefig(output_path_png, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_png}\")\n",
        "        \n",
        "        # Save as PDF\n",
        "        output_path_pdf = output_dir / f'dendrogram_{group_name}.pdf'\n",
        "        plt.savefig(output_path_pdf, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_pdf}\")\n",
        "        \n",
        "        plt.close()\n",
        "    \n",
        "    return clustered_categories, linkage_matrix\n",
        "\n",
        "print(\"Helper functions loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "**Please update the paths below according to your setup:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded. Please review and update paths as needed.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - UPDATE THESE PATHS FOR YOUR SETUP\n",
        "# ============================================================================\n",
        "\n",
        "# Input: Path to .npz file containing category average embeddings from Step 1\n",
        "INPUT_EMBEDDING_PATH = \"./bv_dino_rdm_results_26/category_average_embeddings.npz\"  # Direct path to .npz file (e.g., \"things_clip_embeddings.npz\")\n",
        "\n",
        "# Output directory prefix (e.g., \"bv_clip\", \"bv_dinov3\", \"things_clip\", \"things_dinov3\")\n",
        "# The output directory will be constructed as: {OUTPUT_DIR_PREFIX}_filtered_zscored_hierarchical_{n_cats}cats/\n",
        "OUTPUT_DIR_PREFIX = \"bv_dino\"  # Change this for different datasets/models\n",
        "\n",
        "# CDI words CSV file (required for category type organization)\n",
        "CDI_PATH = \"../../data/cdi_words.csv\"\n",
        "\n",
        "# Filtering options\n",
        "EXCLUSION_FILE = None  # Path to text file with categories to exclude (one per line), or None\n",
        "INCLUSION_FILE = \"../../data/things_bv_overlap_categories_exclude_zero_precisions.txt\"  # Path to text file with categories to include (one per line), or None\n",
        "\n",
        "# Processing options\n",
        "USE_CLUSTERING = True  # Enable hierarchical clustering within category groups\n",
        "SAVE_DENDROGRAMS = True  # Save dendrogram plots for each category group\n",
        "\n",
        "print(\"Configuration loaded. Please review and update paths as needed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Load average category embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 1/8] Loading category averages from bv_dino_rdm_results_26/category_average_embeddings.npz...\n",
            "  Found categories under key 'categories'\n",
            "  Loaded 291 categories with embeddings of shape (291, 768)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load category average embeddings from Step 1\n",
        "npz_path = Path(INPUT_EMBEDDING_PATH)\n",
        "if not npz_path.exists():\n",
        "    raise FileNotFoundError(f\"{npz_path} not found. Please run Step 1 first or check the path.\")\n",
        "\n",
        "print(f\"\\n[Step 1/8] Loading category averages from {npz_path}...\")\n",
        "data = np.load(npz_path)\n",
        "embeddings = data['embeddings']\n",
        "\n",
        "# Handle different key names (categories, category, labels, label)\n",
        "available_keys = list(data.keys())\n",
        "categories = None\n",
        "for key_name in ['categories', 'category', 'labels', 'label']:\n",
        "    if key_name in available_keys:\n",
        "        categories = data[key_name]\n",
        "        # Convert numpy array of strings to list\n",
        "        if categories.dtype == 'object':\n",
        "            categories = [str(cat) for cat in categories]\n",
        "        else:\n",
        "            categories = categories.tolist()\n",
        "        print(f\"  Found categories under key '{key_name}'\")\n",
        "        break\n",
        "\n",
        "if categories is None:\n",
        "    raise KeyError(f\"Expected 'categories', 'category', 'labels', or 'label' key in NPZ file. Available keys: {available_keys}\")\n",
        "\n",
        "print(f\"  Loaded {len(categories)} categories with embeddings of shape {embeddings.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Filter categories based on inclusion/exclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 2/8] Filtering categories...\n",
            "  Loading included categories from ../../data/things_bv_overlap_categories_exclude_zero_precisions.txt...\n",
            "  Found 163 categories to include\n",
            "  After filtering: 163 categories\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Filter categories based on inclusion/exclusion lists\n",
        "print(f\"\\n[Step 2/8] Filtering categories...\")\n",
        "if INCLUSION_FILE:\n",
        "    print(f\"  Loading included categories from {INCLUSION_FILE}...\")\n",
        "    with open(INCLUSION_FILE, 'r') as f:\n",
        "        included_categories = set(line.strip() for line in f if line.strip())\n",
        "    print(f\"  Found {len(included_categories)} categories to include\")\n",
        "    excluded_categories = set()\n",
        "elif EXCLUSION_FILE:\n",
        "    print(f\"  Loading excluded categories from {EXCLUSION_FILE}...\")\n",
        "    with open(EXCLUSION_FILE, 'r') as f:\n",
        "        excluded_categories = set(line.strip() for line in f if line.strip())\n",
        "    print(f\"  Found {len(excluded_categories)} categories to exclude\")\n",
        "    included_categories = None\n",
        "else:\n",
        "    print(\"  No filtering file specified. Using all categories.\")\n",
        "    included_categories = None\n",
        "    excluded_categories = set()\n",
        "\n",
        "# Filter categories\n",
        "if included_categories is not None:\n",
        "    filtered_indices = [i for i, cat in enumerate(categories) if cat in included_categories]\n",
        "    filtered_categories = [categories[i] for i in filtered_indices]\n",
        "    filtered_embeddings = embeddings[filtered_indices]\n",
        "    print(f\"  After filtering: {len(filtered_categories)} categories\")\n",
        "else:\n",
        "    filtered_indices = [i for i, cat in enumerate(categories) if cat not in excluded_categories]\n",
        "    filtered_categories = [categories[i] for i in filtered_indices]\n",
        "    filtered_embeddings = embeddings[filtered_indices]\n",
        "    print(f\"  After filtering: {len(filtered_categories)} categories (excluded {len(excluded_categories)})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Normalize embeddings (z-score normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 3/8] Normalizing filtered embeddings...\n",
            "  Normalized embeddings shape: (163, 768)\n",
            "  Sorting categories alphabetically...\n",
            "  Categories and embeddings sorted alphabetically\n",
            "  Saved alphabetically sorted normalized embeddings to bv_dino_filtered_zscored_hierarchical_163cats/normalized_filtered_embeddings.csv\n",
            "    CSV contains 163 categories with 768 embedding dimensions\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Normalize embeddings (z-score normalization)\n",
        "print(f\"\\n[Step 3/8] Normalizing filtered embeddings...\")\n",
        "normalized_filtered_embeddings = (filtered_embeddings - filtered_embeddings.mean(axis=0)) / (filtered_embeddings.std(axis=0) + 1e-10)\n",
        "print(f\"  Normalized embeddings shape: {normalized_filtered_embeddings.shape}\")\n",
        "\n",
        "# Sort categories alphabetically and reorder embeddings to match\n",
        "print(f\"  Sorting categories alphabetically...\")\n",
        "sorted_category_indices = sorted(range(len(filtered_categories)), key=lambda i: filtered_categories[i])\n",
        "sorted_filtered_categories = [filtered_categories[i] for i in sorted_category_indices]\n",
        "sorted_normalized_filtered_embeddings = normalized_filtered_embeddings[sorted_category_indices]\n",
        "\n",
        "# Update filtered_categories and normalized_filtered_embeddings to sorted versions\n",
        "filtered_categories = sorted_filtered_categories\n",
        "normalized_filtered_embeddings = sorted_normalized_filtered_embeddings\n",
        "print(f\"  Categories and embeddings sorted alphabetically\")\n",
        "\n",
        "# Construct output directory name based on prefix\n",
        "n_cats = len(filtered_categories)\n",
        "output_dir_name = f\"{OUTPUT_DIR_PREFIX}_filtered_zscored_hierarchical_{n_cats}cats\"\n",
        "output_dir = Path(output_dir_name)\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save normalized embeddings as CSV with category names\n",
        "# Create DataFrame with category names as index and embedding dimensions as columns\n",
        "embedding_df = pd.DataFrame(\n",
        "    normalized_filtered_embeddings,\n",
        "    index=filtered_categories,\n",
        "    columns=[f'dim_{i}' for i in range(normalized_filtered_embeddings.shape[1])]\n",
        ")\n",
        "csv_path = output_dir / 'normalized_filtered_embeddings.csv'\n",
        "embedding_df.to_csv(csv_path)\n",
        "print(f\"  Saved alphabetically sorted normalized embeddings to {csv_path}\")\n",
        "print(f\"    CSV contains {len(filtered_categories)} categories with {normalized_filtered_embeddings.shape[1]} embedding dimensions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Compute RDM matrices on filtered, normalized embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 4/8] Computing RDM matrices on filtered, normalized embeddings...\n",
            "  Computed RDM matrices with shape (163, 163)\n",
            "  Mean distance: 0.9987\n",
            "  Std distance: 0.2037\n",
            "  Saving original (pre-reorganization, alphabetically sorted) matrices to bv_dino_filtered_zscored_hierarchical_163cats...\n",
            "  Saved original similarity and distance matrices\n",
            "  Note: RDM computed before reorganization, sorted alphabetically - will be reordered in Step 8\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Compute RDM matrices on filtered, normalized embeddings (before reorganization)\n",
        "print(f\"\\n[Step 4/8] Computing RDM matrices on filtered, normalized embeddings...\")\n",
        "# Compute similarity and distance matrices using normalized embeddings\n",
        "similarity_matrix_filtered = cosine_similarity(normalized_filtered_embeddings)\n",
        "distance_matrix_filtered = 1 - similarity_matrix_filtered\n",
        "np.fill_diagonal(distance_matrix_filtered, 0)\n",
        "distance_matrix_filtered = (distance_matrix_filtered + distance_matrix_filtered.T) / 2\n",
        "\n",
        "print(f\"  Computed RDM matrices with shape {distance_matrix_filtered.shape}\")\n",
        "print(f\"  Mean distance: {distance_matrix_filtered.mean():.4f}\")\n",
        "print(f\"  Std distance: {distance_matrix_filtered.std():.4f}\")\n",
        "\n",
        "# Sort matrices by alphabetical order of categories\n",
        "sorted_categories = sorted(filtered_categories)\n",
        "sorted_indices = [filtered_categories.index(cat) for cat in sorted_categories]\n",
        "similarity_matrix_sorted = similarity_matrix_filtered[np.ix_(sorted_indices, sorted_indices)]\n",
        "distance_matrix_sorted = distance_matrix_filtered[np.ix_(sorted_indices, sorted_indices)]\n",
        "\n",
        "\n",
        "# Save original matrices (before reorganization) for reference\n",
        "print(f\"  Saving original (pre-reorganization, alphabetically sorted) matrices to {output_dir}...\")\n",
        "np.save(output_dir / 'similarity_matrix_filtered_original.npy', similarity_matrix_sorted)\n",
        "np.save(output_dir / 'distance_matrix_filtered_original.npy', distance_matrix_sorted)\n",
        "\n",
        "sim_df_original = pd.DataFrame(similarity_matrix_sorted, index=sorted_categories, columns=sorted_categories)\n",
        "sim_df_original.to_csv(output_dir / 'similarity_matrix_filtered_original.csv')\n",
        "\n",
        "dist_df_original = pd.DataFrame(distance_matrix_sorted, index=sorted_categories, columns=sorted_categories)\n",
        "dist_df_original.to_csv(output_dir / 'distance_matrix_filtered_original.csv')\n",
        "print(f\"  Saved original similarity and distance matrices\")\n",
        "print(f\"  Note: RDM computed before reorganization, sorted alphabetically - will be reordered in Step 8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Organize categories by type (animals, bodyparts, big objects, small objects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 5/8] Organizing categories by type...\n",
            "Loading category types from ../../data/cdi_words.csv...\n",
            "Loaded type information for 295 categories\n",
            "  Organized into: 19 animals, 14 bodyparts, 32 big objects, 96 small objects, 2 others\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Organize categories by type (animals, bodyparts, big objects, small objects)\n",
        "print(f\"\\n[Step 5/8] Organizing categories by type...\")\n",
        "cdi_path = Path(CDI_PATH)\n",
        "# Output directory already created in Step 4\n",
        "\n",
        "if cdi_path.exists():\n",
        "    category_types = load_category_types(cdi_path)\n",
        "    \n",
        "    # Organize by type\n",
        "    organized = {\n",
        "        'animals': [],\n",
        "        'bodyparts': [],\n",
        "        'big_objects': [],\n",
        "        'small_objects': [],\n",
        "        'others': []\n",
        "    }\n",
        "    \n",
        "    # Use normalized embeddings for the mapping\n",
        "    cat_to_embedding = {cat: emb for cat, emb in zip(filtered_categories, normalized_filtered_embeddings)}\n",
        "    \n",
        "    for cat in filtered_categories:\n",
        "        if cat not in category_types:\n",
        "            organized['others'].append(cat)\n",
        "            continue\n",
        "        \n",
        "        types = category_types[cat]\n",
        "        if types['is_animate']:\n",
        "            organized['animals'].append(cat)\n",
        "        elif types['is_bodypart']:\n",
        "            organized['bodyparts'].append(cat)\n",
        "        elif types['is_big']:\n",
        "            organized['big_objects'].append(cat)\n",
        "        elif types['is_small']:\n",
        "            organized['small_objects'].append(cat)\n",
        "        else:\n",
        "            organized['others'].append(cat)\n",
        "    \n",
        "    print(f\"  Organized into: {len(organized['animals'])} animals, {len(organized['bodyparts'])} bodyparts, \"\n",
        "          f\"{len(organized['big_objects'])} big objects, {len(organized['small_objects'])} small objects, \"\n",
        "          f\"{len(organized['others'])} others\")\n",
        "else:\n",
        "    print(f\"  Warning: CDI path {cdi_path} not found. Skipping organization by type.\")\n",
        "    organized = {'animals': [], 'bodyparts': [], 'big_objects': [], 'small_objects': [], 'others': filtered_categories}\n",
        "    cat_to_embedding = {cat: emb for cat, emb in zip(filtered_categories, normalized_filtered_embeddings)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Optionally apply hierarchical clustering within each group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 6/8] Applying hierarchical clustering within groups...\n",
            "  Clustering animals (19 categories)...\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_animals.png\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_animals.pdf\n",
            "  Clustering bodyparts (14 categories)...\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_bodyparts.png\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_bodyparts.pdf\n",
            "  Clustering big_objects (32 categories)...\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_big_objects.png\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_big_objects.pdf\n",
            "  Clustering small_objects (96 categories)...\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_small_objects.png\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_small_objects.pdf\n",
            "  Clustering others (2 categories)...\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_others.png\n",
            "    Saved dendrogram to bv_dino_filtered_zscored_hierarchical_163cats/dendrogram_others.pdf\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Optionally apply hierarchical clustering within each group\n",
        "print(f\"\\n[Step 6/8] Applying hierarchical clustering within groups...\")\n",
        "if USE_CLUSTERING:\n",
        "    for key in organized:\n",
        "        if len(organized[key]) > 1:\n",
        "            print(f\"  Clustering {key} ({len(organized[key])} categories)...\")\n",
        "            organized[key], _ = cluster_categories_within_group(\n",
        "                organized[key], \n",
        "                cat_to_embedding,\n",
        "                save_dendrogram=SAVE_DENDROGRAMS,\n",
        "                output_dir=output_dir,\n",
        "                group_name=key\n",
        "            )\n",
        "else:\n",
        "    for key in organized:\n",
        "        organized[key] = sorted(organized[key])\n",
        "\n",
        "# Create ordered list\n",
        "ordered_categories = (\n",
        "    organized['animals'] +\n",
        "    organized['bodyparts'] +\n",
        "    organized['big_objects'] +\n",
        "    organized['small_objects'] +\n",
        "    organized['others']\n",
        ")\n",
        "\n",
        "# Save category organization info\n",
        "with open(output_dir / 'category_organization_filtered.txt', 'w') as f:\n",
        "    f.write(\"Category Organization:\\n\")\n",
        "    f.write(\"=\"*60 + \"\\n\")\n",
        "    for key in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "        f.write(f\"\\n{key.replace('_', ' ').title()} ({len(organized[key])}):\\n\")\n",
        "        for cat in organized[key]:\n",
        "            f.write(f\"  {cat}\\n\")\n",
        "\n",
        "with open(output_dir / 'category_names_filtered.txt', 'w') as f:\n",
        "    for cat in ordered_categories:\n",
        "        f.write(f\"{cat}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Compute and save filtered RDM matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 7/8] Reorganizing RDM matrices according to new category ordering...\n",
            "  Reorganized RDM matrices with shape (163, 163)\n",
            "  Saving reorganized matrices to bv_dino_filtered_zscored_hierarchical_163cats...\n",
            "  Saved reorganized similarity and distance matrices\n",
            "  Note: Original (pre-reorganization) matrices saved in Step 4 with '_original' suffix\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Reorganize RDM matrices according to new category ordering\n",
        "print(f\"\\n[Step 7/8] Reorganizing RDM matrices according to new category ordering...\")\n",
        "# Create mapping from old index to new index\n",
        "old_to_new_index = {cat: i for i, cat in enumerate(filtered_categories)}\n",
        "new_indices = [old_to_new_index[cat] for cat in ordered_categories]\n",
        "\n",
        "# Reorganize the matrices (computed in Step 4) according to the new ordering\n",
        "similarity_matrix = similarity_matrix_filtered[np.ix_(new_indices, new_indices)]\n",
        "distance_matrix = distance_matrix_filtered[np.ix_(new_indices, new_indices)]\n",
        "\n",
        "print(f\"  Reorganized RDM matrices with shape {distance_matrix.shape}\")\n",
        "print(f\"  Saving reorganized matrices to {output_dir}...\")\n",
        "np.save(output_dir / 'similarity_matrix_filtered.npy', similarity_matrix)\n",
        "np.save(output_dir / 'distance_matrix_filtered.npy', distance_matrix)\n",
        "\n",
        "sim_df = pd.DataFrame(similarity_matrix, index=ordered_categories, columns=ordered_categories)\n",
        "sim_df.to_csv(output_dir / 'similarity_matrix_filtered.csv')\n",
        "\n",
        "dist_df = pd.DataFrame(distance_matrix, index=ordered_categories, columns=ordered_categories)\n",
        "dist_df.to_csv(output_dir / 'distance_matrix_filtered.csv')\n",
        "print(f\"  Saved reorganized similarity and distance matrices\")\n",
        "print(f\"  Note: Original (pre-reorganization) matrices saved in Step 4 with '_original' suffix\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 8: Create visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 8/8] Creating visualizations...\n",
            "  Saved RDM heatmap to bv_dino_filtered_zscored_hierarchical_163cats/rdm_organized_filtered.png\n",
            "  Saved RDM heatmap to bv_dino_filtered_zscored_hierarchical_163cats/rdm_organized_filtered.pdf\n",
            "  Saved RDM heatmap (coolwarm) to bv_dino_filtered_zscored_hierarchical_163cats/rdm_organized_filtered_coolwarm.png\n",
            "  Saved RDM heatmap (coolwarm) to bv_dino_filtered_zscored_hierarchical_163cats/rdm_organized_filtered_coolwarm.pdf\n",
            "  Computing top similar/dissimilar pairs...\n",
            "\n",
            "============================================================\n",
            "Filtering complete! Results saved to bv_dino_filtered_zscored_hierarchical_163cats\n",
            "============================================================\n",
            "Original categories: 291\n",
            "Filtered categories: 163\n",
            "Mean distance: 0.9987\n",
            "Std distance: 0.2037\n",
            "Min distance: 0.0328\n",
            "Max distance: 1.4313\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Create visualizations\n",
        "print(f\"\\n[Step 8/8] Creating visualizations...\")\n",
        "\n",
        "# Create organized RDM heatmap\n",
        "n_categories = len(ordered_categories)\n",
        "fig_size = max(20, n_categories * 0.5)\n",
        "\n",
        "# Set font size for axis labels (adaptive based on number of categories)\n",
        "# Larger font for fewer categories, smaller but still readable for many categories\n",
        "if n_categories <= 50:\n",
        "    label_fontsize = 14\n",
        "elif n_categories <= 100:\n",
        "    label_fontsize = 12\n",
        "elif n_categories <= 150:\n",
        "    label_fontsize = 10\n",
        "else:\n",
        "    label_fontsize = 9\n",
        "\n",
        "plt.figure(figsize=(fig_size, fig_size))\n",
        "ax = sns.heatmap(distance_matrix, \n",
        "            xticklabels=ordered_categories,\n",
        "            yticklabels=ordered_categories,\n",
        "            cmap='viridis',\n",
        "            vmin=0,\n",
        "            vmax=2,\n",
        "            square=True,\n",
        "            cbar_kws={'label': 'Distance (1 - Cosine Similarity)', 'shrink': 0.8})\n",
        "\n",
        "plt.title(f'{OUTPUT_DIR_PREFIX.replace(\"_\", \" \").title()} Category RDM (Filtered and Organized)', fontsize=24, pad=20)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=label_fontsize)\n",
        "plt.yticks(rotation=0, fontsize=label_fontsize)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'rdm_organized_filtered.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig(output_dir / 'rdm_organized_filtered.pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"  Saved RDM heatmap to {output_dir / 'rdm_organized_filtered.png'}\")\n",
        "print(f\"  Saved RDM heatmap to {output_dir / 'rdm_organized_filtered.pdf'}\")\n",
        "\n",
        "# Create coolwarm colormap version\n",
        "plt.figure(figsize=(fig_size, fig_size))\n",
        "ax = sns.heatmap(distance_matrix, \n",
        "            xticklabels=ordered_categories,\n",
        "            yticklabels=ordered_categories,\n",
        "            cmap='coolwarm',\n",
        "            vmin=0,\n",
        "            vmax=2,\n",
        "            square=True,\n",
        "            cbar_kws={'label': 'Distance (1 - Cosine Similarity)', 'shrink': 0.8})\n",
        "\n",
        "plt.title(f'{OUTPUT_DIR_PREFIX.replace(\"_\", \" \").title()} Category RDM (Filtered and Organized)', fontsize=24, pad=20)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=label_fontsize)\n",
        "plt.yticks(rotation=0, fontsize=label_fontsize)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / 'rdm_organized_filtered_coolwarm.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig(output_dir / 'rdm_organized_filtered_coolwarm.pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"  Saved RDM heatmap (coolwarm) to {output_dir / 'rdm_organized_filtered_coolwarm.png'}\")\n",
        "print(f\"  Saved RDM heatmap (coolwarm) to {output_dir / 'rdm_organized_filtered_coolwarm.pdf'}\")\n",
        "\n",
        "# Find and save top similar/dissimilar pairs\n",
        "print(f\"  Computing top similar/dissimilar pairs...\")\n",
        "# Get upper triangle (excluding diagonal)\n",
        "triu_indices = np.triu_indices_from(distance_matrix, k=1)\n",
        "distances_flat = distance_matrix[triu_indices]\n",
        "pairs_flat = [(ordered_categories[i], ordered_categories[j]) for i, j in zip(triu_indices[0], triu_indices[1])]\n",
        "\n",
        "# Sort by distance (ascending for similar, descending for dissimilar)\n",
        "sorted_indices_similar = np.argsort(distances_flat)\n",
        "sorted_indices_dissimilar = np.argsort(distances_flat)[::-1]\n",
        "\n",
        "for n in [20, 30, 50]:\n",
        "    # Top similar pairs\n",
        "    top_similar = [(pairs_flat[i], distances_flat[i]) for i in sorted_indices_similar[:n]]\n",
        "    with open(output_dir / f'top_{n}_similar_pairs.txt', 'w') as f:\n",
        "        f.write(f\"Top {n} Most Similar Category Pairs:\\n\")\n",
        "        f.write(\"=\"*60 + \"\\n\")\n",
        "        for (cat1, cat2), dist in top_similar:\n",
        "            f.write(f\"{cat1} <-> {cat2}: {dist:.4f}\\n\")\n",
        "    \n",
        "    # Top dissimilar pairs\n",
        "    top_dissimilar = [(pairs_flat[i], distances_flat[i]) for i in sorted_indices_dissimilar[:n]]\n",
        "    with open(output_dir / f'top_{n}_dissimilar_pairs.txt', 'w') as f:\n",
        "        f.write(f\"Top {n} Most Dissimilar Category Pairs:\\n\")\n",
        "        f.write(\"=\"*60 + \"\\n\")\n",
        "        for (cat1, cat2), dist in top_dissimilar:\n",
        "            f.write(f\"{cat1} <-> {cat2}: {dist:.4f}\\n\")\n",
        "    \n",
        "    # Visualize top similar pairs\n",
        "    if n <= 30:  # Only create visualizations for smaller numbers\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "        \n",
        "        # Similar pairs\n",
        "        similar_cats = list(set([cat for pair, _ in top_similar for cat in pair]))\n",
        "        similar_indices = [ordered_categories.index(cat) for cat in similar_cats if cat in ordered_categories]\n",
        "        similar_matrix = distance_matrix[np.ix_(similar_indices, similar_indices)]\n",
        "        \n",
        "        sns.heatmap(similar_matrix, \n",
        "                   xticklabels=[ordered_categories[i] for i in similar_indices],\n",
        "                   yticklabels=[ordered_categories[i] for i in similar_indices],\n",
        "                   cmap='viridis', vmin=0, vmax=2, square=True, ax=axes[0],\n",
        "                   cbar_kws={'label': 'Distance'})\n",
        "        axes[0].set_title(f'Top {n} Similar Pairs', fontsize=14)\n",
        "        axes[0].tick_params(axis='x', rotation=45, labelsize=8)\n",
        "        axes[0].tick_params(axis='y', rotation=0, labelsize=8)\n",
        "        \n",
        "        # Dissimilar pairs\n",
        "        dissimilar_cats = list(set([cat for pair, _ in top_dissimilar for cat in pair]))\n",
        "        dissimilar_indices = [ordered_categories.index(cat) for cat in dissimilar_cats if cat in ordered_categories]\n",
        "        dissimilar_matrix = distance_matrix[np.ix_(dissimilar_indices, dissimilar_indices)]\n",
        "        \n",
        "        sns.heatmap(dissimilar_matrix, \n",
        "                   xticklabels=[ordered_categories[i] for i in dissimilar_indices],\n",
        "                   yticklabels=[ordered_categories[i] for i in dissimilar_indices],\n",
        "                   cmap='viridis', vmin=0, vmax=2, square=True, ax=axes[1],\n",
        "                   cbar_kws={'label': 'Distance'})\n",
        "        axes[1].set_title(f'Top {n} Dissimilar Pairs', fontsize=14)\n",
        "        axes[1].tick_params(axis='x', rotation=45, labelsize=8)\n",
        "        axes[1].tick_params(axis='y', rotation=0, labelsize=8)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_dir / f'top_{n}_similar_pairs.png', dpi=300, bbox_inches='tight')\n",
        "        plt.savefig(output_dir / f'top_{n}_dissimilar_pairs.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Filtering complete! Results saved to {output_dir}\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Original categories: {len(categories)}\")\n",
        "print(f\"Filtered categories: {len(ordered_categories)}\")\n",
        "print(f\"Mean distance: {distance_matrix.mean():.4f}\")\n",
        "print(f\"Std distance: {distance_matrix.std():.4f}\")\n",
        "print(f\"Min distance: {distance_matrix[triu_indices].min():.4f}\")\n",
        "print(f\"Max distance: {distance_matrix[triu_indices].max():.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vislearnlabpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
