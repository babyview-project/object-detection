{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developmental Trajectory RDM Analysis\n",
    "\n",
    "This notebook creates multiple Representational Dissimilarity Matrices (RDMs) for each individual subject, binned by age in months (age_mo).\n",
    "This allows tracking how object representations change developmentally within each subject.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This analysis:\n",
    "1. Loads grouped embeddings (averaged by category, subject, and age_mo)\n",
    "2. Bins embeddings by age_mo for each subject\n",
    "3. Computes RDM for each subject at each age_mo bin\n",
    "4. Handles data density differences (some subjects/ages have more data)\n",
    "5. Visualizes developmental trajectories\n",
    "6. Compares RDMs across age bins within subjects\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Age binning**: Groups embeddings by age_mo to track developmental changes\n",
    "- **Data density handling**: Minimum category threshold per age bin\n",
    "- **Trajectory analysis**: Compare RDMs across age bins to see developmental changes\n",
    "- **Missing data handling**: Only includes age bins with sufficient data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
    "from scipy.spatial.distance import squareform\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set matplotlib backend\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "print(\"All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo\n",
      "Output directory: developmental_trajectory_rdms\n",
      "Min categories per age bin: 8\n",
      "Min age bins per subject: 2\n",
      "Age binning strategy: exact\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo\")\n",
    "output_dir = Path(\"developmental_trajectory_rdms\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Categories file (optional - to filter to specific categories)\n",
    "categories_file = Path(\"../../data/things_bv_overlap_categories_exclude_zero_precisions.txt\")\n",
    "\n",
    "# CDI words CSV file (required for category type organization)\n",
    "cdi_path = Path(\"../../data/cdi_words.csv\")\n",
    "\n",
    "# Hierarchical clustering options\n",
    "use_clustering = True  # Enable hierarchical clustering within category groups\n",
    "save_dendrograms = True  # Save dendrogram plots for each category group\n",
    "\n",
    "# Minimum categories required per age_mo bin to compute RDM\n",
    "min_categories_per_age_bin = 8\n",
    "\n",
    "# Minimum number of age bins required per subject to include in analysis\n",
    "min_age_bins_per_subject = 2\n",
    "\n",
    "# Age binning strategy: 'exact' (use exact age_mo) or 'binned' (group into bins)\n",
    "age_binning_strategy = 'exact'  # or 'binned'\n",
    "age_bin_size = 3  # if using 'binned', group ages into bins of this size (e.g., 3 months)\n",
    "\n",
    "print(f\"Embeddings directory: {embeddings_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"CDI path: {cdi_path}\")\n",
    "print(f\"Use clustering: {use_clustering}\")\n",
    "print(f\"Min categories per age bin: {min_categories_per_age_bin}\")\n",
    "print(f\"Min age bins per subject: {min_age_bins_per_subject}\")\n",
    "print(f\"Age binning strategy: {age_binning_strategy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_category_types(cdi_path):\n",
    "    \"\"\"Load category type information from CDI words CSV\"\"\"\n",
    "    print(f\"Loading category types from {cdi_path}...\")\n",
    "    cdi_df = pd.read_csv(cdi_path)\n",
    "    \n",
    "    category_types = {}\n",
    "    for _, row in cdi_df.iterrows():\n",
    "        category_types[row['uni_lemma']] = {\n",
    "            'is_animate': bool(row.get('is_animate', 0)),\n",
    "            'is_bodypart': bool(row.get('is_bodypart', 0)),\n",
    "            'is_small': bool(row.get('is_small', 0)),\n",
    "            'is_big': bool(row.get('is_big', 0))\n",
    "        }\n",
    "    \n",
    "    print(f\"Loaded type information for {len(category_types)} categories\")\n",
    "    return category_types\n",
    "\n",
    "def cluster_categories_within_group(group_categories, cat_to_embedding, save_dendrogram=False, output_dir=None, group_name=None):\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering within a group of categories.\n",
    "    \n",
    "    Args:\n",
    "        group_categories: List of category names in the group\n",
    "        cat_to_embedding: Dictionary mapping category names to embeddings\n",
    "        save_dendrogram: Whether to save dendrogram plot (default: False)\n",
    "        output_dir: Output directory for saving dendrogram (required if save_dendrogram=True)\n",
    "        group_name: Name of the group for saving dendrogram (required if save_dendrogram=True)\n",
    "    \n",
    "    Returns:\n",
    "        List of category names reordered according to clustering dendrogram\n",
    "    \"\"\"\n",
    "    if len(group_categories) <= 1:\n",
    "        return group_categories, None\n",
    "    \n",
    "    # Get embeddings for this group\n",
    "    group_embeddings = np.array([cat_to_embedding[cat].flatten() for cat in group_categories])\n",
    "    \n",
    "    # Normalize embeddings (z-score normalization per embedding)\n",
    "    normalized_embeddings = (group_embeddings - group_embeddings.mean(axis=0)) / (group_embeddings.std(axis=0) + 1e-10)\n",
    "    \n",
    "    # Compute distance matrix (1 - cosine similarity)\n",
    "    similarity_matrix = cosine_similarity(normalized_embeddings)\n",
    "    distance_matrix = 1 - similarity_matrix\n",
    "    np.fill_diagonal(distance_matrix, 0)\n",
    "    \n",
    "    # Convert to condensed form for linkage\n",
    "    condensed_distances = squareform(distance_matrix)\n",
    "    \n",
    "    # Perform hierarchical clustering\n",
    "    linkage_matrix = linkage(condensed_distances, method='ward')\n",
    "    \n",
    "    # Get optimal leaf ordering for better visualization\n",
    "    try:\n",
    "        linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
    "    except:\n",
    "        # If optimal leaf ordering fails, use original linkage\n",
    "        pass\n",
    "    \n",
    "    # Extract the order from the dendrogram\n",
    "    dendro_dict = dendrogram(linkage_matrix, no_plot=True)\n",
    "    leaf_order = dendro_dict['leaves']\n",
    "    \n",
    "    # Reorder categories according to clustering\n",
    "    clustered_categories = [group_categories[i] for i in leaf_order]\n",
    "    \n",
    "    # Save dendrogram if requested\n",
    "    if save_dendrogram and output_dir is not None and group_name is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        dendrogram(linkage_matrix, \n",
    "                  labels=group_categories,\n",
    "                  leaf_rotation=90,\n",
    "                  leaf_font_size=10)\n",
    "        plt.title(f'Hierarchical Clustering Dendrogram: {group_name.upper()}\\n({len(group_categories)} categories)',\n",
    "                 fontsize=16, pad=20)\n",
    "        plt.xlabel('Category', fontsize=12)\n",
    "        plt.ylabel('Distance', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save as PNG\n",
    "        output_path_png = output_dir / f'dendrogram_{group_name}.png'\n",
    "        plt.savefig(output_path_png, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
    "        print(f\"    Saved dendrogram to {output_path_png}\")\n",
    "        \n",
    "        # Save as PDF\n",
    "        output_path_pdf = output_dir / f'dendrogram_{group_name}.pdf'\n",
    "        plt.savefig(output_path_pdf, bbox_inches='tight', pad_inches=0.2)\n",
    "        print(f\"    Saved dendrogram to {output_path_pdf}\")\n",
    "        \n",
    "        plt.close()\n",
    "    \n",
    "    return clustered_categories, linkage_matrix\n",
    "\n",
    "print(\"Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading categories from ../../data/things_bv_overlap_categories_exclude_zero_precisions.txt...\n",
      "Loaded 163 categories\n"
     ]
    }
   ],
   "source": [
    "# Load allowed categories if file exists\n",
    "allowed_categories = None\n",
    "if categories_file.exists():\n",
    "    print(f\"Loading categories from {categories_file}...\")\n",
    "    with open(categories_file, 'r') as f:\n",
    "        allowed_categories = set(line.strip() for line in f if line.strip())\n",
    "    print(f\"Loaded {len(allowed_categories)} categories\")\n",
    "else:\n",
    "    print(f\"Categories file not found, using all categories\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings by Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from 163 categories...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading categories: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163/163 [00:01<00:00, 119.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded embeddings for 32 subjects\n",
      "Age bins found: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37]\n",
      "Age range: 6 to 37 months\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings_by_age(embeddings_dir, allowed_categories=None, age_binning_strategy='exact', age_bin_size=3):\n",
    "    \"\"\"\n",
    "    Load embeddings organized by subject, age_mo, and category.\n",
    "    \n",
    "    Returns:\n",
    "        subject_age_embeddings: dict[subject_id][age_mo_bin][category] = embedding array\n",
    "    \"\"\"\n",
    "    subject_age_embeddings = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    # Get all category folders\n",
    "    category_folders = [f for f in embeddings_dir.iterdir() if f.is_dir()]\n",
    "    \n",
    "    if allowed_categories:\n",
    "        category_folders = [f for f in category_folders if f.name in allowed_categories]\n",
    "    \n",
    "    print(f\"Loading embeddings from {len(category_folders)} categories...\")\n",
    "    \n",
    "    for category_folder in tqdm(category_folders, desc=\"Loading categories\"):\n",
    "        category = category_folder.name\n",
    "        \n",
    "        # Get all embedding files in this category\n",
    "        embedding_files = list(category_folder.glob(\"*.npy\"))\n",
    "        \n",
    "        for emb_file in embedding_files:\n",
    "            # Parse filename: {subject_id}_{age_mo}_month_level_avg.npy\n",
    "            filename = emb_file.stem  # without .npy\n",
    "            parts = filename.split('_')\n",
    "            \n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Extract subject_id and age_mo\n",
    "            subject_id = parts[0]\n",
    "            age_mo = int(parts[1]) if parts[1].isdigit() else None\n",
    "            \n",
    "            if age_mo is None:\n",
    "                continue\n",
    "            \n",
    "            # Apply age binning strategy\n",
    "            if age_binning_strategy == 'binned':\n",
    "                age_mo_bin = (age_mo // age_bin_size) * age_bin_size  # Round down to bin\n",
    "            else:\n",
    "                age_mo_bin = age_mo  # Use exact age\n",
    "            \n",
    "            try:\n",
    "                embedding = np.load(emb_file)\n",
    "                subject_age_embeddings[subject_id][age_mo_bin][category] = embedding\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {emb_file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return subject_age_embeddings\n",
    "\n",
    "# Load embeddings\n",
    "subject_age_embeddings = load_embeddings_by_age(\n",
    "    embeddings_dir, \n",
    "    allowed_categories, \n",
    "    age_binning_strategy=age_binning_strategy,\n",
    "    age_bin_size=age_bin_size\n",
    ")\n",
    "\n",
    "print(f\"\\nLoaded embeddings for {len(subject_age_embeddings)} subjects\")\n",
    "\n",
    "# Show age bin distribution\n",
    "all_age_bins = set()\n",
    "for subject_id, age_data in subject_age_embeddings.items():\n",
    "    all_age_bins.update(age_data.keys())\n",
    "\n",
    "print(f\"Age bins found: {sorted(all_age_bins)}\")\n",
    "print(f\"Age range: {min(all_age_bins)} to {max(all_age_bins)} months\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Embeddings\n",
    "\n",
    "Before computing RDMs, we normalize embeddings using z-score normalization (mean=0, std=1) for each age bin to ensure fair comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing embeddings per subject and age bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 32/32 [00:00<00:00, 414.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized embeddings for 32 subjects\n",
      "  Note: Each age bin is normalized independently, focusing on relative structure within that age bin\n",
      "Total unique categories across all subjects and ages: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing RDMs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 32/32 [00:00<00:00, 242.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computed RDMs for 26 subjects\n",
      "  (Excluded subjects with < 2 age bins with sufficient data)\n",
      "\n",
      "Age bins per subject:\n",
      "  Min: 2\n",
      "  Max: 20\n",
      "  Mean: 10.0\n",
      "  Median: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize embeddings within each subject across all age bins (z-score normalization)\n",
    "# This normalizes all embeddings for a subject together, allowing comparison across age bins\n",
    "print(\"Normalizing embeddings within each subject across all age bins...\")\n",
    "subject_age_embeddings_normalized = {}\n",
    "\n",
    "for subject_id, age_data in tqdm(subject_age_embeddings.items(), desc=\"Normalizing\"):\n",
    "    # Collect all embeddings for this subject across all age bins\n",
    "    all_embeddings_list = []\n",
    "    embedding_to_age_cat = []  # Track which (age, category) each embedding belongs to\n",
    "    \n",
    "    for age_mo, categories in age_data.items():\n",
    "        for cat, embedding in categories.items():\n",
    "            all_embeddings_list.append(embedding.flatten())\n",
    "            embedding_to_age_cat.append((age_mo, cat))\n",
    "    \n",
    "    if len(all_embeddings_list) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Stack all embeddings for this subject\n",
    "    all_embeddings_matrix = np.array(all_embeddings_list)\n",
    "    \n",
    "    # Compute global mean and std across all embeddings for this subject\n",
    "    subject_mean = all_embeddings_matrix.mean(axis=0)\n",
    "    subject_std = all_embeddings_matrix.std(axis=0) + 1e-10  # Add small epsilon to avoid division by zero\n",
    "    \n",
    "    # Normalize all embeddings using subject-level statistics\n",
    "    normalized_embeddings_matrix = (all_embeddings_matrix - subject_mean) / subject_std\n",
    "    \n",
    "    # Store normalized embeddings back by age and category\n",
    "    subject_age_embeddings_normalized[subject_id] = {}\n",
    "    for i, (age_mo, cat) in enumerate(embedding_to_age_cat):\n",
    "        if age_mo not in subject_age_embeddings_normalized[subject_id]:\n",
    "            subject_age_embeddings_normalized[subject_id][age_mo] = {}\n",
    "        subject_age_embeddings_normalized[subject_id][age_mo][cat] = normalized_embeddings_matrix[i]\n",
    "\n",
    "print(f\"Normalized embeddings for {len(subject_age_embeddings_normalized)} subjects\")\n",
    "print(\"  Note: Normalized within each subject across all age bins, allowing comparison across development\")\n",
    "def compute_rdm_for_age_bin(age_embeddings_dict, categories_list):\n",
    "    \"\"\"\n",
    "    Compute RDM for a single age bin.\n",
    "    \n",
    "    Args:\n",
    "        age_embeddings_dict: dict[category] = embedding array (should be normalized)\n",
    "        categories_list: list of categories to include (in order)\n",
    "    \n",
    "    Returns:\n",
    "        rdm: numpy array of shape (n_categories, n_categories) or None\n",
    "        available_categories: list of categories actually present\n",
    "    \"\"\"\n",
    "    # Filter to categories that exist for this age bin\n",
    "    available_categories = [cat for cat in categories_list if cat in age_embeddings_dict]\n",
    "    \n",
    "    if len(available_categories) < min_categories_per_age_bin:\n",
    "        return None, available_categories\n",
    "    \n",
    "    # Build embedding matrix (already normalized)\n",
    "    # Flatten each embedding to ensure 1D (in case they have shape (1, 512) instead of (512,))\n",
    "    embedding_matrix = np.array([age_embeddings_dict[cat].flatten() for cat in available_categories])\n",
    "    \n",
    "    # Ensure 2D shape: (n_categories, embedding_dim)\n",
    "    if embedding_matrix.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D embedding matrix, got shape {embedding_matrix.shape}\")\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(embedding_matrix)\n",
    "    \n",
    "    # Convert to distance (RDM)\n",
    "    distance_matrix = 1 - similarity_matrix\n",
    "    np.fill_diagonal(distance_matrix, 0)  # Ensure diagonal is 0\n",
    "    \n",
    "    # Make symmetric (in case of numerical errors)\n",
    "    distance_matrix = (distance_matrix + distance_matrix.T) / 2\n",
    "    \n",
    "    return distance_matrix, available_categories\n",
    "\n",
    "# Get all unique categories across all subjects and ages\n",
    "all_categories = set()\n",
    "for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
    "    for age_mo, categories in age_data.items():\n",
    "        all_categories.update(categories.keys())\n",
    "\n",
    "all_categories = sorted(list(all_categories))\n",
    "print(f\"Total unique categories across all subjects and ages: {len(all_categories)}\")\n",
    "\n",
    "# Compute RDMs for each subject at each age bin using normalized embeddings\n",
    "subject_age_rdms = {}\n",
    "subject_age_rdm_categories = {}\n",
    "\n",
    "for subject_id, age_data in tqdm(subject_age_embeddings_normalized.items(), desc=\"Computing RDMs\"):\n",
    "    subject_age_rdms[subject_id] = {}\n",
    "    subject_age_rdm_categories[subject_id] = {}\n",
    "    \n",
    "    for age_mo, categories in age_data.items():\n",
    "        rdm, available_cats = compute_rdm_for_age_bin(categories, all_categories)\n",
    "        \n",
    "        if rdm is not None:\n",
    "            subject_age_rdms[subject_id][age_mo] = rdm\n",
    "            subject_age_rdm_categories[subject_id][age_mo] = available_cats\n",
    "    \n",
    "    # Filter out subjects with too few age bins\n",
    "    if len(subject_age_rdms[subject_id]) < min_age_bins_per_subject:\n",
    "        del subject_age_rdms[subject_id]\n",
    "        del subject_age_rdm_categories[subject_id]\n",
    "\n",
    "print(f\"\\nComputed RDMs for {len(subject_age_rdms)} subjects\")\n",
    "print(f\"  (Excluded subjects with < {min_age_bins_per_subject} age bins with sufficient data)\")\n",
    "\n",
    "# Show distribution of age bins per subject\n",
    "age_bin_counts = [len(age_rdms) for age_rdms in subject_age_rdms.values()]\n",
    "print(f\"\\nAge bins per subject:\")\n",
    "print(f\"  Min: {min(age_bin_counts) if age_bin_counts else 0}\")\n",
    "print(f\"  Max: {max(age_bin_counts) if age_bin_counts else 0}\")\n",
    "print(f\"  Mean: {np.mean(age_bin_counts):.1f}\" if age_bin_counts else \"  Mean: 0\")\n",
    "print(f\"  Median: {np.median(age_bin_counts):.1f}\" if age_bin_counts else \"  Median: 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Organize Categories and Apply Hierarchical Clustering\n",
    "\n",
    "# Load category types for organization\n",
    "if cdi_path.exists():\n",
    "    category_types = load_category_types(cdi_path)\n",
    "else:\n",
    "    print(f\"Warning: CDI path {cdi_path} not found. Skipping category organization.\")\n",
    "    category_types = {}\n",
    "\n",
    "# Get all unique categories across all subjects and ages (needed for organization)\n",
    "all_categories = set()\n",
    "for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
    "    for age_mo, categories in age_data.items():\n",
    "        all_categories.update(categories.keys())\n",
    "\n",
    "all_categories = sorted(list(all_categories))\n",
    "print(f\"Total unique categories across all subjects and ages: {len(all_categories)}\")\n",
    "\n",
    "# Organize categories by broad types and apply hierarchical clustering\n",
    "print(\"\\nOrganizing categories by type and applying hierarchical clustering...\")\n",
    "\n",
    "# Get a representative set of embeddings for clustering (average across all subjects and ages)\n",
    "representative_embeddings = {}\n",
    "for cat in all_categories:\n",
    "    cat_embeddings = []\n",
    "    for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
    "        for age_mo, categories in age_data.items():\n",
    "            if cat in categories:\n",
    "                cat_embeddings.append(categories[cat])\n",
    "    if len(cat_embeddings) > 0:\n",
    "        # Average across all subjects and ages for this category\n",
    "        representative_embeddings[cat] = np.mean(cat_embeddings, axis=0)\n",
    "\n",
    "# Organize by type\n",
    "organized = {\n",
    "    'animals': [],\n",
    "    'bodyparts': [],\n",
    "    'big_objects': [],\n",
    "    'small_objects': [],\n",
    "    'others': []\n",
    "}\n",
    "\n",
    "for cat in all_categories:\n",
    "    if cat not in category_types:\n",
    "        organized['others'].append(cat)\n",
    "        continue\n",
    "    \n",
    "    types = category_types[cat]\n",
    "    if types['is_animate']:\n",
    "        organized['animals'].append(cat)\n",
    "    elif types['is_bodypart']:\n",
    "        organized['bodyparts'].append(cat)\n",
    "    elif types['is_big']:\n",
    "        organized['big_objects'].append(cat)\n",
    "    elif types['is_small']:\n",
    "        organized['small_objects'].append(cat)\n",
    "    else:\n",
    "        organized['others'].append(cat)\n",
    "\n",
    "print(f\"  Organized into: {len(organized['animals'])} animals, {len(organized['bodyparts'])} bodyparts, \"\n",
    "      f\"{len(organized['big_objects'])} big objects, {len(organized['small_objects'])} small objects, \"\n",
    "      f\"{len(organized['others'])} others\")\n",
    "\n",
    "# Apply hierarchical clustering within each group\n",
    "if use_clustering:\n",
    "    print(\"\\nApplying hierarchical clustering within groups...\")\n",
    "    for key in organized:\n",
    "        if len(organized[key]) > 1:\n",
    "            # Filter to categories that have representative embeddings\n",
    "            group_cats = [cat for cat in organized[key] if cat in representative_embeddings]\n",
    "            if len(group_cats) > 1:\n",
    "                print(f\"  Clustering {key} ({len(group_cats)} categories)...\")\n",
    "                organized[key], _ = cluster_categories_within_group(\n",
    "                    group_cats,\n",
    "                    representative_embeddings,\n",
    "                    save_dendrogram=save_dendrograms,\n",
    "                    output_dir=output_dir,\n",
    "                    group_name=key\n",
    "                )\n",
    "            else:\n",
    "                organized[key] = group_cats\n",
    "        else:\n",
    "            organized[key] = [cat for cat in organized[key] if cat in representative_embeddings]\n",
    "else:\n",
    "    for key in organized:\n",
    "        organized[key] = sorted([cat for cat in organized[key] if cat in representative_embeddings])\n",
    "\n",
    "# Create ordered list of categories\n",
    "ordered_categories = (\n",
    "    organized['animals'] +\n",
    "    organized['bodyparts'] +\n",
    "    organized['big_objects'] +\n",
    "    organized['small_objects'] +\n",
    "    organized['others']\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal ordered category list: {len(ordered_categories)} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age binning for visualization",
    "# Group ages into bins to reduce number of RDMs per subject",
    "def create_age_bins(ages, bin_size=3):",
    "    \"\"\"",
    "    Create age bins of specified size.",
    "    ",
    "    Args:",
    "        ages: List of age values in months",
    "        bin_size: Size of each bin in months (default: 3)",
    "    ",
    "    Returns:",
    "        Dictionary mapping age_bin -> list of ages in that bin",
    "    \"\"\"\"",
    "    age_bins = {}",
    "    for age in sorted(ages):",
    "        # Round down to nearest bin",
    "        age_bin = (age // bin_size) * bin_size",
    "        if age_bin not in age_bins:",
    "            age_bins[age_bin] = []",
    "        age_bins[age_bin].append(age)",
    "    return age_bins",
    "",
    "def aggregate_rdm_for_age_bin(rdms_dict, ages_in_bin, categories_dict):",
    "    \"\"\"",
    "    Aggregate RDMs for multiple ages in a bin by averaging.",
    "    ",
    "    Args:",
    "        rdms_dict: Dictionary mapping age -> RDM matrix",
    "        ages_in_bin: List of ages to aggregate",
    "        categories_dict: Dictionary mapping age -> list of categories",
    "    ",
    "    Returns:",
    "        Aggregated RDM and common categories",
    "    \"\"\"",
    "    if len(ages_in_bin) == 0:",
    "        return None, []",
    "    ",
    "    # Find common categories across all ages in bin",
    "    common_cats = set(categories_dict[ages_in_bin[0]])",
    "    for age in ages_in_bin[1:]:",
    "        common_cats = common_cats & set(categories_dict[age])",
    "    ",
    "    common_cats = sorted(list(common_cats))",
    "    ",
    "    if len(common_cats) < min_categories_per_age_bin:",
    "        return None, common_cats",
    "    ",
    "    # Get indices for common categories in each RDM",
    "    rdms_to_aggregate = []",
    "    for age in ages_in_bin:",
    "        rdm = rdms_dict[age]",
    "        cats = categories_dict[age]",
    "        indices = [cats.index(cat) for cat in common_cats]",
    "        rdm_subset = rdm[np.ix_(indices, indices)]",
    "        rdms_to_aggregate.append(rdm_subset)",
    "    ",
    "    # Average the RDMs",
    "    aggregated_rdm = np.mean(rdms_to_aggregate, axis=0)",
    "    ",
    "    return aggregated_rdm, common_cats",
    "",
    "# Age binning configuration",
    "age_bin_size = 3  # Group ages into 3-month bins (e.g., 6-8, 9-11, 12-14, etc.)",
    "use_age_binning = True  # Set to False to use exact ages",
    "",
    "print(f\"Age binning: {'Enabled' if use_age_binning else 'Disabled'}\")",
    "if use_age_binning:",
    "    print(f\"  Bin size: {age_bin_size} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reorganize each subject's RDM at each age bin according to the new ordering\n",
    "print(\"\\nReorganizing individual subject RDMs according to new category ordering...\")\n",
    "subject_age_rdms_reorganized = {}\n",
    "subject_age_rdm_categories_reorganized = {}\n",
    "subject_age_group_boundaries = {}  # Store group boundaries for visual separators\n",
    "\n",
    "for subject_id in tqdm(subject_age_rdms.keys(), desc=\"Reorganizing RDMs\"):\n",
    "    subject_age_rdms_reorganized[subject_id] = {}",
    "    subject_age_rdm_categories_reorganized[subject_id] = {}",
    "    subject_age_group_boundaries[subject_id] = {}",
    "    ",
    "    # Get original age RDMs for this subject",
    "    original_age_rdms = subject_age_rdms[subject_id]",
    "    original_age_categories = subject_age_rdm_categories[subject_id]",
    "    ",
    "    # Apply age binning if enabled",
    "    if use_age_binning:",
    "        # Get all ages for this subject",
    "        subject_ages = sorted(list(original_age_rdms.keys()))",
    "        age_bins = create_age_bins(subject_ages, age_bin_size)",
    "        ",
    "        # Aggregate RDMs within each bin",
    "        binned_rdms = {}",
    "        binned_categories = {}",
    "        for age_bin, ages_in_bin in age_bins.items():",
    "            rdms_for_bin = {age: original_age_rdms[age] for age in ages_in_bin}",
    "            cats_for_bin = {age: original_age_categories[age] for age in ages_in_bin}",
    "            agg_rdm, agg_cats = aggregate_rdm_for_age_bin(rdms_for_bin, ages_in_bin, cats_for_bin)",
    "            if agg_rdm is not None:",
    "                # Use bin label (e.g., \"6-8\" for ages 6,7,8)",
    "                bin_label = f\"{min(ages_in_bin)}-{max(ages_in_bin)}\"",
    "                binned_rdms[bin_label] = agg_rdm",
    "                binned_categories[bin_label] = agg_cats",
    "        ",
    "        # Use binned version for reorganization",
    "        age_rdms_to_process = binned_rdms",
    "        age_categories_to_process = binned_categories",
    "    else:",
    "        age_rdms_to_process = original_age_rdms",
    "        age_categories_to_process = original_age_categories",
    "    ",
    "    # Reorganize each age bin's RDM",
    "    for age_mo, rdm in age_rdms_to_process.items():",
    "        available_cats = age_categories_to_process[age_mo]",
    "        \n",
    "        # Get the ordered list of categories for this age bin (subset of ordered_categories)\n",
    "        subject_age_ordered_cats = [cat for cat in ordered_categories if cat in available_cats]\n",
    "        \n",
    "        # Create new indices for reorganized RDM\n",
    "        new_indices = [available_cats.index(cat) for cat in subject_age_ordered_cats]\n",
    "        \n",
    "        # Reorganize the RDM\n",
    "        rdm_reorganized = rdm[np.ix_(new_indices, new_indices)]\n",
    "        \n",
    "        # Compute group boundaries for this age bin\n",
    "        group_boundaries = []\n",
    "        current_idx = 0\n",
    "        for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
    "            group_cats = [cat for cat in organized[group_name] if cat in subject_age_ordered_cats]\n",
    "            if len(group_cats) > 0:\n",
    "                group_start = current_idx\n",
    "                group_end = current_idx + len(group_cats)\n",
    "                group_boundaries.append({\n",
    "                    'name': group_name,\n",
    "                    'start': group_start,\n",
    "                    'end': group_end,\n",
    "                    'categories': group_cats\n",
    "                })\n",
    "                current_idx = group_end\n",
    "        \n",
    "        subject_age_rdms_reorganized[subject_id][age_mo] = rdm_reorganized\n",
    "        subject_age_rdm_categories_reorganized[subject_id][age_mo] = subject_age_ordered_cats\n",
    "        subject_age_group_boundaries[subject_id][age_mo] = group_boundaries\n",
    "\n",
    "# Update the main dictionaries\n",
    "subject_age_rdms = subject_age_rdms_reorganized\n",
    "subject_age_rdm_categories = subject_age_rdm_categories_reorganized\n",
    "\n",
    "print(f\"Reorganized RDMs for {len(subject_age_rdms)} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute RDMs for Each Subject at Each Age Bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving developmental trajectory RDMs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving RDMs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 26/26 [00:04<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved RDMs to developmental_trajectory_rdms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save RDMs for each subject-age combination\n",
    "print(\"Saving developmental trajectory RDMs...\")\n",
    "\n",
    "for subject_id, age_rdms in tqdm(subject_age_rdms.items(), desc=\"Saving RDMs\"):\n",
    "    subject_output_dir = output_dir / subject_id\n",
    "    subject_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for age_mo, rdm in age_rdms.items():\n",
    "        categories = subject_age_rdm_categories[subject_id][age_mo]\n",
    "        \n",
    "        # Save as numpy array\n",
    "        np.save(subject_output_dir / f\"rdm_age_{age_mo}.npy\", rdm)\n",
    "        \n",
    "        # Save as CSV with category labels\n",
    "        rdm_df = pd.DataFrame(rdm, index=categories, columns=categories)\n",
    "        rdm_df.to_csv(subject_output_dir / f\"rdm_age_{age_mo}.csv\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'subject_id': subject_id,\n",
    "            'age_mo': age_mo,\n",
    "            'n_categories': len(categories),\n",
    "            'categories': categories,\n",
    "            'mean_distance': float(rdm.mean()),\n",
    "            'std_distance': float(rdm.std())\n",
    "        }\n",
    "        \n",
    "        metadata_df = pd.DataFrame([metadata])\n",
    "        metadata_df.to_csv(subject_output_dir / f\"metadata_age_{age_mo}.csv\", index=False)\n",
    "\n",
    "        # Create and save individual dendrogram for this age bin\n",
    "        if len(categories) > 1:\n",
    "            # Get embeddings for this age bin's categories\n",
    "            age_embeddings = {cat: subject_age_embeddings_normalized[subject_id][age_mo][cat] \n",
    "                             for cat in categories if cat in subject_age_embeddings_normalized[subject_id][age_mo]}\n",
    "            \n",
    "            if len(age_embeddings) > 1:\n",
    "                # Build embedding matrix\n",
    "                embedding_matrix = np.array([age_embeddings[cat].flatten() for cat in categories])\n",
    "                \n",
    "                # Normalize embeddings\n",
    "                normalized_embeddings = (embedding_matrix - embedding_matrix.mean(axis=0)) / (embedding_matrix.std(axis=0) + 1e-10)\n",
    "                \n",
    "                # Compute distance matrix\n",
    "                similarity_matrix = cosine_similarity(normalized_embeddings)\n",
    "                distance_matrix = 1 - similarity_matrix\n",
    "                np.fill_diagonal(distance_matrix, 0)\n",
    "                \n",
    "                # Convert to condensed form for linkage\n",
    "                condensed_distances = squareform(distance_matrix)\n",
    "                \n",
    "                # Perform hierarchical clustering\n",
    "                linkage_matrix = linkage(condensed_distances, method='ward')\n",
    "                \n",
    "                # Get optimal leaf ordering\n",
    "                try:\n",
    "                    linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Create dendrogram\n",
    "                plt.figure(figsize=(max(16, len(categories) * 0.5), 10))\n",
    "                dendrogram(linkage_matrix, \n",
    "                          labels=categories,\n",
    "                          leaf_rotation=90,\n",
    "                          leaf_font_size=max(8, min(14, 200 // len(categories))))\n",
    "                plt.title(f'Dendrogram: {subject_id} Age {age_mo} months\\n({len(categories)} categories)',\n",
    "                         fontsize=16, pad=20)\n",
    "                plt.xlabel('Category', fontsize=14)\n",
    "                plt.ylabel('Distance', fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save dendrogram\n",
    "                dendrogram_dir = subject_output_dir / \"dendrograms\"\n",
    "                dendrogram_dir.mkdir(exist_ok=True, parents=True)\n",
    "                dendrogram_path = dendrogram_dir / f\"dendrogram_age_{age_mo}.png\"\n",
    "                plt.savefig(dendrogram_path, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
    "                plt.close()\n",
    "\n",
    "print(f\"\\nSaved RDMs to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Developmental Trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing trajectories: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 26/26 [00:00<00:00, 66.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trajectory analysis:\n",
      "  Total age transitions analyzed: 235\n",
      "  Mean RDM correlation: 0.627\n",
      "  Std RDM correlation: 0.083\n",
      "\n",
      "Saved trajectory correlations to developmental_trajectory_rdms/trajectory_correlations.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_rdm_correlation(rdm1, rdm2, categories1, categories2):\n",
    "    \"\"\"\n",
    "    Compute correlation between two RDMs.\n",
    "    Only uses categories present in both RDMs.\n",
    "    \"\"\"\n",
    "    # Find common categories\n",
    "    common_categories = sorted(list(set(categories1) & set(categories2)))\n",
    "    \n",
    "    if len(common_categories) < 2:\n",
    "        return np.nan, len(common_categories)\n",
    "    \n",
    "    # Get indices for common categories\n",
    "    idx1 = [categories1.index(cat) for cat in common_categories]\n",
    "    idx2 = [categories2.index(cat) for cat in common_categories]\n",
    "    \n",
    "    # Extract upper triangle (excluding diagonal) for both RDMs\n",
    "    rdm1_subset = rdm1[np.ix_(idx1, idx1)]\n",
    "    rdm2_subset = rdm2[np.ix_(idx2, idx2)]\n",
    "    \n",
    "    # Get upper triangle\n",
    "    mask = np.triu(np.ones_like(rdm1_subset, dtype=bool), k=1)\n",
    "    rdm1_flat = rdm1_subset[mask]\n",
    "    rdm2_flat = rdm2_subset[mask]\n",
    "    \n",
    "    # Compute Spearman correlation (more robust to outliers)\n",
    "    if len(rdm1_flat) > 0:\n",
    "        corr, _ = spearmanr(rdm1_flat, rdm2_flat)\n",
    "        return corr, len(common_categories)\n",
    "    else:\n",
    "        return np.nan, len(common_categories)\n",
    "\n",
    "# Compute RDM correlations across age bins for each subject\n",
    "trajectory_data = []\n",
    "\n",
    "for subject_id, age_rdms in tqdm(subject_age_rdms.items(), desc=\"Analyzing trajectories\"):\n",
    "    ages = sorted(age_rdms.keys())\n",
    "    \n",
    "    if len(ages) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Compute pairwise correlations between consecutive age bins\n",
    "    for i in range(len(ages) - 1):\n",
    "        age1 = ages[i]\n",
    "        age2 = ages[i + 1]\n",
    "        \n",
    "        rdm1 = age_rdms[age1]\n",
    "        rdm2 = age_rdms[age2]\n",
    "        cats1 = subject_age_rdm_categories[subject_id][age1]\n",
    "        cats2 = subject_age_rdm_categories[subject_id][age2]\n",
    "        \n",
    "        corr, n_common = compute_rdm_correlation(rdm1, rdm2, cats1, cats2)\n",
    "        \n",
    "        trajectory_data.append({\n",
    "            'subject_id': subject_id,\n",
    "            'age1': age1,\n",
    "            'age2': age2,\n",
    "            'age_diff': age2 - age1,\n",
    "            'rdm_correlation': corr,\n",
    "            'n_common_categories': n_common,\n",
    "            'n_categories_age1': len(cats1),\n",
    "            'n_categories_age2': len(cats2)\n",
    "        })\n",
    "\n",
    "trajectory_df = pd.DataFrame(trajectory_data)\n",
    "trajectory_df.to_csv(output_dir / \"trajectory_correlations.csv\", index=False)\n",
    "\n",
    "print(f\"\\nTrajectory analysis:\")\n",
    "print(f\"  Total age transitions analyzed: {len(trajectory_df)}\")\n",
    "print(f\"  Mean RDM correlation: {trajectory_df['rdm_correlation'].mean():.3f}\")\n",
    "print(f\"  Std RDM correlation: {trajectory_df['rdm_correlation'].std():.3f}\")\n",
    "print(f\"\\nSaved trajectory correlations to {output_dir / 'trajectory_correlations.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Developmental Trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trajectory visualizations for 3 sample subjects\n"
     ]
    }
   ],
   "source": [
    "# Create grid layout RDM trajectory overview for each subject",
    "print(\"Creating grid layout RDM trajectory visualizations for all subjects...\")",
    "",
    "for subject_id in tqdm(subject_age_rdms.keys(), desc=\"Creating trajectory grids\"):",
    "    age_rdms = subject_age_rdms[subject_id]",
    "    ages = sorted(age_rdms.keys())",
    "    ",
    "    if len(ages) == 0:",
    "        continue",
    "    ",
    "    # Determine grid layout (aim for roughly square grid)",
    "    n_ages = len(ages)",
    "    n_cols = int(np.ceil(np.sqrt(n_ages)))",
    "    n_rows = int(np.ceil(n_ages / n_cols))",
    "    ",
    "    # Create figure with appropriate size",
    "    fig_size_per_plot = 4",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * fig_size_per_plot, n_rows * fig_size_per_plot))",
    "    ",
    "    # Flatten axes for easier indexing",
    "    if n_ages == 1:",
    "        axes = [axes]",
    "    elif n_rows == 1:",
    "        axes = axes if isinstance(axes, list) else [axes]",
    "    else:",
    "        axes = axes.flatten()",
    "    ",
    "    # Find global min/max for consistent color scale",
    "    all_rdm_values = []",
    "    for rdm in age_rdms.values():",
    "        all_rdm_values.extend(rdm.flatten())",
    "    vmin = np.percentile(all_rdm_values, 1)",
    "    vmax = np.percentile(all_rdm_values, 99)",
    "    ",
    "    for idx, age_mo in enumerate(ages):",
    "        rdm = age_rdms[age_mo]",
    "        categories = subject_age_rdm_categories[subject_id][age_mo]",
    "        group_boundaries = subject_age_group_boundaries[subject_id][age_mo]",
    "        ",
    "        ax = axes[idx]",
    "        ",
    "        # Determine font sizes based on number of categories",
    "        n_cats = len(categories)",
    "        if n_cats <= 50:",
    "            label_fontsize = 10",
    "            tick_fontsize = 14",
    "        elif n_cats <= 100:",
    "            label_fontsize = 8",
    "            tick_fontsize = 12",
    "        else:",
    "            label_fontsize = 6",
    "            tick_fontsize = 10",
    "        ",
    "        im = ax.imshow(rdm, cmap=\"viridis\", aspect=\"auto\", vmin=vmin, vmax=vmax)",
    "        ",
    "        # Add visual separators between category groups",
    "        for boundary in group_boundaries:",
    "            # Draw vertical line",
    "            if boundary[\"start\"] > 0:",
    "                ax.axvline(x=boundary[\"start\"] - 0.5, color=\"white\", linewidth=1.5, linestyle=\"--\", alpha=0.7)",
    "            # Draw horizontal line",
    "            if boundary[\"start\"] > 0:",
    "                ax.axhline(y=boundary[\"start\"] - 0.5, color=\"white\", linewidth=1.5, linestyle=\"--\", alpha=0.7)",
    "        ",
    "        # Set category names as axis labels (show every Nth label to avoid crowding)",
    "        n_cats = len(categories)",
    "        if n_cats > 50:",
    "            # Show every 5th label",
    "            tick_step = max(1, n_cats // 20)",
    "            tick_positions = list(range(0, n_cats, tick_step))",
    "            tick_labels = [categories[i] if i < len(categories) else '' for i in tick_positions]",
    "        else:",
    "            tick_positions = range(len(categories))",
    "            tick_labels = categories",
    "        ",
    "        ax.set_xticks(tick_positions)",
    "        ax.set_yticks(tick_positions)",
    "        ax.set_xticklabels(tick_labels, rotation=90, ha=\"right\", fontsize=tick_fontsize)",
    "        ax.set_yticklabels(tick_labels, fontsize=tick_fontsize)",
    "        ",
    "        ax.set_title(f\"Age {age_mo} months\\n({n_cats} cats)\", fontsize=10, pad=5)",
    "        ",
    "        # Add colorbar",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)",
    "    ",
    "    # Hide unused subplots",
    "    for idx in range(n_ages, len(axes)):",
    "        axes[idx].axis('off')",
    "    ",
    "    plt.suptitle(f\"Developmental Trajectory: {subject_id}\\n({n_ages} age bins)\", fontsize=14, y=0.995)",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])",
    "    plt.savefig(output_dir / f\"trajectory_grid_{subject_id}.png\", dpi=200, bbox_inches='tight')",
    "    plt.close()",
    "",
    "print(f\"\\nSaved grid layout trajectory visualizations for {len(subject_age_rdms)} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RDM Stability Across Development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved RDM stability analysis to developmental_trajectory_rdms/rdm_stability_analysis.png\n"
     ]
    }
   ],
   "source": [
    "# Plot RDM correlation as a function of age difference\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RDM correlation vs age difference\n",
    "axes[0].scatter(trajectory_df['age_diff'], trajectory_df['rdm_correlation'], alpha=0.6)\n",
    "axes[0].set_xlabel('Age Difference (months)')\n",
    "axes[0].set_ylabel('RDM Correlation (Spearman)')\n",
    "axes[0].set_title('RDM Stability vs Age Gap')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RDM correlation vs mean age\n",
    "trajectory_df['mean_age'] = (trajectory_df['age1'] + trajectory_df['age2']) / 2\n",
    "axes[1].scatter(trajectory_df['mean_age'], trajectory_df['rdm_correlation'], alpha=0.6)\n",
    "axes[1].set_xlabel('Mean Age (months)')\n",
    "axes[1].set_ylabel('RDM Correlation (Spearman)')\n",
    "axes[1].set_title('RDM Stability vs Age')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"rdm_stability_analysis.png\", dpi=150, bbox_inches='tight')\n",
    "print(f\"Saved RDM stability analysis to {output_dir / 'rdm_stability_analysis.png'}\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics:\n",
      "           age_mo  n_categories  mean_distance  std_distance  min_distance  \\\n",
      "count  261.000000    261.000000     261.000000    261.000000    261.000000   \n",
      "mean    16.743295    130.164751       0.996279      0.254649      0.046867   \n",
      "std      5.773880     15.093544       0.000960      0.009529      0.027013   \n",
      "min      6.000000     60.000000       0.993074      0.228317      0.003778   \n",
      "25%     13.000000    122.000000       0.995709      0.248605      0.027431   \n",
      "50%     16.000000    134.000000       0.996341      0.254671      0.041594   \n",
      "75%     20.000000    142.000000       0.996917      0.260849      0.063201   \n",
      "max     37.000000    157.000000       0.998314      0.278531      0.183422   \n",
      "\n",
      "       max_distance  \n",
      "count    261.000000  \n",
      "mean       1.612466  \n",
      "std        0.037372  \n",
      "min        1.498946  \n",
      "25%        1.588435  \n",
      "50%        1.614097  \n",
      "75%        1.636053  \n",
      "max        1.696628  \n",
      "\n",
      "Saved summary to developmental_trajectory_rdms/summary_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "# Create summary statistics\n",
    "summary_data = []\n",
    "\n",
    "for subject_id, age_rdms in subject_age_rdms.items():\n",
    "    ages = sorted(age_rdms.keys())\n",
    "    \n",
    "    for age_mo in ages:\n",
    "        rdm = age_rdms[age_mo]\n",
    "        categories = subject_age_rdm_categories[subject_id][age_mo]\n",
    "        \n",
    "        summary_data.append({\n",
    "            'subject_id': subject_id,\n",
    "            'age_mo': age_mo,\n",
    "            'n_categories': len(categories),\n",
    "            'mean_distance': float(rdm.mean()),\n",
    "            'std_distance': float(rdm.std()),\n",
    "            'min_distance': float(rdm[rdm > 0].min()) if (rdm > 0).any() else np.nan,\n",
    "            'max_distance': float(rdm.max())\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv(output_dir / \"summary_statistics.csv\", index=False)\n",
    "\n",
    "print(\"Summary statistics:\")\n",
    "print(summary_df.describe())\n",
    "print(f\"\\nSaved summary to {output_dir / 'summary_statistics.csv'}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}