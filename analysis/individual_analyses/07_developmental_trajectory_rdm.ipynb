{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Developmental Trajectory RDM Analysis\n",
        "\n",
        "This notebook creates two Representational Dissimilarity Matrices (RDMs) for each individual subject, split by a median age threshold computed across all participants.\n",
        "This allows tracking how object representations change developmentally within each subject.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This analysis:\n",
        "1. Loads grouped embeddings (averaged by category, subject, and age_mo)\n",
        "2. Calculates the overall median age across all participants\n",
        "3. For each subject, splits data into \"younger\" (age_mo <= median) and \"older\" (age_mo > median) bins\n",
        "4. Computes RDM for each subject for each age bin (2 RDMs per subject)\n",
        "5. Handles data density differences (some subjects/ages have more data)\n",
        "6. Visualizes developmental trajectories\n",
        "7. Compares RDMs between younger and older periods within subjects\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Median split**: Uses overall median age across all participants to split each subject's data\n",
        "- **Two RDMs per subject**: One for \"younger\" period, one for \"older\" period\n",
        "- **Data density handling**: Minimum category threshold per age bin\n",
        "- **Trajectory analysis**: Compare RDMs between younger and older periods to see developmental changes\n",
        "- **Missing data handling**: Only includes subjects with sufficient data in both bins\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
        "from scipy.spatial.distance import squareform\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set matplotlib backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized embeddings directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\n",
            "Detected embedding type: clip\n",
            "Output directory: developmental_trajectory_rdms_clip\n",
            "Excluded subject: 00270001\n",
            "CDI path: ../../data/cdi_words.csv\n",
            "Use clustering: True\n",
            "Use predefined category list: True\n",
            "Predefined category list path: ../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "# Path to normalized embeddings from notebook 05 (age-month level normalized embeddings)\n",
        "# These are saved in category folders: {normalized_embeddings_dir}/{category}/{subject_id}_{age_mo}_month_level_avg.npy\n",
        "# normalized_embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/facebook_dinov3-vitb16-pretrain-lvd1689m_grouped_by_age-mo_normalized\")\n",
        "normalized_embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\")\n",
        "\n",
        "# Detect embedding type from path\n",
        "normalized_embeddings_dir_str = str(normalized_embeddings_dir).lower()\n",
        "if \"dinov3\" in normalized_embeddings_dir_str or \"dinov\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"dinov3\"\n",
        "elif \"clip\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"clip\"\n",
        "else:\n",
        "    embedding_type = \"unknown\"\n",
        "\n",
        "# Create output directory with embedding type in name\n",
        "output_dir = Path(f\"developmental_trajectory_rdms_{embedding_type}\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Subject to exclude from analyses (should match notebook 06)\n",
        "excluded_subject = \"00270001\"\n",
        "\n",
        "# Categories file (optional - to filter to specific categories)\n",
        "categories_file = Path(\"../../data/things_bv_overlap_categories_exclude_zero_precisions.txt\")\n",
        "\n",
        "# CDI words CSV file (required for category type organization)\n",
        "cdi_path = Path(\"../../data/cdi_words.csv\")\n",
        "\n",
        "# Hierarchical clustering options\n",
        "use_clustering = True  # Enable hierarchical clustering within category groups\n",
        "save_dendrograms = True  # Save dendrogram plots for each category group\n",
        "\n",
        "# Predefined category list for consistent RDM ordering (optional)\n",
        "# Set to None to use automatic organization, or provide path to category order file\n",
        "# This allows comparing RDMs across subjects with the same category ordering\n",
        "USE_PREDEFINED_CATEGORY_LIST = True  # If True, load category order from PREDEFINED_CATEGORY_LIST_PATH\n",
        "PREDEFINED_CATEGORY_LIST_PATH = \"../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\"  # Path to text file with category order (one category per line), or None\n",
        "# Example: PREDEFINED_CATEGORY_LIST_PATH = \"../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\"\n",
        "\n",
        "# Minimum categories required per age bin to compute RDM\n",
        "min_categories_per_age_bin = 8\n",
        "\n",
        "print(f\"Normalized embeddings directory: {normalized_embeddings_dir}\")\n",
        "print(f\"Detected embedding type: {embedding_type}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Excluded subject: {excluded_subject}\")\n",
        "print(f\"CDI path: {cdi_path}\")\n",
        "print(f\"Use clustering: {use_clustering}\")\n",
        "print(f\"Use predefined category list: {USE_PREDEFINED_CATEGORY_LIST}\")\n",
        "if USE_PREDEFINED_CATEGORY_LIST and PREDEFINED_CATEGORY_LIST_PATH:\n",
        "    print(f\"Predefined category list path: {PREDEFINED_CATEGORY_LIST_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded!\n"
          ]
        }
      ],
      "source": [
        "def load_category_types(cdi_path):\n",
        "    \"\"\"Load category type information from CDI words CSV\"\"\"\n",
        "    print(f\"Loading category types from {cdi_path}...\")\n",
        "    cdi_df = pd.read_csv(cdi_path)\n",
        "    \n",
        "    category_types = {}\n",
        "    for _, row in cdi_df.iterrows():\n",
        "        category_types[row['uni_lemma']] = {\n",
        "            'is_animate': bool(row.get('is_animate', 0)),\n",
        "            'is_bodypart': bool(row.get('is_bodypart', 0)),\n",
        "            'is_small': bool(row.get('is_small', 0)),\n",
        "            'is_big': bool(row.get('is_big', 0))\n",
        "        }\n",
        "    \n",
        "    print(f\"Loaded type information for {len(category_types)} categories\")\n",
        "    return category_types\n",
        "\n",
        "def load_cdi_category_mapping(cdi_path):\n",
        "    \"\"\"Load CDI category mapping (uni_lemma -> category) for coloring labels\"\"\"\n",
        "    cdi_df = pd.read_csv(cdi_path)\n",
        "    category_map = {}\n",
        "    for _, row in cdi_df.iterrows():\n",
        "        category_map[row['uni_lemma']] = row.get('category', 'unknown')\n",
        "    return category_map\n",
        "\n",
        "def get_category_color(category_name, category_map):\n",
        "    \"\"\"Get color for a category based on its CDI category type\"\"\"\n",
        "    # Define color scheme for CDI categories\n",
        "    category_colors = {\n",
        "        'animals': '#8B4513',  # Brown\n",
        "        'body_parts': '#FF6B6B',  # Red\n",
        "        'food_drink': '#FFA500',  # Orange\n",
        "        'furniture_rooms': '#4169E1',  # Royal Blue\n",
        "        'toys': '#FF69B4',  # Hot Pink\n",
        "        'vehicles': '#32CD32',  # Lime Green\n",
        "        'clothing': '#9370DB',  # Medium Purple\n",
        "        'outside': '#228B22',  # Forest Green\n",
        "        'places': '#4682B4',  # Steel Blue\n",
        "        'small_things': '#FFD700',  # Gold\n",
        "        'action_words': '#DC143C',  # Crimson\n",
        "        'descriptive_words': '#20B2AA',  # Light Sea Green\n",
        "        'sound_effects': '#FF1493',  # Deep Pink\n",
        "        'games_routines': '#00CED1',  # Dark Turquoise\n",
        "    }\n",
        "    \n",
        "    # Get the CDI category for this uni_lemma\n",
        "    cdi_category = category_map.get(category_name, 'unknown')\n",
        "    \n",
        "    # Return color, default to gray if not found\n",
        "    return category_colors.get(cdi_category, '#808080')  # Gray for unknown\n",
        "\n",
        "def cluster_categories_within_group(group_categories, cat_to_embedding, save_dendrogram=False, output_dir=None, group_name=None):\n",
        "    \"\"\"\n",
        "    Perform hierarchical clustering within a group of categories.\n",
        "    \n",
        "    Args:\n",
        "        group_categories: List of category names in the group\n",
        "        cat_to_embedding: Dictionary mapping category names to embeddings\n",
        "        save_dendrogram: Whether to save dendrogram plot (default: False)\n",
        "        output_dir: Output directory for saving dendrogram (required if save_dendrogram=True)\n",
        "        group_name: Name of the group for saving dendrogram (required if save_dendrogram=True)\n",
        "    \n",
        "    Returns:\n",
        "        List of category names reordered according to clustering dendrogram\n",
        "    \"\"\"\n",
        "    if len(group_categories) <= 1:\n",
        "        return group_categories, None\n",
        "    \n",
        "    # Get embeddings for this group\n",
        "    group_embeddings = np.array([cat_to_embedding[cat].flatten() for cat in group_categories])\n",
        "    \n",
        "    # Normalize embeddings (z-score normalization per embedding)\n",
        "    normalized_embeddings = (group_embeddings - group_embeddings.mean(axis=0)) / (group_embeddings.std(axis=0) + 1e-10)\n",
        "    \n",
        "    # Compute distance matrix (1 - cosine similarity)\n",
        "    similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    np.fill_diagonal(distance_matrix, 0)\n",
        "    \n",
        "    # Convert to condensed form for linkage\n",
        "    condensed_distances = squareform(distance_matrix)\n",
        "    \n",
        "    # Perform hierarchical clustering\n",
        "    linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "    \n",
        "    # Get optimal leaf ordering for better visualization\n",
        "    try:\n",
        "        linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "    except:\n",
        "        # If optimal leaf ordering fails, use original linkage\n",
        "        pass\n",
        "    \n",
        "    # Extract the order from the dendrogram\n",
        "    dendro_dict = dendrogram(linkage_matrix, no_plot=True)\n",
        "    leaf_order = dendro_dict['leaves']\n",
        "    \n",
        "    # Reorder categories according to clustering\n",
        "    clustered_categories = [group_categories[i] for i in leaf_order]\n",
        "    \n",
        "    # Save dendrogram if requested\n",
        "    if save_dendrogram and output_dir is not None and group_name is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        dendrogram(linkage_matrix, \n",
        "                  labels=group_categories,\n",
        "                  leaf_rotation=90,\n",
        "                  leaf_font_size=10)\n",
        "        plt.title(f'Hierarchical Clustering Dendrogram: {group_name.upper()}\\n({len(group_categories)} categories)',\n",
        "                 fontsize=16, pad=20)\n",
        "        plt.xlabel('Category', fontsize=12)\n",
        "        plt.ylabel('Distance', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save as PNG\n",
        "        output_path_png = output_dir / f'dendrogram_{group_name}.png'\n",
        "        plt.savefig(output_path_png, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_png}\")\n",
        "        \n",
        "        # Save as PDF\n",
        "        output_path_pdf = output_dir / f'dendrogram_{group_name}.pdf'\n",
        "        plt.savefig(output_path_pdf, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_pdf}\")\n",
        "        \n",
        "        plt.close()\n",
        "    \n",
        "    return clustered_categories, linkage_matrix\n",
        "\n",
        "print(\"Helper functions loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading categories from ../../data/things_bv_overlap_categories_exclude_zero_precisions.txt...\n",
            "Loaded 163 categories\n"
          ]
        }
      ],
      "source": [
        "# Load allowed categories if file exists\n",
        "allowed_categories = None\n",
        "if categories_file.exists():\n",
        "    print(f\"Loading categories from {categories_file}...\")\n",
        "    with open(categories_file, 'r') as f:\n",
        "        allowed_categories = set(line.strip() for line in f if line.strip())\n",
        "    print(f\"Loaded {len(allowed_categories)} categories\")\n",
        "else:\n",
        "    print(f\"Categories file not found, using all categories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Embeddings by Age\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pre-normalized embeddings from 163 categories...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading categories: 100%|██████████| 163/163 [00:01<00:00, 124.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded embeddings for 31 subjects\n",
            "Age bins found: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37]\n",
            "Age range: 6 to 37 months\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def load_embeddings_by_age(embeddings_dir, allowed_categories=None, excluded_subject=None, age_binning_strategy='exact', age_bin_size=3):\n",
        "    \"\"\"\n",
        "    Load pre-normalized embeddings organized by subject, age_mo, and category.\n",
        "    These embeddings are already normalized from notebook 05.\n",
        "    \n",
        "    Returns:\n",
        "        subject_age_embeddings: dict[subject_id][age_mo_bin][category] = embedding array (already normalized)\n",
        "    \"\"\"\n",
        "    subject_age_embeddings = defaultdict(lambda: defaultdict(dict))\n",
        "    \n",
        "    # Get all category folders\n",
        "    category_folders = [f for f in embeddings_dir.iterdir() if f.is_dir()]\n",
        "    \n",
        "    if allowed_categories:\n",
        "        category_folders = [f for f in category_folders if f.name in allowed_categories]\n",
        "    \n",
        "    print(f\"Loading pre-normalized embeddings from {len(category_folders)} categories...\")\n",
        "    \n",
        "    for category_folder in tqdm(category_folders, desc=\"Loading categories\"):\n",
        "        category = category_folder.name\n",
        "        \n",
        "        # Get all embedding files in this category\n",
        "        embedding_files = list(category_folder.glob(\"*.npy\"))\n",
        "        \n",
        "        for emb_file in embedding_files:\n",
        "            # Parse filename: {subject_id}_{age_mo}_month_level_avg.npy\n",
        "            filename = emb_file.stem  # without .npy\n",
        "            parts = filename.split('_')\n",
        "            \n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            \n",
        "            # Extract subject_id and age_mo\n",
        "            subject_id = parts[0]\n",
        "            \n",
        "            # Exclude subject if specified\n",
        "            if excluded_subject and subject_id == excluded_subject:\n",
        "                continue\n",
        "            \n",
        "            age_mo = int(parts[1]) if parts[1].isdigit() else None\n",
        "            \n",
        "            if age_mo is None:\n",
        "                continue\n",
        "            \n",
        "            # Apply age binning strategy\n",
        "            if age_binning_strategy == 'binned':\n",
        "                age_mo_bin = (age_mo // age_bin_size) * age_bin_size  # Round down to bin\n",
        "            else:\n",
        "                age_mo_bin = age_mo  # Use exact age\n",
        "            \n",
        "            try:\n",
        "                embedding = np.load(emb_file)\n",
        "                subject_age_embeddings[subject_id][age_mo_bin][category] = embedding\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {emb_file}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    return subject_age_embeddings\n",
        "\n",
        "# Load pre-normalized embeddings from notebook 05 (using exact ages - we'll do median split later)\n",
        "subject_age_embeddings = load_embeddings_by_age(\n",
        "    normalized_embeddings_dir,  # Use normalized embeddings from notebook 05\n",
        "    allowed_categories,\n",
        "    excluded_subject=excluded_subject,  # Exclude specified subject\n",
        "    age_binning_strategy='exact',  # Use exact ages\n",
        "    age_bin_size=1  # Not used when strategy is 'exact'\n",
        ")\n",
        "\n",
        "print(f\"\\nLoaded embeddings for {len(subject_age_embeddings)} subjects\")\n",
        "\n",
        "# Show age bin distribution\n",
        "all_age_bins = set()\n",
        "for subject_id, age_data in subject_age_embeddings.items():\n",
        "    all_age_bins.update(age_data.keys())\n",
        "\n",
        "print(f\"Age bins found: {sorted(all_age_bins)}\")\n",
        "print(f\"Age range: {min(all_age_bins)} to {max(all_age_bins)} months\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Overall Median Age\n",
        "\n",
        "We calculate the overall median age across all participants to split each subject's data into younger and older periods. Note: Embeddings are already normalized from notebook 05, so no normalization is performed here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall median age across all participants: 16.0 months\n",
            "Age range: 6 to 37 months\n",
            "Total age observations: 266\n",
            "\n",
            "Using pre-normalized embeddings for 31 subjects\n",
            "  Note: Embeddings were normalized in notebook 05 (within each subject across all age bins)\n",
            "  No additional normalization performed here\n",
            "\n",
            "Total unique categories across all subjects and ages: 163\n",
            "Note: RDMs will be computed with predefined category order after organization step.\n",
            "\n",
            "Identifying subjects with sufficient data in both age bins...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking subjects: 100%|██████████| 31/31 [00:00<00:00, 462.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Identified 18 subjects with sufficient data in both bins\n",
            "  Excluded 13 subjects without sufficient data in both bins\n",
            "\n",
            "Excluded subjects (13):\n",
            "  00220001: no older ages (younger: 155 cats, older: 0 cats)\n",
            "  00230001: no older ages (younger: 143 cats, older: 0 cats)\n",
            "  00340002: no older ages (younger: 99 cats, older: 0 cats)\n",
            "  00350001: no older ages (younger: 111 cats, older: 0 cats)\n",
            "  00350002: no older ages (younger: 123 cats, older: 0 cats)\n",
            "  00360001: no older ages (younger: 153 cats, older: 0 cats)\n",
            "  00390001: no older ages (younger: 141 cats, older: 0 cats)\n",
            "  00430002: no older ages (younger: 112 cats, older: 0 cats)\n",
            "  00440001: no older ages (younger: 134 cats, older: 0 cats)\n",
            "  00460001: no older ages (younger: 140 cats, older: 0 cats)\n",
            "  00550001: no older ages (younger: 132 cats, older: 0 cats)\n",
            "  00720001: no younger ages (younger: 0 cats, older: 154 cats)\n",
            "  00820001: no younger ages (younger: 0 cats, older: 160 cats)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Calculate Overall Median Age Across All Participants\n",
        "\n",
        "# Collect all age_mo values across all subjects to compute overall median\n",
        "all_ages = []\n",
        "for subject_id, age_data in subject_age_embeddings.items():\n",
        "    all_ages.extend(age_data.keys())\n",
        "\n",
        "overall_median_age = np.median(all_ages)\n",
        "print(f\"Overall median age across all participants: {overall_median_age:.1f} months\")\n",
        "print(f\"Age range: {min(all_ages)} to {max(all_ages)} months\")\n",
        "print(f\"Total age observations: {len(all_ages)}\")\n",
        "\n",
        "## Use Pre-Normalized Embeddings from Notebook 05\n",
        "\n",
        "# Embeddings are already normalized from notebook 05, so we use them directly\n",
        "# Rename for consistency with rest of code\n",
        "subject_age_embeddings_normalized = subject_age_embeddings\n",
        "\n",
        "print(f\"\\nUsing pre-normalized embeddings for {len(subject_age_embeddings_normalized)} subjects\")\n",
        "print(\"  Note: Embeddings were normalized in notebook 05 (within each subject across all age bins)\")\n",
        "print(\"  No additional normalization performed here\")\n",
        "\n",
        "## Aggregate Embeddings by Median Split and Compute RDMs\n",
        "\n",
        "def aggregate_embeddings_by_bin(age_embeddings_dict, age_bin_name):\n",
        "    \"\"\"\n",
        "    Aggregate embeddings for a bin by averaging across all ages in that bin.\n",
        "    \n",
        "    Args:\n",
        "        age_embeddings_dict: dict[age_mo][category] = embedding array\n",
        "        age_bin_name: 'younger' or 'older'\n",
        "    \n",
        "    Returns:\n",
        "        aggregated_embeddings: dict[category] = averaged embedding array\n",
        "    \"\"\"\n",
        "    # Collect all embeddings for each category across ages in this bin\n",
        "    category_embeddings = defaultdict(list)\n",
        "    \n",
        "    for age_mo, categories in age_embeddings_dict.items():\n",
        "        for cat, embedding in categories.items():\n",
        "            category_embeddings[cat].append(embedding)\n",
        "    \n",
        "    # Average embeddings for each category\n",
        "    aggregated = {}\n",
        "    for cat, embeddings_list in category_embeddings.items():\n",
        "        if len(embeddings_list) > 0:\n",
        "            aggregated[cat] = np.mean(embeddings_list, axis=0)\n",
        "    \n",
        "    return aggregated\n",
        "\n",
        "def compute_rdm_for_bin_with_na(bin_embeddings_dict, ordered_categories_list):\n",
        "    \"\"\"\n",
        "    Compute RDM for a single age bin (younger or older) with NA for missing categories.\n",
        "    This ensures consistent ordering across bins using the predefined category order.\n",
        "    \n",
        "    Args:\n",
        "        bin_embeddings_dict: dict[category] = embedding array (should be normalized and aggregated)\n",
        "        ordered_categories_list: list of all categories in desired order (may include categories not present for this bin)\n",
        "    \n",
        "    Returns:\n",
        "        rdm: numpy array of shape (n_categories, n_categories) with np.nan for missing categories\n",
        "        mask: boolean array of shape (n_categories, n_categories) where True indicates NA (missing category)\n",
        "        available_categories: list of categories actually present for this bin\n",
        "    \"\"\"\n",
        "    n_categories = len(ordered_categories_list)\n",
        "    \n",
        "    # Find available categories (categories that exist for this bin)\n",
        "    available_categories = [cat for cat in ordered_categories_list if cat in bin_embeddings_dict]\n",
        "    \n",
        "    if len(available_categories) < min_categories_per_age_bin:\n",
        "        # Return RDM full of NaN if not enough categories\n",
        "        rdm = np.full((n_categories, n_categories), np.nan)\n",
        "        mask = np.ones((n_categories, n_categories), dtype=bool)\n",
        "        return rdm, mask, available_categories\n",
        "    \n",
        "    # Build embedding matrix for available categories (already normalized)\n",
        "    embedding_matrix = np.array([bin_embeddings_dict[cat].flatten() for cat in available_categories])\n",
        "    \n",
        "    # Ensure 2D shape: (n_available_categories, embedding_dim)\n",
        "    if embedding_matrix.ndim != 2:\n",
        "        raise ValueError(f\"Expected 2D embedding matrix, got shape {embedding_matrix.shape}\")\n",
        "    \n",
        "    # Compute cosine similarity for available categories\n",
        "    similarity_matrix_available = cosine_similarity(embedding_matrix)\n",
        "    \n",
        "    # Convert to distance (RDM) for available categories\n",
        "    distance_matrix_available = 1 - similarity_matrix_available\n",
        "    np.fill_diagonal(distance_matrix_available, 0)  # Ensure diagonal is 0\n",
        "    \n",
        "    # Make symmetric (in case of numerical errors)\n",
        "    distance_matrix_available = (distance_matrix_available + distance_matrix_available.T) / 2\n",
        "    \n",
        "    # Create full RDM with NaN for missing categories\n",
        "    rdm = np.full((n_categories, n_categories), np.nan)\n",
        "    mask = np.ones((n_categories, n_categories), dtype=bool)\n",
        "    \n",
        "    # Map available categories to their indices in ordered_categories_list\n",
        "    available_indices = [ordered_categories_list.index(cat) for cat in available_categories]\n",
        "    \n",
        "    # Fill in the RDM for available categories\n",
        "    for i, idx_i in enumerate(available_indices):\n",
        "        for j, idx_j in enumerate(available_indices):\n",
        "            rdm[idx_i, idx_j] = distance_matrix_available[i, j]\n",
        "            mask[idx_i, idx_j] = False  # False means not NA (data present)\n",
        "    \n",
        "    return rdm, mask, available_categories\n",
        "\n",
        "# Get all unique categories across all subjects and ages\n",
        "all_categories = set()\n",
        "for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
        "    for age_mo, categories in age_data.items():\n",
        "        all_categories.update(categories.keys())\n",
        "\n",
        "all_categories = sorted(list(all_categories))\n",
        "print(f\"\\nTotal unique categories across all subjects and ages: {len(all_categories)}\")\n",
        "print(\"Note: RDMs will be computed with predefined category order after organization step.\")\n",
        "\n",
        "# First, identify which subjects have sufficient data in both bins\n",
        "# We'll compute actual RDMs after category organization\n",
        "print(f\"\\nIdentifying subjects with sufficient data in both age bins...\")\n",
        "subject_age_rdms = {}  # Temporary storage - will be recomputed with predefined order\n",
        "subject_age_rdm_categories = {}  # Temporary storage\n",
        "excluded_subjects = []  # Track excluded subjects and reasons\n",
        "\n",
        "for subject_id, age_data in tqdm(subject_age_embeddings_normalized.items(), desc=\"Checking subjects\"):\n",
        "    # Split ages into younger and older bins\n",
        "    younger_ages = {age_mo: categories for age_mo, categories in age_data.items() \n",
        "                    if age_mo <= overall_median_age}\n",
        "    older_ages = {age_mo: categories for age_mo, categories in age_data.items() \n",
        "                  if age_mo > overall_median_age}\n",
        "    \n",
        "    subject_age_rdms[subject_id] = {}\n",
        "    subject_age_rdm_categories[subject_id] = {}\n",
        "    \n",
        "    # Process younger bin\n",
        "    younger_has_rdm = False\n",
        "    younger_n_cats = 0\n",
        "    if len(younger_ages) > 0:\n",
        "        younger_aggregated = aggregate_embeddings_by_bin(younger_ages, 'younger')\n",
        "        younger_n_cats = len(younger_aggregated)\n",
        "        if younger_n_cats >= min_categories_per_age_bin:\n",
        "            younger_has_rdm = True\n",
        "            subject_age_rdms[subject_id]['younger'] = True  # Placeholder\n",
        "            subject_age_rdm_categories[subject_id]['younger'] = list(younger_aggregated.keys())\n",
        "    else:\n",
        "        excluded_subjects.append({\n",
        "            'subject_id': subject_id,\n",
        "            'reason': 'no younger ages',\n",
        "            'younger_n_cats': 0,\n",
        "            'older_n_cats': len(aggregate_embeddings_by_bin(older_ages, 'older')) if len(older_ages) > 0 else 0\n",
        "        })\n",
        "    \n",
        "    # Process older bin\n",
        "    older_has_rdm = False\n",
        "    older_n_cats = 0\n",
        "    if len(older_ages) > 0:\n",
        "        older_aggregated = aggregate_embeddings_by_bin(older_ages, 'older')\n",
        "        older_n_cats = len(older_aggregated)\n",
        "        if older_n_cats >= min_categories_per_age_bin:\n",
        "            older_has_rdm = True\n",
        "            subject_age_rdms[subject_id]['older'] = True  # Placeholder\n",
        "            subject_age_rdm_categories[subject_id]['older'] = list(older_aggregated.keys())\n",
        "    else:\n",
        "        excluded_subjects.append({\n",
        "            'subject_id': subject_id,\n",
        "            'reason': 'no older ages',\n",
        "            'younger_n_cats': younger_n_cats,\n",
        "            'older_n_cats': 0\n",
        "        })\n",
        "    \n",
        "    # Filter out subjects without both bins\n",
        "    if not younger_has_rdm or not older_has_rdm:\n",
        "        if subject_id not in [s['subject_id'] for s in excluded_subjects]:\n",
        "            # Determine specific reason\n",
        "            if not younger_has_rdm and not older_has_rdm:\n",
        "                reason = 'both bins insufficient'\n",
        "            elif not younger_has_rdm:\n",
        "                reason = f'younger bin insufficient ({younger_n_cats} < {min_categories_per_age_bin} cats)'\n",
        "            else:\n",
        "                reason = f'older bin insufficient ({older_n_cats} < {min_categories_per_age_bin} cats)'\n",
        "            \n",
        "            excluded_subjects.append({\n",
        "                'subject_id': subject_id,\n",
        "                'reason': reason,\n",
        "                'younger_n_cats': younger_n_cats,\n",
        "                'older_n_cats': older_n_cats\n",
        "            })\n",
        "        \n",
        "        del subject_age_rdms[subject_id]\n",
        "        del subject_age_rdm_categories[subject_id]\n",
        "\n",
        "print(f\"\\nIdentified {len(subject_age_rdms)} subjects with sufficient data in both bins\")\n",
        "print(f\"  Excluded {len(excluded_subjects)} subjects without sufficient data in both bins\")\n",
        "\n",
        "# Show excluded subjects details\n",
        "if len(excluded_subjects) > 0:\n",
        "    print(f\"\\nExcluded subjects ({len(excluded_subjects)}):\")\n",
        "    excluded_df = pd.DataFrame(excluded_subjects)\n",
        "    excluded_df = excluded_df.sort_values('subject_id')\n",
        "    for _, row in excluded_df.iterrows():\n",
        "        print(f\"  {row['subject_id']}: {row['reason']} (younger: {row['younger_n_cats']} cats, older: {row['older_n_cats']} cats)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique categories across all subjects and ages: 163\n",
            "\n",
            "Organizing categories...\n",
            "  Loading predefined category order from ../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt...\n",
            "  Loaded 163 categories in predefined order\n",
            "Loading category types from ../../data/cdi_words.csv...\n",
            "Loaded type information for 295 categories\n",
            "\n",
            "Final ordered category list: 163 categories\n"
          ]
        }
      ],
      "source": [
        "# Organize Categories (with Predefined List Option)\n",
        "# This section organizes categories either by loading a predefined category list (for consistent ordering across subjects) or by automatic organization.\n",
        "\n",
        "# Get all unique categories across all subjects and ages (needed for organization)\n",
        "all_categories = set()\n",
        "for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
        "    for age_mo, categories in age_data.items():\n",
        "        all_categories.update(categories.keys())\n",
        "\n",
        "all_categories = sorted(list(all_categories))\n",
        "print(f\"Total unique categories across all subjects and ages: {len(all_categories)}\")\n",
        "\n",
        "# Organize categories: either load predefined list or organize automatically\n",
        "print(\"\\nOrganizing categories...\")\n",
        "\n",
        "if USE_PREDEFINED_CATEGORY_LIST and PREDEFINED_CATEGORY_LIST_PATH is not None:\n",
        "    # Load predefined category list\n",
        "    predefined_path = Path(PREDEFINED_CATEGORY_LIST_PATH)\n",
        "    if not predefined_path.exists():\n",
        "        raise FileNotFoundError(f\"Predefined category list file not found: {predefined_path}\")\n",
        "    \n",
        "    print(f\"  Loading predefined category order from {predefined_path}...\")\n",
        "    with open(predefined_path, 'r') as f:\n",
        "        # Skip comment lines (lines starting with #)\n",
        "        ordered_categories = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]\n",
        "    \n",
        "    # Verify that all categories in predefined list exist in our data\n",
        "    predefined_set = set(ordered_categories)\n",
        "    all_categories_set = set(all_categories)\n",
        "    \n",
        "    if predefined_set != all_categories_set:\n",
        "        missing_in_predefined = all_categories_set - predefined_set\n",
        "        extra_in_predefined = predefined_set - all_categories_set\n",
        "        if missing_in_predefined:\n",
        "            print(f\"  Warning: {len(missing_in_predefined)} categories in data but not in predefined list: {sorted(missing_in_predefined)[:5]}...\")\n",
        "        if extra_in_predefined:\n",
        "            print(f\"  Warning: {len(extra_in_predefined)} categories in predefined list but not in data: {sorted(extra_in_predefined)[:5]}...\")\n",
        "        # Use intersection: only categories that exist in both\n",
        "        ordered_categories = [cat for cat in ordered_categories if cat in all_categories_set]\n",
        "        print(f\"  Using intersection: {len(ordered_categories)} categories\")\n",
        "    \n",
        "    print(f\"  Loaded {len(ordered_categories)} categories in predefined order\")\n",
        "    \n",
        "    # Still organize into groups for visualization boundaries (even though order is predefined)\n",
        "    # Load category types for grouping\n",
        "    if cdi_path.exists():\n",
        "        category_types = load_category_types(cdi_path)\n",
        "    else:\n",
        "        print(f\"Warning: CDI path {cdi_path} not found. Cannot compute group boundaries.\")\n",
        "        category_types = {}\n",
        "    \n",
        "    # Organize predefined categories into groups for visualization boundaries\n",
        "    organized = {\n",
        "        'animals': [],\n",
        "        'bodyparts': [],\n",
        "        'big_objects': [],\n",
        "        'small_objects': [],\n",
        "        'others': []\n",
        "    }\n",
        "    \n",
        "    for cat in ordered_categories:\n",
        "        if cat not in category_types:\n",
        "            organized['others'].append(cat)\n",
        "            continue\n",
        "        \n",
        "        types = category_types[cat]\n",
        "        if types['is_animate']:\n",
        "            organized['animals'].append(cat)\n",
        "        elif types['is_bodypart']:\n",
        "            organized['bodyparts'].append(cat)\n",
        "        elif types['is_big']:\n",
        "            organized['big_objects'].append(cat)\n",
        "        elif types['is_small']:\n",
        "            organized['small_objects'].append(cat)\n",
        "        else:\n",
        "            organized['others'].append(cat)\n",
        "    \n",
        "else:\n",
        "    # Automatic organization by type (similar to notebook 02)\n",
        "    print(f\"  Organizing categories by type...\")\n",
        "    \n",
        "    # Load category types for organization\n",
        "    if cdi_path.exists():\n",
        "        category_types = load_category_types(cdi_path)\n",
        "    else:\n",
        "        print(f\"Warning: CDI path {cdi_path} not found. Skipping category organization.\")\n",
        "        category_types = {}\n",
        "    \n",
        "    # Get a representative set of embeddings for clustering (average across all subjects and ages)\n",
        "    representative_embeddings = {}\n",
        "    for cat in all_categories:\n",
        "        cat_embeddings = []\n",
        "        for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
        "            for age_mo, categories in age_data.items():\n",
        "                if cat in categories:\n",
        "                    cat_embeddings.append(categories[cat])\n",
        "        if len(cat_embeddings) > 0:\n",
        "            # Average across all subjects and ages for this category\n",
        "            representative_embeddings[cat] = np.mean(cat_embeddings, axis=0)\n",
        "    \n",
        "    # Organize by type\n",
        "    organized = {\n",
        "        'animals': [],\n",
        "        'bodyparts': [],\n",
        "        'big_objects': [],\n",
        "        'small_objects': [],\n",
        "        'others': []\n",
        "    }\n",
        "    \n",
        "    for cat in all_categories:\n",
        "        if cat not in category_types:\n",
        "            organized['others'].append(cat)\n",
        "            continue\n",
        "        \n",
        "        types = category_types[cat]\n",
        "        if types['is_animate']:\n",
        "            organized['animals'].append(cat)\n",
        "        elif types['is_bodypart']:\n",
        "            organized['bodyparts'].append(cat)\n",
        "        elif types['is_big']:\n",
        "            organized['big_objects'].append(cat)\n",
        "        elif types['is_small']:\n",
        "            organized['small_objects'].append(cat)\n",
        "        else:\n",
        "            organized['others'].append(cat)\n",
        "    \n",
        "    print(f\"  Organized into: {len(organized['animals'])} animals, {len(organized['bodyparts'])} bodyparts, \"\n",
        "          f\"{len(organized['big_objects'])} big objects, {len(organized['small_objects'])} small objects, \"\n",
        "          f\"{len(organized['others'])} others\")\n",
        "    \n",
        "    # Apply hierarchical clustering if enabled\n",
        "    if use_clustering:\n",
        "        print(f\"  Applying hierarchical clustering within groups...\")\n",
        "        for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "            if len(organized[group_name]) > 1:\n",
        "                # Filter to categories that have representative embeddings\n",
        "                group_cats = [cat for cat in organized[group_name] if cat in representative_embeddings]\n",
        "                if len(group_cats) > 1:\n",
        "                    print(f\"    Clustering {group_name} ({len(group_cats)} categories)...\")\n",
        "                    organized[group_name], _ = cluster_categories_within_group(\n",
        "                        group_cats,\n",
        "                        representative_embeddings,\n",
        "                        save_dendrogram=save_dendrograms,\n",
        "                        output_dir=output_dir,\n",
        "                        group_name=group_name\n",
        "                    )\n",
        "                else:\n",
        "                    organized[group_name] = group_cats\n",
        "            else:\n",
        "                organized[group_name] = [cat for cat in organized[group_name] if cat in representative_embeddings]\n",
        "    else:\n",
        "        for group_name in organized:\n",
        "            organized[group_name] = sorted([cat for cat in organized[group_name] if cat in representative_embeddings])\n",
        "    \n",
        "    # Create ordered list\n",
        "    ordered_categories = (\n",
        "        organized['animals'] +\n",
        "        organized['bodyparts'] +\n",
        "        organized['big_objects'] +\n",
        "        organized['small_objects'] +\n",
        "        organized['others']\n",
        "    )\n",
        "\n",
        "print(f\"\\nFinal ordered category list: {len(ordered_categories)} categories\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# No age binning needed - we're using median split (younger/older)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grouped Developmental Trajectory Visualization\n",
        "\n",
        "Create a grouped visualization combining multiple subjects' developmental trajectory plots together in one figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating grouped developmental trajectory visualization...\n",
            "Plotting 18 subjects in grouped visualization...\n",
            "Warning: Shape mismatch for 00320001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00320001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00320001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00680001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00680001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00680001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00680001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320002 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00320002 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320002 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00320002 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00500001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00500001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00500001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00500001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00400001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00400001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00430001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00430001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00430001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00430001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00560001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00560001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00560001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00560001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00370001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00370001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00370001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00370001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400003 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00400003 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400003 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00400003 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00510001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00510001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00420001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00420001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00420001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00420001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510002 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00510002 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510002 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00510002 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00240001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00240001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00240001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00240001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00490001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00490001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00490001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00490001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320003 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00320003 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320003 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00320003 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400002 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00400002 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400002 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00400002 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00370002 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00370002 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00370002 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00370002 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00590001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00590001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00590001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00590001 older due to incompatible shapes\n",
            "Saved grouped visualization to developmental_trajectory_rdms_clip/grouped_trajectory_18_subjects.png\n",
            "\n",
            "Creating additional grouped visualization with first 12 subjects for better readability...\n",
            "Warning: Shape mismatch for 00320001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00320001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00320001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00680001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00680001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00680001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00680001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320002 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00320002 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00320002 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00320002 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00500001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00500001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00500001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00500001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00400001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00400001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00430001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00430001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00430001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00430001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00560001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00560001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00560001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00560001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00370001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00370001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00370001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00370001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400003 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00400003 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00400003 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00400003 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00510001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00510001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00420001 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00420001 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00420001 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00420001 older due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510002 younger: rdm () vs mask (163, 163)\n",
            "  Skipping 00510002 younger due to incompatible shapes\n",
            "Warning: Shape mismatch for 00510002 older: rdm () vs mask (163, 163)\n",
            "  Skipping 00510002 older due to incompatible shapes\n",
            "Saved 12-subject grouped visualization to developmental_trajectory_rdms_clip/grouped_trajectory_12_subjects.png\n",
            "\n",
            "Grouped visualization complete!\n"
          ]
        }
      ],
      "source": [
        "# Create grouped visualization combining N subjects' developmental trajectory plots\n",
        "print(\"Creating grouped developmental trajectory visualization...\")\n",
        "\n",
        "# Initialize subject_age_group_boundaries if it doesn't exist\n",
        "if 'subject_age_group_boundaries' not in globals():\n",
        "    subject_age_group_boundaries = {}\n",
        "    # Initialize empty dicts for all subjects\n",
        "    for sid in subject_age_rdms.keys():\n",
        "        subject_age_group_boundaries[sid] = {}\n",
        "        for bname in ['younger', 'older']:\n",
        "            if bname in subject_age_rdms[sid]:\n",
        "                subject_age_group_boundaries[sid][bname] = []\n",
        "\n",
        "# Load CDI category mapping for label coloring\n",
        "cdi_category_map = load_cdi_category_mapping(cdi_path)\n",
        "\n",
        "# Get all subjects with valid data\n",
        "valid_subjects = [sid for sid in subject_age_rdms.keys() \n",
        "                  if 'younger' in subject_age_rdms[sid] and 'older' in subject_age_rdms[sid]]\n",
        "\n",
        "if len(valid_subjects) == 0:\n",
        "    print(\"No subjects with valid data for grouped visualization\")\n",
        "else:\n",
        "    # Number of subjects to plot (can be adjusted)\n",
        "    # Set to None to plot all subjects, or specify a number\n",
        "    n_subjects_to_plot = None  # Change to a number like 6, 9, 12, etc. to limit\n",
        "    \n",
        "    subjects_to_plot = valid_subjects[:n_subjects_to_plot] if n_subjects_to_plot else valid_subjects\n",
        "    n_subjects = len(subjects_to_plot)\n",
        "    \n",
        "    print(f\"Plotting {n_subjects} subjects in grouped visualization...\")\n",
        "    \n",
        "    # Calculate global min/max for consistent color scale across all subjects\n",
        "    all_rdm_values = []\n",
        "    for subject_id in subjects_to_plot:\n",
        "        bin_rdms = subject_age_rdms[subject_id]\n",
        "        for bin_name in ['younger', 'older']:\n",
        "            rdm = bin_rdms[bin_name]\n",
        "            # Ensure rdm is a numpy array\n",
        "            if not isinstance(rdm, np.ndarray):\n",
        "                rdm = np.array(rdm)\n",
        "            # Only process if numeric array (not boolean)\n",
        "            if isinstance(rdm, np.ndarray) and rdm.size > 0 and rdm.dtype != bool:\n",
        "                valid_values = rdm[~np.isnan(rdm)]\n",
        "                if len(valid_values) > 0:\n",
        "                    all_rdm_values.extend(valid_values.tolist())\n",
        "    \n",
        "    vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "    vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "    \n",
        "    # Create figure with n_subjects rows and 2 columns (younger, older)\n",
        "    # Adjust figure size based on number of subjects\n",
        "    fig_height = max(4, n_subjects * 2.5)  # At least 4 inches, 2.5 inches per subject\n",
        "    fig_width = 16  # Keep consistent width\n",
        "    \n",
        "    fig, axes = plt.subplots(n_subjects, 2, figsize=(fig_width, fig_height))\n",
        "    \n",
        "    # Handle case where there's only one subject (axes would be 1D)\n",
        "    if n_subjects == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    else:\n",
        "        axes = axes.reshape(n_subjects, 2)\n",
        "    \n",
        "    # Determine font sizes based on number of categories\n",
        "    n_cats_total = len(ordered_categories)\n",
        "    if n_cats_total <= 50:\n",
        "        tick_fontsize = 8\n",
        "    elif n_cats_total <= 100:\n",
        "        tick_fontsize = 6\n",
        "    else:\n",
        "        tick_fontsize = 4\n",
        "    \n",
        "    # Plot each subject\n",
        "    for row_idx, subject_id in enumerate(subjects_to_plot):\n",
        "        bin_rdms = subject_age_rdms[subject_id]\n",
        "        # Check if masks exist, if not create empty masks\n",
        "        if \"subject_age_rdm_masks\" not in globals() or subject_age_rdm_masks is None:\n",
        "            # Create empty masks if not available\n",
        "            subject_age_rdm_masks = {}\n",
        "            for sid in subject_age_rdms.keys():\n",
        "                subject_age_rdm_masks[sid] = {}\n",
        "                for bname in [\"younger\", \"older\"]:\n",
        "                    if bname in subject_age_rdms[sid]:\n",
        "                        # Create mask with all False (no masking)\n",
        "                        rdm_shape = subject_age_rdms[sid][bname].shape if isinstance(subject_age_rdms[sid][bname], np.ndarray) else (0, 0)\n",
        "                        subject_age_rdm_masks[sid][bname] = np.zeros(rdm_shape, dtype=bool)\n",
        "        \n",
        "        bin_masks = subject_age_rdm_masks[subject_id]\n",
        "        \n",
        "        for col_idx, bin_name in enumerate(['younger', 'older']):\n",
        "            rdm = bin_rdms[bin_name]\n",
        "            mask = bin_masks[bin_name]\n",
        "            available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "            group_boundaries = subject_age_group_boundaries[subject_id][bin_name]\n",
        "            \n",
        "            ax = axes[row_idx, col_idx]\n",
        "            \n",
        "            # Ensure rdm is a numpy array with correct shape\n",
        "            rdm = np.array(rdm)\n",
        "            # Ensure mask is a numpy array with correct shape\n",
        "            mask = np.array(mask)\n",
        "            # Ensure shapes match\n",
        "            if rdm.shape != mask.shape:\n",
        "                print(f\"Warning: Shape mismatch for {subject_id} {bin_name}: rdm {rdm.shape} vs mask {mask.shape}\")\n",
        "                # Try to reshape or skip if incompatible\n",
        "                if rdm.size == mask.size:\n",
        "                    rdm = rdm.reshape(mask.shape)\n",
        "                else:\n",
        "                    print(f\"  Skipping {subject_id} {bin_name} due to incompatible shapes\")\n",
        "                    continue\n",
        "            \n",
        "            # Create masked array for visualization\n",
        "            rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "            cmap = plt.cm.get_cmap('viridis').copy()\n",
        "            cmap.set_bad(color='white', alpha=1.0)\n",
        "            im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "            \n",
        "            # Set category names as axis labels (only show every Nth label to avoid crowding)\n",
        "            n_cats = len(ordered_categories)\n",
        "            if n_cats <= 50:\n",
        "                tick_step = 1\n",
        "            elif n_cats <= 100:\n",
        "                tick_step = 2\n",
        "            else:\n",
        "                tick_step = max(1, n_cats // 50)\n",
        "            \n",
        "            ax.set_xticks(range(0, n_cats, tick_step))\n",
        "            ax.set_yticks(range(0, n_cats, tick_step))\n",
        "            ax.set_xticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)],\n",
        "                               rotation=90, ha=\"right\", fontsize=max(8, tick_fontsize))\n",
        "            ax.set_yticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)], \n",
        "                               fontsize=tick_fontsize)\n",
        "            \n",
        "            # Color code labels based on category\n",
        "            for i, (xlabel, ylabel) in enumerate(zip(ax.get_xticklabels(), ax.get_yticklabels())):\n",
        "                tick_idx = i * tick_step\n",
        "                if tick_idx < len(ordered_categories):\n",
        "                    cat_name = ordered_categories[tick_idx]\n",
        "                    color = get_category_color(cat_name, cdi_category_map)\n",
        "                    xlabel.set_color(color)\n",
        "                    ylabel.set_color(color)\n",
        "            \n",
        "            # Create title with subject ID and age info\n",
        "            n_cats_available = len(available_cats)\n",
        "            if bin_name == \"younger\":\n",
        "                title = f\"{subject_id} - Younger (≤{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "            else:\n",
        "                title = f\"{subject_id} - Older (>{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "            \n",
        "            ax.set_title(title, fontsize=10, pad=5)\n",
        "            \n",
        "            # Add colorbar only to the rightmost plots\n",
        "            if col_idx == 1:  # Right column\n",
        "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    \n",
        "    # Add overall title\n",
        "    plt.suptitle(f'Grouped Developmental Trajectories: {n_subjects} Subjects\\n(Median split at {overall_median_age:.1f} months)', \n",
        "                 fontsize=16, y=0.998, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "    \n",
        "    # Save the grouped visualization\n",
        "    output_filename = f\"grouped_trajectory_{n_subjects}_subjects.png\"\n",
        "    plt.savefig(output_dir / output_filename, dpi=200, bbox_inches='tight')\n",
        "    print(f\"Saved grouped visualization to {output_dir / output_filename}\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Also create a version with fewer subjects if there are many (for better readability)\n",
        "    if n_subjects > 12:\n",
        "        print(f\"\\nCreating additional grouped visualization with first 12 subjects for better readability...\")\n",
        "        subjects_to_plot_12 = valid_subjects[:12]\n",
        "        \n",
        "        fig_height_12 = 12 * 2.5\n",
        "        fig, axes = plt.subplots(12, 2, figsize=(fig_width, fig_height_12))\n",
        "        \n",
        "        for row_idx, subject_id in enumerate(subjects_to_plot_12):\n",
        "            bin_rdms = subject_age_rdms[subject_id]\n",
        "            # Check if masks exist, if not create empty masks\n",
        "            if \"subject_age_rdm_masks\" not in globals() or subject_age_rdm_masks is None:\n",
        "                # Create empty masks if not available\n",
        "                subject_age_rdm_masks = {}\n",
        "                for sid in subject_age_rdms.keys():\n",
        "                    subject_age_rdm_masks[sid] = {}\n",
        "                    for bname in [\"younger\", \"older\"]:\n",
        "                        if bname in subject_age_rdms[sid]:\n",
        "                            # Create mask with all False (no masking)\n",
        "                            rdm_shape = subject_age_rdms[sid][bname].shape if isinstance(subject_age_rdms[sid][bname], np.ndarray) else (0, 0)\n",
        "                            subject_age_rdm_masks[sid][bname] = np.zeros(rdm_shape, dtype=bool)\n",
        "            \n",
        "            bin_masks = subject_age_rdm_masks[subject_id]\n",
        "            \n",
        "            for col_idx, bin_name in enumerate(['younger', 'older']):\n",
        "                rdm = bin_rdms[bin_name]\n",
        "                mask = bin_masks[bin_name]\n",
        "                available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "                group_boundaries = subject_age_group_boundaries[subject_id][bin_name]\n",
        "                \n",
        "                ax = axes[row_idx, col_idx]\n",
        "                \n",
        "                # Ensure rdm is a numpy array with correct shape\n",
        "                rdm = np.array(rdm)\n",
        "                \n",
        "                # Ensure mask is a numpy array with correct shape\n",
        "                mask = np.array(mask)\n",
        "                \n",
        "                # Ensure shapes match\n",
        "                if rdm.shape != mask.shape:\n",
        "                    print(f\"Warning: Shape mismatch for {subject_id} {bin_name}: rdm {rdm.shape} vs mask {mask.shape}\")\n",
        "                    # Try to reshape or skip if incompatible\n",
        "                    if rdm.size == mask.size:\n",
        "                        rdm = rdm.reshape(mask.shape)\n",
        "                    else:\n",
        "                        print(f\"  Skipping {subject_id} {bin_name} due to incompatible shapes\")\n",
        "                        continue\n",
        "                \n",
        "                # Create masked array for visualization\n",
        "                rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "                cmap = plt.cm.get_cmap('viridis').copy()\n",
        "                cmap.set_bad(color='white', alpha=1.0)\n",
        "                im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "                \n",
        "                # Set category names as axis labels\n",
        "                n_cats = len(ordered_categories)\n",
        "                if n_cats <= 50:\n",
        "                    tick_step = 1\n",
        "                elif n_cats <= 100:\n",
        "                    tick_step = 2\n",
        "                else:\n",
        "                    tick_step = max(1, n_cats // 50)\n",
        "                \n",
        "                ax.set_xticks(range(0, n_cats, tick_step))\n",
        "                ax.set_yticks(range(0, n_cats, tick_step))\n",
        "                ax.set_xticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)],\n",
        "                                   rotation=90, ha=\"right\", fontsize=max(8, tick_fontsize))\n",
        "                ax.set_yticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)], \n",
        "                                   fontsize=tick_fontsize)\n",
        "                \n",
        "                # Color code labels based on category\n",
        "                for i, (xlabel, ylabel) in enumerate(zip(ax.get_xticklabels(), ax.get_yticklabels())):\n",
        "                    tick_idx = i * tick_step\n",
        "                    if tick_idx < len(ordered_categories):\n",
        "                        cat_name = ordered_categories[tick_idx]\n",
        "                        color = get_category_color(cat_name, cdi_category_map)\n",
        "                        xlabel.set_color(color)\n",
        "                        ylabel.set_color(color)\n",
        "                \n",
        "                # Create title with subject ID and age info\n",
        "                n_cats_available = len(available_cats)\n",
        "                if bin_name == \"younger\":\n",
        "                    title = f\"{subject_id} - Younger (≤{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "                else:\n",
        "                    title = f\"{subject_id} - Older (>{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "                \n",
        "                ax.set_title(title, fontsize=10, pad=5)\n",
        "                \n",
        "                # Add colorbar only to the rightmost plots\n",
        "                if col_idx == 1:  # Right column\n",
        "                    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "        \n",
        "        # Add overall title (outside the loops)\n",
        "        plt.suptitle(f'Grouped Developmental Trajectories: First 12 Subjects\\n(Median split at {overall_median_age:.1f} months)', \n",
        "                     fontsize=16, y=0.998, fontweight='bold')\n",
        "        \n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "        \n",
        "        output_filename_12 = f\"grouped_trajectory_12_subjects.png\"\n",
        "        plt.savefig(output_dir / output_filename_12, dpi=200, bbox_inches='tight')\n",
        "        print(f\"Saved 12-subject grouped visualization to {output_dir / output_filename_12}\")\n",
        "        plt.close()\n",
        "\n",
        "print(\"\\nGrouped visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Recomputing RDMs with predefined category order (including NaN for missing categories)...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recomputing RDMs: 100%|██████████| 18/18 [00:00<00:00, 64.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recomputed RDMs for 18 subjects using predefined category order\n",
            "  All RDMs now use the same 163-category order with NaN for missing categories\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Recompute RDMs using predefined category order with NaN for missing categories\n",
        "print(\"\\nRecomputing RDMs with predefined category order (including NaN for missing categories)...\")\n",
        "subject_age_rdms_reorganized = {}\n",
        "subject_age_rdm_masks = {}  # Store masks indicating NA cells\n",
        "subject_age_rdm_categories_reorganized = {}\n",
        "subject_age_group_boundaries = {}  # Store group boundaries for visual separators\n",
        "\n",
        "for subject_id in tqdm(subject_age_rdms.keys(), desc=\"Recomputing RDMs\"):\n",
        "    subject_age_rdms_reorganized[subject_id] = {}\n",
        "    subject_age_rdm_masks[subject_id] = {}\n",
        "    subject_age_rdm_categories_reorganized[subject_id] = {}\n",
        "    subject_age_group_boundaries[subject_id] = {}\n",
        "    \n",
        "    # Get original data for this subject\n",
        "    original_rdms = subject_age_rdms[subject_id]\n",
        "    original_categories = subject_age_rdm_categories[subject_id]\n",
        "    \n",
        "    # Recompute each bin's RDM using predefined order\n",
        "    for bin_name in ['younger', 'older']:\n",
        "        if bin_name not in original_rdms:\n",
        "            continue\n",
        "        \n",
        "        # Get aggregated embeddings for this bin\n",
        "        if bin_name == 'younger':\n",
        "            relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                           if age_mo <= overall_median_age}\n",
        "        else:  # older\n",
        "            relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                            if age_mo > overall_median_age}\n",
        "        \n",
        "        # Aggregate embeddings for this bin\n",
        "        bin_embeddings = aggregate_embeddings_by_bin(relevant_ages, bin_name)\n",
        "        \n",
        "        # Compute RDM with NaN for missing categories using predefined order\n",
        "        rdm, mask, available_cats = compute_rdm_for_bin_with_na(bin_embeddings, ordered_categories)\n",
        "        \n",
        "        if rdm is not None:\n",
        "            subject_age_rdms_reorganized[subject_id][bin_name] = rdm\n",
        "            subject_age_rdm_masks[subject_id][bin_name] = mask\n",
        "            subject_age_rdm_categories_reorganized[subject_id][bin_name] = available_cats\n",
        "            \n",
        "            # Compute group boundaries based on full ordered_categories (for visualization)\n",
        "            group_boundaries = []\n",
        "            current_idx = 0\n",
        "            for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "                group_cats = [cat for cat in organized[group_name] if cat in ordered_categories]\n",
        "                if len(group_cats) > 0:\n",
        "                    group_start = current_idx\n",
        "                    group_end = current_idx + len(group_cats)\n",
        "                    group_boundaries.append({\n",
        "                        'name': group_name,\n",
        "                        'start': group_start,\n",
        "                        'end': group_end,\n",
        "                        'categories': group_cats\n",
        "                    })\n",
        "                    current_idx = group_end\n",
        "            \n",
        "            subject_age_group_boundaries[subject_id][bin_name] = group_boundaries\n",
        "\n",
        "# Update the main dictionaries\n",
        "subject_age_rdms = subject_age_rdms_reorganized\n",
        "subject_age_rdm_categories = subject_age_rdm_categories_reorganized\n",
        "\n",
        "print(f\"Recomputed RDMs for {len(subject_age_rdms)} subjects using predefined category order\")\n",
        "print(f\"  All RDMs now use the same {len(ordered_categories)}-category order with NaN for missing categories\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save RDMs for Each Subject (Younger and Older Bins)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving developmental trajectory RDMs...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving RDMs: 100%|██████████| 18/18 [01:29<00:00,  4.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved RDMs to developmental_trajectory_rdms_clip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Save RDMs for each subject (younger and older bins)\n",
        "print(\"Saving developmental trajectory RDMs...\")\n",
        "\n",
        "for subject_id, bin_rdms in tqdm(subject_age_rdms.items(), desc=\"Saving RDMs\"):\n",
        "    subject_output_dir = output_dir / subject_id\n",
        "    subject_output_dir.mkdir(exist_ok=True, parents=True)\n",
        "    \n",
        "    for bin_name, rdm in bin_rdms.items():\n",
        "        available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "        \n",
        "        # Save as numpy array (includes NaN for missing categories)\n",
        "        np.save(subject_output_dir / f\"rdm_{bin_name}.npy\", rdm)\n",
        "        \n",
        "        # Save as CSV with category labels (use ordered_categories for full order)\n",
        "        rdm_df = pd.DataFrame(rdm, index=ordered_categories, columns=ordered_categories)\n",
        "        rdm_df.to_csv(subject_output_dir / f\"rdm_{bin_name}.csv\")\n",
        "        \n",
        "        # Save metadata\n",
        "        # Compute statistics only on valid (non-NaN) values\n",
        "        valid_rdm = rdm[~np.isnan(rdm)]\n",
        "        valid_rdm_positive = valid_rdm[valid_rdm > 0]\n",
        "        \n",
        "        metadata = {\n",
        "            'subject_id': subject_id,\n",
        "            'age_bin': bin_name,\n",
        "            'median_age_threshold': overall_median_age,\n",
        "            'n_categories_total': len(ordered_categories),\n",
        "            'n_categories_available': len(available_cats),\n",
        "            'n_categories_missing': len(ordered_categories) - len(available_cats),\n",
        "            'categories_available': available_cats,\n",
        "            'mean_distance': float(np.nanmean(rdm)),\n",
        "            'std_distance': float(np.nanstd(rdm)),\n",
        "            'min_distance': float(valid_rdm_positive.min()) if len(valid_rdm_positive) > 0 else np.nan,\n",
        "            'max_distance': float(np.nanmax(rdm))\n",
        "        }\n",
        "        \n",
        "        metadata_df = pd.DataFrame([metadata])\n",
        "        metadata_df.to_csv(subject_output_dir / f\"metadata_{bin_name}.csv\", index=False)\n",
        "\n",
        "        # Create and save individual dendrogram for this bin (using available categories only)\n",
        "        if len(available_cats) > 1:\n",
        "            # Get aggregated embeddings for this bin's available categories\n",
        "            # We need to reconstruct from the original normalized embeddings\n",
        "            bin_embeddings = {}\n",
        "            for cat in available_cats:\n",
        "                cat_embeddings = []\n",
        "                # Get all ages in this bin for this subject\n",
        "                if bin_name == 'younger':\n",
        "                    relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                                   if age_mo <= overall_median_age}\n",
        "                else:  # older\n",
        "                    relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                                    if age_mo > overall_median_age}\n",
        "                \n",
        "                for age_mo, age_cats in relevant_ages.items():\n",
        "                    if cat in age_cats:\n",
        "                        cat_embeddings.append(age_cats[cat])\n",
        "                \n",
        "                if len(cat_embeddings) > 0:\n",
        "                    bin_embeddings[cat] = np.mean(cat_embeddings, axis=0)\n",
        "            \n",
        "            if len(bin_embeddings) > 1:\n",
        "                # Build embedding matrix\n",
        "                embedding_matrix = np.array([bin_embeddings[cat].flatten() for cat in available_cats])\n",
        "                \n",
        "                # Normalize embeddings\n",
        "                normalized_embeddings = (embedding_matrix - embedding_matrix.mean(axis=0)) / (embedding_matrix.std(axis=0) + 1e-10)\n",
        "                \n",
        "                # Compute distance matrix\n",
        "                similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "                distance_matrix = 1 - similarity_matrix\n",
        "                np.fill_diagonal(distance_matrix, 0)\n",
        "                \n",
        "                # Convert to condensed form for linkage\n",
        "                condensed_distances = squareform(distance_matrix)\n",
        "                \n",
        "                # Perform hierarchical clustering\n",
        "                linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "                \n",
        "                # Get optimal leaf ordering\n",
        "                try:\n",
        "                    linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "                except:\n",
        "                    pass\n",
        "                \n",
        "                # Create dendrogram\n",
        "                plt.figure(figsize=(max(16, len(available_cats) * 0.5), 10))\n",
        "                dendrogram(linkage_matrix, \n",
        "                          labels=available_cats,\n",
        "                          leaf_rotation=90,\n",
        "                          leaf_font_size=max(8, min(14, 200 // len(available_cats))))\n",
        "                plt.title(f'Dendrogram: {subject_id} {bin_name.capitalize()} (≤{overall_median_age:.0f}mo vs >{overall_median_age:.0f}mo)\\n({len(available_cats)}/{len(ordered_categories)} categories)',\n",
        "                         fontsize=16, pad=20)\n",
        "                plt.xlabel('Category', fontsize=14)\n",
        "                plt.ylabel('Distance', fontsize=14)\n",
        "                plt.tight_layout()\n",
        "                \n",
        "                # Save dendrogram\n",
        "                dendrogram_dir = subject_output_dir / \"dendrograms\"\n",
        "                dendrogram_dir.mkdir(exist_ok=True, parents=True)\n",
        "                dendrogram_path = dendrogram_dir / f\"dendrogram_{bin_name}.png\"\n",
        "                plt.savefig(dendrogram_path, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "                plt.close()\n",
        "\n",
        "print(f\"\\nSaved RDMs to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Developmental Trajectories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Explanation: RDM Correlation Logic\n",
        "\n",
        "### Overview\n",
        "This section explains in detail how we compute correlations between younger and older RDMs for each subject, including how we handle missing categories (NaN values) and whether correlations are comparable across subjects.\n",
        "\n",
        "### RDM Structure\n",
        "Each subject has two RDMs (younger and older), both with shape (163, 163) corresponding to the full predefined category order:\n",
        "- **Diagonal elements**: Always 0 (distance from category to itself)\n",
        "- **Off-diagonal elements**: Distance values (0-2 range) for category pairs that exist in that age bin\n",
        "- **Missing categories**: Represented as NaN (white cells in visualization)\n",
        "\n",
        "### Step-by-Step Correlation Process\n",
        "\n",
        "#### Step 1: Identify Common Categories\n",
        "- **Input**: Two lists of available categories (`available_cats1` for younger, `available_cats2` for older) and the full `ordered_categories_list` (predefined order)\n",
        "- **Process**: Find categories that are in BOTH available lists, preserving the predefined order (NOT alphabetical)\n",
        "- **Output**: `common_categories` - categories present in BOTH age bins, in predefined order\n",
        "- **Example**: If younger has 150 categories and older has 155 categories, they might share 140 categories\n",
        "- **Key Point**: Order matters! We use the predefined order to ensure submatrices are aligned correctly\n",
        "\n",
        "#### Step 2: Map to Full Category Order\n",
        "- **Input**: `common_categories` and the full `ordered_categories` list (163 categories)\n",
        "- **Process**: Find the indices of common categories in the full ordered list\n",
        "- **Output**: `common_indices` - positions in the 163x163 RDM matrices\n",
        "- **Purpose**: This ensures we extract the correct submatrices from the full RDMs\n",
        "\n",
        "#### Step 3: Extract Submatrices\n",
        "- **Input**: Full 163x163 RDMs and `common_indices`\n",
        "- **Process**: Extract square submatrices using `rdm[np.ix_(common_indices, common_indices)]`\n",
        "- **Output**: Two smaller square matrices (e.g., 140x140 if 140 common categories)\n",
        "- **Key Point**: These submatrices contain ONLY the common categories, but may still have NaN if there are any data issues\n",
        "\n",
        "#### Step 4: Extract Upper Triangle\n",
        "- **Process**: Use a triangular mask to extract only the upper triangle (excluding diagonal)\n",
        "- **Why**: RDMs are symmetric, so we only need half the values to avoid double-counting\n",
        "- **Output**: Two flattened arrays of pairwise distances\n",
        "- **Size**: If n common categories, we get n×(n-1)/2 distance values\n",
        "\n",
        "#### Step 5: Filter NaN Values\n",
        "- **Process**: Create a boolean mask identifying valid (non-NaN) values in BOTH arrays\n",
        "- **Filter**: Keep only pairs where BOTH RDMs have valid values\n",
        "- **Output**: Two arrays of the same length with only valid distance pairs\n",
        "- **Safety Check**: Even though we only use common categories, this ensures no NaN values slip through\n",
        "\n",
        "#### Step 6: Compute Spearman Correlation\n",
        "- **Method**: Spearman rank correlation (non-parametric, robust to outliers)\n",
        "- **Input**: Two arrays of valid distance values (same length, same category pairs)\n",
        "- **Output**: Correlation coefficient (-1 to 1)\n",
        "- **Interpretation**: \n",
        "  - High correlation (>0.7): Similar representational structure across age bins\n",
        "  - Low correlation (<0.5): Representational structure changed with development\n",
        "  - Near 0: No relationship between structures\n",
        "\n",
        "### Handling NaN Values\n",
        "\n",
        "**Where NaN values come from:**\n",
        "1. Categories not present in a particular age bin (expected)\n",
        "2. Categories present but with insufficient data (rare, but possible)\n",
        "\n",
        "**How we handle them:**\n",
        "1. **Pre-filtering**: We only use categories present in BOTH bins (common categories)\n",
        "2. **Submatrix extraction**: We extract only the common category submatrices\n",
        "3. **Post-filtering**: We filter out any remaining NaN values before correlation\n",
        "4. **Result**: The correlation is computed only on valid distance pairs\n",
        "\n",
        "**Why this works:**\n",
        "- By using only common categories, we ensure we're comparing the same category pairs\n",
        "- The correlation reflects how similarly those common categories are organized in younger vs older periods\n",
        "- Missing categories don't affect the correlation (they're simply excluded)\n",
        "\n",
        "### Comparability Across Subjects\n",
        "\n",
        "**Are correlations comparable across subjects?**\n",
        "\n",
        "**YES, with important caveats:**\n",
        "\n",
        "1. **Same correlation metric**: All subjects use Spearman correlation on the same type of data (distance matrices)\n",
        "\n",
        "2. **Different category sets**: Each subject may have different numbers of common categories:\n",
        "   - Subject A: 140 common categories → 9,730 distance pairs\n",
        "   - Subject B: 150 common categories → 11,175 distance pairs\n",
        "   - Subject C: 130 common categories → 8,385 distance pairs\n",
        "\n",
        "3. **Interpretation considerations**:\n",
        "   - **Absolute correlation values ARE comparable**: A correlation of 0.8 means the same thing for all subjects (strong similarity between age bins)\n",
        "   - **Statistical power varies**: Subjects with more common categories have more data points, so their correlations may be more reliable\n",
        "   - **Missing categories don't bias**: As long as we use only common categories, missing categories don't affect the correlation value\n",
        "\n",
        "4. **What makes correlations comparable**:\n",
        "   - Same age split (median = 16 months for all)\n",
        "   - Same normalization (within-subject z-score normalization)\n",
        "   - Same distance metric (cosine distance)\n",
        "   - Same correlation method (Spearman)\n",
        "   - Only common categories used (fair comparison)\n",
        "\n",
        "5. **What to consider when comparing**:\n",
        "   - **Number of common categories**: Tracked in `n_common_categories` - more categories = more reliable\n",
        "   - **Category composition**: Different subjects may have different sets of common categories\n",
        "   - **Data density**: Subjects with more data in both bins may have more stable RDMs\n",
        "\n",
        "### Example Walkthrough\n",
        "\n",
        "**Subject 00240001:**\n",
        "- Younger bin: 155 categories available\n",
        "- Older bin: 160 categories available\n",
        "- Common categories: 150 categories\n",
        "- Extracted submatrices: 150×150 (22,500 cells)\n",
        "- Upper triangle: 11,175 distance pairs\n",
        "- After NaN filtering: 11,175 valid pairs (assuming all common categories have data)\n",
        "- Spearman correlation: 0.756\n",
        "- **Interpretation**: Strong similarity (0.756) between younger and older representational structures, based on 150 common categories\n",
        "\n",
        "**Subject 00320001:**\n",
        "- Younger bin: 140 categories available\n",
        "- Older bin: 145 categories available\n",
        "- Common categories: 135 categories\n",
        "- Extracted submatrices: 135×135 (18,225 cells)\n",
        "- Upper triangle: 9,045 distance pairs\n",
        "- After NaN filtering: 9,045 valid pairs\n",
        "- Spearman correlation: 0.682\n",
        "- **Interpretation**: Moderate similarity (0.682) between age bins, based on 135 common categories\n",
        "\n",
        "**Comparison**: Subject 00240001 has a higher correlation (0.756 vs 0.682), suggesting more stable representational structure across development. However, we should also consider that Subject 00240001 has more common categories (150 vs 135), which provides more data for the correlation.\n",
        "\n",
        "### Summary\n",
        "\n",
        "The correlation logic:\n",
        "1. ✅ Uses only categories present in BOTH age bins (fair comparison)\n",
        "2. ✅ Filters out all NaN values before correlation\n",
        "3. ✅ Uses Spearman correlation (robust, non-parametric)\n",
        "4. ✅ Produces comparable values across subjects\n",
        "5. ⚠️ But correlations should be interpreted with awareness of the number of common categories\n",
        "\n",
        "**Key insight**: The correlation tells us how similarly categories are organized in younger vs older periods, but only for the categories that exist in both periods. This is appropriate for developmental trajectory analysis because we want to know: \"For the categories this child experienced at both ages, how stable was their representational structure?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Null Model: Age-Shuffled Baseline\n",
        "\n",
        "To interpret whether the within-kid correlations reflect true developmental stability or just stable individual differences, we implement a null model by randomly shuffling age labels per subject. \n",
        "\n",
        "### What the Null Model Tests\n",
        "\n",
        "**Real Split (Median Age)**: Uses actual chronological ages → captures both:\n",
        "- **Developmental changes** (how representations change with age)\n",
        "- **Stable individual differences** (consistent patterns unique to each child)\n",
        "\n",
        "**Null Model (Age-Shuffled)**: Randomly shuffles age labels within each subject → destroys temporal structure but preserves:\n",
        "- **Stable individual differences** (child-specific patterns remain)\n",
        "- **No developmental signal** (age information is scrambled)\n",
        "\n",
        "### How to Interpret Results\n",
        "\n",
        "**Scenario 1: Real >> Null (Large Positive Difference)**\n",
        "- **Interpretation**: Strong developmental stability signal\n",
        "- **Meaning**: The median age split captures genuine developmental changes. Representations are more similar within age periods than would be expected by chance.\n",
        "- **Example**: Real = 0.75, Null = 0.50 → Difference = 0.25 indicates strong developmental structure\n",
        "\n",
        "**Scenario 2: Real ≈ Null (Small Difference)**\n",
        "- **Interpretation**: Weak or no developmental signal\n",
        "- **Meaning**: High correlations are primarily due to stable individual differences, not developmental changes. The median split doesn't capture meaningful developmental structure.\n",
        "- **Example**: Real = 0.75, Null = 0.72 → Difference = 0.03 suggests mostly stable individual patterns\n",
        "\n",
        "**Scenario 3: Real < Null (Negative Difference)**\n",
        "- **Interpretation**: Unusual pattern (rare)\n",
        "- **Meaning**: Shuffled splits are more correlated than real splits, suggesting the median split might be creating artificial structure or there's something unexpected in the data.\n",
        "\n",
        "### Key Metrics to Check\n",
        "\n",
        "1. **Mean Difference (Real - Null)**: \n",
        "   - Large positive (>0.1): Strong developmental signal\n",
        "   - Small positive (0.01-0.1): Weak developmental signal\n",
        "   - Near zero (<0.01): No developmental signal, just stable individual differences\n",
        "\n",
        "2. **Effect Size (Cohen's d)**:\n",
        "   - d > 0.8: Large effect (strong developmental signal)\n",
        "   - 0.5 < d < 0.8: Medium effect\n",
        "   - d < 0.5: Small effect\n",
        "\n",
        "3. **Proportion of Subjects with Real > Null**:\n",
        "   - >90%: Consistent developmental signal across subjects\n",
        "   - 50-90%: Mixed pattern\n",
        "   - <50%: Concerning (suggests median split may not be appropriate)\n",
        "\n",
        "4. **Statistical Significance (p-value)**:\n",
        "   - p < 0.05: Statistically significant difference\n",
        "   - p > 0.05: No significant difference (null model cannot be rejected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing null model with age-shuffled splits...\n",
            "This will help interpret whether correlations reflect developmental stability or just stable individual differences.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null model: 100%|██████████| 18/18 [00:30<00:00,  1.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Null model analysis:\n",
            "  Total permutations: 1800\n",
            "  Subjects analyzed: 18\n",
            "\n",
            "Real vs Null correlations:\n",
            "  Real correlation mean: 0.756 ± 0.071\n",
            "  Null correlation mean: 0.782 ± 0.066\n",
            "  Difference: -0.026\n",
            "  Cohen's d (effect size): -0.383\n",
            "  t-test: t=-1.682, p=9.28e-02\n",
            "\n",
            "Per-subject comparison (Real vs Null mean):\n",
            "  Mean difference per subject: -0.026 ± 0.023\n",
            "  Subjects with real > null: 3 / 18\n",
            "\n",
            "Saved null model results to developmental_trajectory_rdms_clip/null_model_age_shuffled_correlations.csv\n",
            "Saved comparison to developmental_trajectory_rdms_clip/real_vs_null_comparison.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Null Model: Randomly shuffle age labels per subject\n",
        "print(\"Computing null model with age-shuffled splits...\")\n",
        "print(\"This will help interpret whether correlations reflect developmental stability or just stable individual differences.\\n\")\n",
        "\n",
        "n_permutations = 100  # Number of random shuffles per subject\n",
        "null_model_data = []\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "for subject_id, age_data in tqdm(subject_age_rdms.items(), desc=\"Null model\"):\n",
        "    if 'younger' not in subject_age_rdms[subject_id] or 'older' not in subject_age_rdms[subject_id]:\n",
        "        continue\n",
        "    \n",
        "    # Get original age data for this subject\n",
        "    original_age_data = subject_age_embeddings_normalized[subject_id]\n",
        "    original_ages = list(original_age_data.keys())\n",
        "    \n",
        "    # Store correlations for this subject across permutations\n",
        "    subject_null_corrs = []\n",
        "    \n",
        "    for perm_idx in range(n_permutations):\n",
        "        # Randomly shuffle age labels for this subject\n",
        "        shuffled_ages = original_ages.copy()\n",
        "        np.random.shuffle(shuffled_ages)\n",
        "        \n",
        "        # Create shuffled age mapping: original_age -> shuffled_age\n",
        "        age_mapping = {orig_age: shuffled_age for orig_age, shuffled_age in zip(original_ages, shuffled_ages)}\n",
        "        \n",
        "        # Create shuffled age data structure\n",
        "        shuffled_age_data = {}\n",
        "        for orig_age, categories in original_age_data.items():\n",
        "            shuffled_age = age_mapping[orig_age]\n",
        "            shuffled_age_data[shuffled_age] = categories\n",
        "        \n",
        "        # Split into younger and older using the same median threshold\n",
        "        shuffled_younger_ages = {age_mo: cats for age_mo, cats in shuffled_age_data.items() \n",
        "                                if age_mo <= overall_median_age}\n",
        "        shuffled_older_ages = {age_mo: cats for age_mo, cats in shuffled_age_data.items() \n",
        "                              if age_mo > overall_median_age}\n",
        "        \n",
        "        # Aggregate embeddings for shuffled bins\n",
        "        shuffled_younger_aggregated = aggregate_embeddings_by_bin(shuffled_younger_ages, 'younger')\n",
        "        shuffled_older_aggregated = aggregate_embeddings_by_bin(shuffled_older_ages, 'older')\n",
        "        \n",
        "        # Check if we have enough categories in both bins\n",
        "        if len(shuffled_younger_aggregated) < min_categories_per_age_bin or len(shuffled_older_aggregated) < min_categories_per_age_bin:\n",
        "            continue\n",
        "        \n",
        "        # Compute RDMs for shuffled bins\n",
        "        rdm_younger_shuffled, mask_younger, cats_younger_shuffled = compute_rdm_for_bin_with_na(\n",
        "            shuffled_younger_aggregated, ordered_categories\n",
        "        )\n",
        "        rdm_older_shuffled, mask_older, cats_older_shuffled = compute_rdm_for_bin_with_na(\n",
        "            shuffled_older_aggregated, ordered_categories\n",
        "        )\n",
        "        \n",
        "        if rdm_younger_shuffled is None or rdm_older_shuffled is None:\n",
        "            continue\n",
        "        \n",
        "        # Compute correlation between shuffled bins\n",
        "        corr_shuffled, n_common_shuffled = compute_rdm_correlation(\n",
        "            rdm_younger_shuffled, rdm_older_shuffled,\n",
        "            ordered_categories,\n",
        "            cats_younger_shuffled, cats_older_shuffled\n",
        "        )\n",
        "        \n",
        "        if not np.isnan(corr_shuffled):\n",
        "            subject_null_corrs.append(corr_shuffled)\n",
        "            null_model_data.append({\n",
        "                'subject_id': subject_id,\n",
        "                'permutation': perm_idx,\n",
        "                'correlation': corr_shuffled,\n",
        "                'n_common_categories': n_common_shuffled\n",
        "            })\n",
        "    \n",
        "    # Store summary statistics for this subject\n",
        "    if len(subject_null_corrs) > 0:\n",
        "        null_model_data.append({\n",
        "            'subject_id': subject_id,\n",
        "            'permutation': 'mean',\n",
        "            'correlation': np.mean(subject_null_corrs),\n",
        "            'n_common_categories': np.nan  # Not applicable for mean\n",
        "        })\n",
        "\n",
        "null_model_df = pd.DataFrame(null_model_data)\n",
        "null_model_df.to_csv(output_dir / \"null_model_age_shuffled_correlations.csv\", index=False)\n",
        "\n",
        "# Compute summary statistics\n",
        "print(f\"\\nNull model analysis:\")\n",
        "print(f\"  Total permutations: {len(null_model_df[null_model_df['permutation'] != 'mean'])}\")\n",
        "print(f\"  Subjects analyzed: {len(null_model_df[null_model_df['permutation'] == 'mean'])}\")\n",
        "\n",
        "# Compare real vs null correlations\n",
        "real_corrs = trajectory_df['rdm_correlation'].dropna().values\n",
        "null_corrs = null_model_df[null_model_df['permutation'] != 'mean']['correlation'].dropna().values\n",
        "\n",
        "if len(null_corrs) > 0:\n",
        "    print(f\"\\nReal vs Null correlations:\")\n",
        "    print(f\"  Real correlation mean: {np.mean(real_corrs):.3f} ± {np.std(real_corrs):.3f}\")\n",
        "    print(f\"  Null correlation mean: {np.mean(null_corrs):.3f} ± {np.std(null_corrs):.3f}\")\n",
        "    print(f\"  Difference: {np.mean(real_corrs) - np.mean(null_corrs):.3f}\")\n",
        "    \n",
        "    # Compute effect size (Cohen's d)\n",
        "    pooled_std = np.sqrt((np.var(real_corrs) + np.var(null_corrs)) / 2)\n",
        "    if pooled_std > 0:\n",
        "        cohens_d = (np.mean(real_corrs) - np.mean(null_corrs)) / pooled_std\n",
        "        print(f\"  Cohen's d (effect size): {cohens_d:.3f}\")\n",
        "    \n",
        "    # Statistical test\n",
        "    from scipy import stats\n",
        "    t_stat, p_value = stats.ttest_ind(real_corrs, null_corrs)\n",
        "    print(f\"  t-test: t={t_stat:.3f}, p={p_value:.2e}\")\n",
        "    \n",
        "    # Per-subject comparison\n",
        "    print(f\"\\nPer-subject comparison (Real vs Null mean):\")\n",
        "    subject_null_means = null_model_df[null_model_df['permutation'] == 'mean'].set_index('subject_id')['correlation']\n",
        "    comparison_data = []\n",
        "    for subject_id in trajectory_df['subject_id']:\n",
        "        real_corr = trajectory_df[trajectory_df['subject_id'] == subject_id]['rdm_correlation'].values[0]\n",
        "        if subject_id in subject_null_means.index:\n",
        "            null_mean = subject_null_means[subject_id]\n",
        "            diff = real_corr - null_mean\n",
        "            comparison_data.append({\n",
        "                'subject_id': subject_id,\n",
        "                'real_correlation': real_corr,\n",
        "                'null_mean_correlation': null_mean,\n",
        "                'difference': diff\n",
        "            })\n",
        "    \n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    comparison_df.to_csv(output_dir / \"real_vs_null_comparison.csv\", index=False)\n",
        "    \n",
        "    print(f\"  Mean difference per subject: {comparison_df['difference'].mean():.3f} ± {comparison_df['difference'].std():.3f}\")\n",
        "    print(f\"  Subjects with real > null: {len(comparison_df[comparison_df['difference'] > 0])} / {len(comparison_df)}\")\n",
        "    \n",
        "    print(f\"\\nSaved null model results to {output_dir / 'null_model_age_shuffled_correlations.csv'}\")\n",
        "    print(f\"Saved comparison to {output_dir / 'real_vs_null_comparison.csv'}\")\n",
        "else:\n",
        "    print(\"  Warning: No valid null correlations computed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating visualization for real vs null model correlations...\n",
            "Saved visualization to developmental_trajectory_rdms_clip/null_model_age_shuffled_comparison.png\n",
            "\n",
            "Visualization complete!\n"
          ]
        }
      ],
      "source": [
        "# Visualize real vs null model correlations\n",
        "print(\"Creating visualization for real vs null model correlations...\")\n",
        "\n",
        "if len(null_corrs) > 0 and len(real_corrs) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Distribution comparison\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.hist(real_corrs, bins=20, alpha=0.7, label='Real (median split)', color='#4ECDC4', edgecolor='black')\n",
        "    ax1.hist(null_corrs, bins=20, alpha=0.7, label='Null (age-shuffled)', color='#FF6B6B', edgecolor='black')\n",
        "    ax1.axvline(np.mean(real_corrs), color='#4ECDC4', linestyle='--', linewidth=2, label=f'Real mean: {np.mean(real_corrs):.3f}')\n",
        "    ax1.axvline(np.mean(null_corrs), color='#FF6B6B', linestyle='--', linewidth=2, label=f'Null mean: {np.mean(null_corrs):.3f}')\n",
        "    ax1.set_xlabel('RDM Correlation', fontsize=12)\n",
        "    ax1.set_ylabel('Frequency', fontsize=12)\n",
        "    ax1.set_title('Distribution: Real vs Null Correlations', fontsize=13, pad=10)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Box plot comparison\n",
        "    ax2 = axes[0, 1]\n",
        "    box_data = [real_corrs, null_corrs]\n",
        "    bp = ax2.boxplot(box_data, labels=['Real', 'Null'], patch_artist=True)\n",
        "    colors_box = ['#4ECDC4', '#FF6B6B']\n",
        "    for patch, color in zip(bp['boxes'], colors_box):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "    ax2.set_ylabel('RDM Correlation', fontsize=12)\n",
        "    ax2.set_title('Box Plot: Real vs Null', fontsize=13, pad=10)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    ax2.set_ylim([0, 1])\n",
        "    \n",
        "    # 3. Per-subject comparison\n",
        "    if len(comparison_df) > 0:\n",
        "        ax3 = axes[1, 0]\n",
        "        x_pos = np.arange(len(comparison_df))\n",
        "        width = 0.35\n",
        "        ax3.bar(x_pos - width/2, comparison_df['real_correlation'], width, \n",
        "               label='Real', alpha=0.7, color='#4ECDC4', edgecolor='black')\n",
        "        ax3.bar(x_pos + width/2, comparison_df['null_mean_correlation'], width,\n",
        "               label='Null (mean)', alpha=0.7, color='#FF6B6B', edgecolor='black')\n",
        "        ax3.set_xlabel('Subject', fontsize=12)\n",
        "        ax3.set_ylabel('RDM Correlation', fontsize=12)\n",
        "        ax3.set_title('Per-Subject: Real vs Null Mean', fontsize=13, pad=10)\n",
        "        ax3.set_xticks(x_pos)\n",
        "        ax3.set_xticklabels(comparison_df['subject_id'], rotation=45, ha='right', fontsize=8)\n",
        "        ax3.legend()\n",
        "        ax3.grid(True, alpha=0.3, axis='y')\n",
        "        ax3.set_ylim([0, 1])\n",
        "        \n",
        "        # 4. Difference distribution\n",
        "        ax4 = axes[1, 1]\n",
        "        differences = comparison_df['difference']\n",
        "        ax4.hist(differences, bins=20, alpha=0.7, color='#45B7D1', edgecolor='black')\n",
        "        ax4.axvline(0, color='red', linestyle='--', linewidth=2, label='No difference')\n",
        "        ax4.axvline(np.mean(differences), color='green', linestyle='--', linewidth=2, \n",
        "                   label=f'Mean: {np.mean(differences):.3f}')\n",
        "        ax4.set_xlabel('Difference (Real - Null)', fontsize=12)\n",
        "        ax4.set_ylabel('Frequency', fontsize=12)\n",
        "        ax4.set_title('Distribution of Differences', fontsize=13, pad=10)\n",
        "        ax4.legend()\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Null Model: Real vs Age-Shuffled Correlations\\n(Testing Developmental Stability vs Stable Individual Differences)', \n",
        "                 fontsize=14, y=0.995, fontweight='bold')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "    plt.savefig(output_dir / \"null_model_age_shuffled_comparison.png\", dpi=200, bbox_inches='tight')\n",
        "    print(f\"Saved visualization to {output_dir / 'null_model_age_shuffled_comparison.png'}\")\n",
        "    plt.close()\n",
        "    \n",
        "    print(\"\\nVisualization complete!\")\n",
        "else:\n",
        "    print(\"  Warning: Insufficient data for visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpreting Null Model Results\n",
        "\n",
        "**Your Results:**\n",
        "- Real correlation: 0.756 ± 0.071\n",
        "- Null correlation: 0.782 ± 0.066\n",
        "- Difference: -0.026 (negative!)\n",
        "- Only 3/18 subjects show real > null\n",
        "\n",
        "### What This Means\n",
        "\n",
        "**The negative difference indicates that the median age split is NOT capturing developmental structure.** Instead:\n",
        "\n",
        "1. **High correlations (0.756) are primarily due to stable individual differences**, not developmental changes\n",
        "2. **Random age shuffling produces HIGHER correlations** (0.782), suggesting the age-based split may be breaking up naturally similar timepoints\n",
        "3. **The median split may be introducing noise** by separating timepoints that are actually more similar than the split suggests\n",
        "\n",
        "### Possible Explanations\n",
        "\n",
        "1. **Individual differences dominate**: Each child has a stable representational structure that doesn't change much with age in this dataset\n",
        "2. **Median split may not align with developmental transitions**: The 16-month median might not correspond to a meaningful developmental boundary\n",
        "3. **Age range may be too narrow**: If most data is clustered around similar ages, the split may be arbitrary\n",
        "4. **Sampling effects**: The way data was collected might not capture developmental changes\n",
        "\n",
        "### What This Means for Your Analysis\n",
        "\n",
        "- **Within-kid correlations (0.756) are meaningful** but reflect **stable individual differences**, not developmental stability\n",
        "- **Cross-kid correlations** (comparing different children) are still valid and interesting\n",
        "- **The median age split** may not be the right approach for detecting developmental changes in this dataset\n",
        "\n",
        "### Potential Next Steps\n",
        "\n",
        "1. **Examine age distribution**: Check if ages are evenly distributed or clustered\n",
        "2. **Try alternative splits**: \n",
        "   - Tertiles or quartiles instead of median\n",
        "   - Age-based thresholds (e.g., 12mo, 18mo, 24mo)\n",
        "   - Equal-sized bins rather than median-based\n",
        "3. **Analyze age effects directly**: Correlate RDMs with continuous age rather than binary splits\n",
        "4. **Focus on individual differences**: The high correlations suggest stable individual patterns are the main signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "DIAGNOSTIC: Investigating Age Distribution and Split Characteristics\n",
            "======================================================================\n",
            "\n",
            "1. AGE DISTRIBUTION:\n",
            "   Total age observations: 266\n",
            "   Age range: 6.0 to 37.0 months\n",
            "   Median age: 16.0 months\n",
            "   Mean age: 16.6 months\n",
            "   Std age: 5.8 months\n",
            "\n",
            "   Split at 16.0 months:\n",
            "   Below/equal: 146 observations (mean: 12.5 ± 2.6)\n",
            "   Above: 120 observations (mean: 21.6 ± 4.5)\n",
            "\n",
            "2. PER-SUBJECT AGE CHARACTERISTICS:\n",
            "   Mean age range per subject: 10.7 ± 4.5 months\n",
            "   Mean split balance (min/max): 0.508\n",
            "   Subjects with very unbalanced splits (<0.3): 4\n",
            "\n",
            "3. RELATIONSHIP BETWEEN AGE RANGE AND CORRELATION DIFFERENCE:\n",
            "   Correlation (age_range vs difference): 0.342\n",
            "   Correlation (split_balance vs difference): -0.003\n",
            "\n",
            "   Subjects with largest negative differences (real << null):\n",
            "     00680001: diff=-0.080, range=4.0mo, balance=0.25\n",
            "     00510001: diff=-0.062, range=7.0mo, balance=0.60\n",
            "     00590001: diff=-0.053, range=4.0mo, balance=0.67\n",
            "     00370001: diff=-0.047, range=10.0mo, balance=0.57\n",
            "     00400001: diff=-0.037, range=19.0mo, balance=0.54\n",
            "\n",
            "======================================================================\n",
            "INTERPRETATION:\n",
            "======================================================================\n",
            "⚠️  NULL MODEL SHOWS HIGHER CORRELATIONS THAN REAL MODEL\n",
            "\n",
            "This suggests:\n",
            "  • High correlations (0.756) are primarily due to STABLE INDIVIDUAL DIFFERENCES\n",
            "  • The median age split is NOT capturing developmental structure\n",
            "  • The split may be breaking up naturally similar timepoints\n",
            "\n",
            "Possible reasons:\n",
            "  • Individual differences dominate over age-related changes\n",
            "  • Age range may be too narrow to see developmental effects\n",
            "  • Median split may not align with meaningful developmental transitions\n",
            "  • Data collection may not capture developmental changes\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Diagnostic: Investigate why null > real\n",
        "print(\"=\"*70)\n",
        "print(\"DIAGNOSTIC: Investigating Age Distribution and Split Characteristics\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Check age distribution\n",
        "print(\"\\n1. AGE DISTRIBUTION:\")\n",
        "all_ages_list = []\n",
        "for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
        "    all_ages_list.extend(age_data.keys())\n",
        "\n",
        "all_ages_array = np.array(all_ages_list)\n",
        "print(f\"   Total age observations: {len(all_ages_array)}\")\n",
        "print(f\"   Age range: {all_ages_array.min():.1f} to {all_ages_array.max():.1f} months\")\n",
        "print(f\"   Median age: {np.median(all_ages_array):.1f} months\")\n",
        "print(f\"   Mean age: {np.mean(all_ages_array):.1f} months\")\n",
        "print(f\"   Std age: {np.std(all_ages_array):.1f} months\")\n",
        "\n",
        "# Check distribution around median\n",
        "below_median = all_ages_array[all_ages_array <= overall_median_age]\n",
        "above_median = all_ages_array[all_ages_array > overall_median_age]\n",
        "print(f\"\\n   Split at {overall_median_age:.1f} months:\")\n",
        "print(f\"   Below/equal: {len(below_median)} observations (mean: {np.mean(below_median):.1f} ± {np.std(below_median):.1f})\")\n",
        "print(f\"   Above: {len(above_median)} observations (mean: {np.mean(above_median):.1f} ± {np.std(above_median):.1f})\")\n",
        "\n",
        "# 2. Check per-subject age distributions\n",
        "print(\"\\n2. PER-SUBJECT AGE CHARACTERISTICS:\")\n",
        "subject_age_stats = []\n",
        "for subject_id in trajectory_df['subject_id']:\n",
        "    if subject_id in subject_age_embeddings_normalized:\n",
        "        ages = np.array(list(subject_age_embeddings_normalized[subject_id].keys()))\n",
        "        n_below = np.sum(ages <= overall_median_age)\n",
        "        n_above = np.sum(ages > overall_median_age)\n",
        "        age_range = ages.max() - ages.min()\n",
        "        subject_age_stats.append({\n",
        "            'subject_id': subject_id,\n",
        "            'n_ages': len(ages),\n",
        "            'age_min': ages.min(),\n",
        "            'age_max': ages.max(),\n",
        "            'age_range': age_range,\n",
        "            'age_mean': ages.mean(),\n",
        "            'n_below_median': n_below,\n",
        "            'n_above_median': n_above,\n",
        "            'split_balance': min(n_below, n_above) / max(n_below, n_above) if max(n_below, n_above) > 0 else 0\n",
        "        })\n",
        "\n",
        "age_stats_df = pd.DataFrame(subject_age_stats)\n",
        "print(f\"   Mean age range per subject: {age_stats_df['age_range'].mean():.1f} ± {age_stats_df['age_range'].std():.1f} months\")\n",
        "print(f\"   Mean split balance (min/max): {age_stats_df['split_balance'].mean():.3f}\")\n",
        "print(f\"   Subjects with very unbalanced splits (<0.3): {len(age_stats_df[age_stats_df['split_balance'] < 0.3])}\")\n",
        "\n",
        "# 3. Check if there's a relationship between age range and correlation difference\n",
        "if len(comparison_df) > 0:\n",
        "    print(\"\\n3. RELATIONSHIP BETWEEN AGE RANGE AND CORRELATION DIFFERENCE:\")\n",
        "    merged = comparison_df.merge(age_stats_df, on='subject_id')\n",
        "    if len(merged) > 0:\n",
        "        corr_age_range = np.corrcoef(merged['age_range'], merged['difference'])[0, 1]\n",
        "        corr_split_balance = np.corrcoef(merged['split_balance'], merged['difference'])[0, 1]\n",
        "        print(f\"   Correlation (age_range vs difference): {corr_age_range:.3f}\")\n",
        "        print(f\"   Correlation (split_balance vs difference): {corr_split_balance:.3f}\")\n",
        "        \n",
        "        # Show subjects with largest negative differences\n",
        "        print(f\"\\n   Subjects with largest negative differences (real << null):\")\n",
        "        top_negative = merged.nsmallest(5, 'difference')[['subject_id', 'difference', 'age_range', 'split_balance']]\n",
        "        for _, row in top_negative.iterrows():\n",
        "            print(f\"     {row['subject_id']}: diff={row['difference']:.3f}, range={row['age_range']:.1f}mo, balance={row['split_balance']:.2f}\")\n",
        "\n",
        "# 4. Summary interpretation\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INTERPRETATION:\")\n",
        "print(\"=\"*70)\n",
        "if np.mean(null_corrs) > np.mean(real_corrs):\n",
        "    print(\"⚠️  NULL MODEL SHOWS HIGHER CORRELATIONS THAN REAL MODEL\")\n",
        "    print(\"\\nThis suggests:\")\n",
        "    print(\"  • High correlations (0.756) are primarily due to STABLE INDIVIDUAL DIFFERENCES\")\n",
        "    print(\"  • The median age split is NOT capturing developmental structure\")\n",
        "    print(\"  • The split may be breaking up naturally similar timepoints\")\n",
        "    print(\"\\nPossible reasons:\")\n",
        "    print(\"  • Individual differences dominate over age-related changes\")\n",
        "    print(\"  • Age range may be too narrow to see developmental effects\")\n",
        "    print(\"  • Median split may not align with meaningful developmental transitions\")\n",
        "    print(\"  • Data collection may not capture developmental changes\")\n",
        "else:\n",
        "    print(\"✓ Real model shows higher correlations - developmental signal detected\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save diagnostic data\n",
        "age_stats_df.to_csv(output_dir / \"age_distribution_diagnostics.csv\", index=False)\n",
        "if len(comparison_df) > 0 and len(age_stats_df) > 0:\n",
        "    merged.to_csv(output_dir / \"correlation_age_relationship.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First-Order Similarity: Category-Wise Embedding Correlations\n",
        "\n",
        "In addition to second-order similarity (RDM correlations that compare the geometric structure), we also compute first-order similarity by directly comparing individual category embeddings.\n",
        "\n",
        "**Second-order (RDM correlation)**: Compares the structure/geometry of representations\n",
        "- \"Are the relationships between categories similar?\"\n",
        "- Example: If \"dog\" and \"cat\" are similar in younger period, are they also similar in older period?\n",
        "\n",
        "**First-order (category embedding correlation)**: Compares individual category embeddings directly\n",
        "- \"Are the individual category representations similar?\"\n",
        "- Example: Is the embedding for \"dog\" in younger period similar to \"dog\" in older period?\n",
        "\n",
        "### Within-Kid First-Order Similarity\n",
        "For each subject, for each category present in both younger and older bins, compute the correlation between the category embeddings. Then average across categories to get a within-kid first-order similarity score.\n",
        "\n",
        "### Between-Kid First-Order Similarity\n",
        "For each pair of subjects, for each category present in both subjects, compute the correlation between the category embeddings. Can compare:\n",
        "- Younger-Younger: subject 1 younger vs subject 2 younger\n",
        "- Older-Older: subject 1 older vs subject 2 older\n",
        "- Younger-Older: subject 1 younger vs subject 2 older\n",
        "- Older-Younger: subject 1 older vs subject 2 younger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing first-order similarity (category-wise embedding correlations)...\n",
            "This compares individual category embeddings directly, rather than the geometric structure.\n",
            "\n",
            "1. Computing within-kid first-order similarity (younger vs older for same subject)...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Within-kid first-order: 100%|██████████| 18/18 [00:01<00:00, 16.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Within-kid first-order similarity:\n",
            "  Subjects analyzed: 18\n",
            "  Mean Spearman correlation: 0.718 ± 0.057\n",
            "  Mean Pearson correlation: 0.726 ± 0.057\n",
            "  Mean categories per subject: 144.1\n",
            "\n",
            "Saved to developmental_trajectory_rdms_clip/within_kid_first_order_similarity.csv\n",
            "\n",
            "2. Computing between-kid first-order similarity...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Between-kid first-order: 100%|██████████| 18/18 [00:35<00:00,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Between-kid first-order similarity:\n",
            "  Total comparisons: 612\n",
            "  Subject pairs: 153\n",
            "\n",
            "  younger_younger:\n",
            "    Mean correlation: 0.631 ± 0.078\n",
            "    N comparisons: 153\n",
            "\n",
            "  older_older:\n",
            "    Mean correlation: 0.600 ± 0.052\n",
            "    N comparisons: 153\n",
            "\n",
            "  younger_older:\n",
            "    Mean correlation: 0.609 ± 0.077\n",
            "    N comparisons: 153\n",
            "\n",
            "  older_younger:\n",
            "    Mean correlation: 0.620 ± 0.055\n",
            "    N comparisons: 153\n",
            "\n",
            "Saved to developmental_trajectory_rdms_clip/between_kid_first_order_similarity.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# First-Order Similarity: Category-wise embedding correlations\n",
        "print(\"Computing first-order similarity (category-wise embedding correlations)...\")\n",
        "print(\"This compares individual category embeddings directly, rather than the geometric structure.\\n\")\n",
        "\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "\n",
        "def compute_first_order_correlation(embedding1, embedding2):\n",
        "    \"\"\"\n",
        "    Compute correlation between two category embeddings.\n",
        "    \n",
        "    Args:\n",
        "        embedding1: numpy array of embedding for category in first condition\n",
        "        embedding2: numpy array of embedding for category in second condition\n",
        "    \n",
        "    Returns:\n",
        "        spearman_corr: Spearman correlation coefficient\n",
        "        pearson_corr: Pearson correlation coefficient\n",
        "    \"\"\"\n",
        "    # Flatten embeddings if needed\n",
        "    emb1_flat = embedding1.flatten()\n",
        "    emb2_flat = embedding2.flatten()\n",
        "    \n",
        "    # Ensure same length\n",
        "    if len(emb1_flat) != len(emb2_flat):\n",
        "        return np.nan, np.nan\n",
        "    \n",
        "    # Compute correlations\n",
        "    spearman_corr, _ = spearmanr(emb1_flat, emb2_flat)\n",
        "    pearson_corr, _ = pearsonr(emb1_flat, emb2_flat)\n",
        "    \n",
        "    return spearman_corr, pearson_corr\n",
        "\n",
        "# ============================================================================\n",
        "# WITHIN-KID FIRST-ORDER SIMILARITY (Category-wise)\n",
        "# ============================================================================\n",
        "print(\"1. Computing within-kid first-order similarity (younger vs older for same subject)...\")\n",
        "print(\"   Computing correlations for EACH category separately, then aggregating across subjects.\\n\")\n",
        "\n",
        "within_kid_category_wise_data = []\n",
        "within_kid_summary_data = []\n",
        "\n",
        "for subject_id in tqdm(subject_age_rdms.keys(), desc=\"Within-kid first-order\"):\n",
        "    if 'younger' not in subject_age_rdms[subject_id] or 'older' not in subject_age_rdms[subject_id]:\n",
        "        continue\n",
        "    \n",
        "    # Get aggregated embeddings for younger and older bins\n",
        "    younger_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                   if age_mo <= overall_median_age}\n",
        "    older_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                  if age_mo > overall_median_age}\n",
        "    \n",
        "    younger_aggregated = aggregate_embeddings_by_bin(younger_ages, 'younger')\n",
        "    older_aggregated = aggregate_embeddings_by_bin(older_ages, 'older')\n",
        "    \n",
        "    # Find common categories\n",
        "    common_categories = [cat for cat in younger_aggregated.keys() if cat in older_aggregated.keys()]\n",
        "    \n",
        "    if len(common_categories) < 2:\n",
        "        continue\n",
        "    \n",
        "        # Compute correlation for each category separately\n",
        "    category_correlations = []\n",
        "    category_pearson_correlations = []\n",
        "    for cat in common_categories:\n",
        "        emb_younger = younger_aggregated[cat]\n",
        "        emb_older = older_aggregated[cat]\n",
        "        \n",
        "        spearman_corr, pearson_corr = compute_first_order_correlation(emb_younger, emb_older)\n",
        "        \n",
        "        if not np.isnan(spearman_corr):\n",
        "            within_kid_category_wise_data.append({\n",
        "                'subject_id': subject_id,\n",
        "                'category': cat,\n",
        "                'spearman_correlation': spearman_corr,\n",
        "                'pearson_correlation': pearson_corr\n",
        "            })\n",
        "            category_correlations.append(spearman_corr)\n",
        "    \n",
        "    if len(category_correlations) > 0:\n",
        "        # Store summary per subject\n",
        "        within_kid_summary_data.append({\n",
        "            'subject_id': subject_id,\n",
        "            'n_common_categories': len(category_correlations),\n",
        "            'mean_spearman_correlation': np.mean(category_correlations),\n",
        "            'mean_pearson_correlation': np.mean([c['pearson_correlation'] for c in within_kid_category_wise_data \n",
        "                                                 if c['subject_id'] == subject_id]),\n",
        "            'std_spearman_correlation': np.std(category_correlations)\n",
        "        })\n",
        "\n",
        "# Save category-wise data\n",
        "within_kid_category_wise_df = pd.DataFrame(within_kid_category_wise_data)\n",
        "within_kid_category_wise_df.to_csv(output_dir / \"within_kid_first_order_category_wise.csv\", index=False)\n",
        "\n",
        "# Aggregate by category across all subjects\n",
        "category_aggregated = within_kid_category_wise_df.groupby('category').agg({\n",
        "    'spearman_correlation': ['mean', 'std', 'count'],\n",
        "    'pearson_correlation': ['mean', 'std']\n",
        "}).reset_index()\n",
        "category_aggregated.columns = ['category', 'mean_spearman', 'std_spearman', 'n_subjects', \n",
        "                               'mean_pearson', 'std_pearson']\n",
        "category_aggregated = category_aggregated.sort_values('mean_spearman', ascending=False)\n",
        "category_aggregated.to_csv(output_dir / \"within_kid_first_order_by_category.csv\", index=False)\n",
        "\n",
        "within_kid_summary_df = pd.DataFrame(within_kid_summary_data)\n",
        "within_kid_summary_df.to_csv(output_dir / \"within_kid_first_order_similarity.csv\", index=False)\n",
        "\n",
        "print(f\"\\nWithin-kid first-order similarity:\")\n",
        "print(f\"  Subjects analyzed: {len(within_kid_summary_df)}\")\n",
        "print(f\"  Total category-subject pairs: {len(within_kid_category_wise_df)}\")\n",
        "print(f\"  Mean Spearman correlation (across all): {within_kid_category_wise_df['spearman_correlation'].mean():.3f} ± {within_kid_category_wise_df['spearman_correlation'].std():.3f}\")\n",
        "print(f\"\\nTop 10 most correlated categories (across subjects):\")\n",
        "for _, row in category_aggregated.head(10).iterrows():\n",
        "    print(f\"  {row['category']:20s}: {row['mean_spearman']:.3f} ± {row['std_spearman']:.3f} (n={int(row['n_subjects'])})\")\n",
        "print(f\"\\nBottom 10 least correlated categories:\")\n",
        "for _, row in category_aggregated.tail(10).iterrows():\n",
        "    print(f\"  {row['category']:20s}: {row['mean_spearman']:.3f} ± {row['std_spearman']:.3f} (n={int(row['n_subjects'])})\")\n",
        "print(f\"\\nSaved category-wise data to {output_dir / 'within_kid_first_order_category_wise.csv'}\")\n",
        "print(f\"Saved aggregated by category to {output_dir / 'within_kid_first_order_by_category.csv'}\")\n",
        "\n",
        "# ============================================================================\n",
        "# BETWEEN-KID FIRST-ORDER SIMILARITY (Category-wise)\n",
        "# ============================================================================\n",
        "print(\"\\n2. Computing between-kid first-order similarity...\")\n",
        "print(\"   Computing correlations for EACH category separately, then aggregating across subject pairs.\\n\")\n",
        "\n",
        "valid_subjects = [sid for sid in subject_age_rdms.keys() \n",
        "                  if 'younger' in subject_age_rdms[sid] and 'older' in subject_age_rdms[sid]]\n",
        "\n",
        "between_kid_category_wise_data = []\n",
        "between_kid_summary_data = []\n",
        "\n",
        "for i, subject_id_1 in enumerate(tqdm(valid_subjects, desc=\"Between-kid first-order\")):\n",
        "    for subject_id_2 in valid_subjects[i+1:]:  # Only upper triangle\n",
        "        # Get aggregated embeddings for both subjects\n",
        "        younger_ages_1 = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id_1].items() \n",
        "                        if age_mo <= overall_median_age}\n",
        "        older_ages_1 = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id_1].items() \n",
        "                        if age_mo > overall_median_age}\n",
        "        younger_ages_2 = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id_2].items() \n",
        "                         if age_mo <= overall_median_age}\n",
        "        older_ages_2 = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id_2].items() \n",
        "                       if age_mo > overall_median_age}\n",
        "        \n",
        "        younger_agg_1 = aggregate_embeddings_by_bin(younger_ages_1, 'younger')\n",
        "        older_agg_1 = aggregate_embeddings_by_bin(older_ages_1, 'older')\n",
        "        younger_agg_2 = aggregate_embeddings_by_bin(younger_ages_2, 'younger')\n",
        "        older_agg_2 = aggregate_embeddings_by_bin(older_ages_2, 'older')\n",
        "        \n",
        "        # Compute correlations for each comparison type\n",
        "        comparison_types = [\n",
        "            ('younger_younger', younger_agg_1, younger_agg_2),\n",
        "            ('older_older', older_agg_1, older_agg_2),\n",
        "            ('younger_older', younger_agg_1, older_agg_2),\n",
        "            ('older_younger', older_agg_1, younger_agg_2)\n",
        "        ]\n",
        "        \n",
        "        for comp_type, emb_dict_1, emb_dict_2 in comparison_types:\n",
        "            # Find common categories\n",
        "            common_cats = [cat for cat in emb_dict_1.keys() if cat in emb_dict_2.keys()]\n",
        "            \n",
        "            if len(common_cats) < 2:\n",
        "                continue\n",
        "            \n",
        "            # Compute correlation for each category separately\n",
        "            category_corrs = []\n",
        "            for cat in common_cats:\n",
        "                emb_1 = emb_dict_1[cat]\n",
        "                emb_2 = emb_dict_2[cat]\n",
        "                \n",
        "                spearman_corr, pearson_corr = compute_first_order_correlation(emb_1, emb_2)\n",
        "                \n",
        "                if not np.isnan(spearman_corr):\n",
        "                    between_kid_category_wise_data.append({\n",
        "                        'subject_id_1': subject_id_1,\n",
        "                        'subject_id_2': subject_id_2,\n",
        "                        'comparison_type': comp_type,\n",
        "                        'category': cat,\n",
        "                        'spearman_correlation': spearman_corr,\n",
        "                        'pearson_correlation': pearson_corr\n",
        "                    })\n",
        "                    category_corrs.append(spearman_corr)\n",
        "            \n",
        "            if len(category_corrs) > 0:\n",
        "                between_kid_summary_data.append({\n",
        "                    'subject_id_1': subject_id_1,\n",
        "                    'subject_id_2': subject_id_2,\n",
        "                    'comparison_type': comp_type,\n",
        "                    'n_common_categories': len(category_corrs),\n",
        "                    'mean_spearman_correlation': np.mean(category_corrs),\n",
        "                    'std_spearman_correlation': np.std(category_corrs)\n",
        "                })\n",
        "\n",
        "# Save category-wise data\n",
        "between_kid_category_wise_df = pd.DataFrame(between_kid_category_wise_data)\n",
        "between_kid_category_wise_df.to_csv(output_dir / \"between_kid_first_order_category_wise.csv\", index=False)\n",
        "\n",
        "# Aggregate by category and comparison type\n",
        "category_comparison_agg = between_kid_category_wise_df.groupby(['category', 'comparison_type']).agg({\n",
        "    'spearman_correlation': ['mean', 'std', 'count']\n",
        "}).reset_index()\n",
        "category_comparison_agg.columns = ['category', 'comparison_type', 'mean_spearman', 'std_spearman', 'n_pairs']\n",
        "\n",
        "# Also aggregate across all comparison types\n",
        "category_agg_all = between_kid_category_wise_df.groupby('category').agg({\n",
        "    'spearman_correlation': ['mean', 'std', 'count']\n",
        "}).reset_index()\n",
        "category_agg_all.columns = ['category', 'mean_spearman', 'std_spearman', 'n_pairs']\n",
        "category_agg_all = category_agg_all.sort_values('mean_spearman', ascending=False)\n",
        "category_agg_all.to_csv(output_dir / \"between_kid_first_order_by_category.csv\", index=False)\n",
        "\n",
        "between_kid_summary_df = pd.DataFrame(between_kid_summary_data)\n",
        "between_kid_summary_df.to_csv(output_dir / \"between_kid_first_order_similarity.csv\", index=False)\n",
        "\n",
        "print(f\"\\nBetween-kid first-order similarity:\")\n",
        "print(f\"  Total comparisons: {len(between_kid_summary_df)}\")\n",
        "print(f\"  Total category-pair comparisons: {len(between_kid_category_wise_df)}\")\n",
        "print(f\"  Subject pairs: {len(valid_subjects) * (len(valid_subjects) - 1) // 2}\")\n",
        "\n",
        "for comp_type in ['younger_younger', 'older_older', 'younger_older', 'older_younger']:\n",
        "    type_data = between_kid_summary_df[between_kid_summary_df['comparison_type'] == comp_type]\n",
        "    if len(type_data) > 0:\n",
        "        print(f\"\\n  {comp_type}:\")\n",
        "        print(f\"    Mean correlation: {type_data['mean_spearman_correlation'].mean():.3f} ± {type_data['mean_spearman_correlation'].std():.3f}\")\n",
        "        print(f\"    N comparisons: {len(type_data)}\")\n",
        "\n",
        "print(f\"\\nTop 10 most correlated categories (across all subject pairs):\")\n",
        "for _, row in category_agg_all.head(10).iterrows():\n",
        "    print(f\"  {row['category']:20s}: {row['mean_spearman']:.3f} ± {row['std_spearman']:.3f} (n={int(row['n_pairs'])})\")\n",
        "\n",
        "print(f\"\\nSaved category-wise data to {output_dir / 'between_kid_first_order_category_wise.csv'}\")\n",
        "print(f\"Saved aggregated by category to {output_dir / 'between_kid_first_order_by_category.csv'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        }
      ],
      "source": [
        "# Visualize first-order similarity with category-wise breakdown\n",
        "print(\"Creating visualizations for first-order similarity...\")\n",
        "\n",
        "# Check if the data exists (from previous cell)\n",
        "if 'within_kid_summary_df' not in globals() or len(within_kid_summary_df) == 0:\n",
        "    print(\"Warning: within_kid_summary_df not found. Please run the previous cell first.\")\n",
        "else:\n",
        "    # Merge first-order and second-order results for comparison (using summary data)\n",
        "    comparison_data = []\n",
        "    for subject_id in within_kid_summary_df['subject_id']:\n",
        "        first_order = within_kid_summary_df[within_kid_summary_df['subject_id'] == subject_id]\n",
        "        second_order = trajectory_df[trajectory_df['subject_id'] == subject_id]\n",
        "        \n",
        "        if len(first_order) > 0 and len(second_order) > 0:\n",
        "            comparison_data.append({\n",
        "                'subject_id': subject_id,\n",
        "                'first_order_spearman': first_order['mean_spearman_correlation'].values[0],\n",
        "                'second_order_spearman': second_order['rdm_correlation'].values[0],\n",
        "                'difference': first_order['mean_spearman_correlation'].values[0] - second_order['rdm_correlation'].values[0]\n",
        "            })\n",
        "    \n",
        "    comparison_similarity_df = pd.DataFrame(comparison_data)\n",
        "    \n",
        "    if len(comparison_similarity_df) > 0:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Scatter plot: First-order vs Second-order\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.scatter(comparison_similarity_df['second_order_spearman'], \n",
        "               comparison_similarity_df['first_order_spearman'],\n",
        "               alpha=0.7, s=100, edgecolors='black', linewidth=1.5)\n",
        "    \n",
        "    # Add diagonal line\n",
        "    min_val = min(comparison_similarity_df['second_order_spearman'].min(), \n",
        "                  comparison_similarity_df['first_order_spearman'].min())\n",
        "    max_val = max(comparison_similarity_df['second_order_spearman'].max(), \n",
        "                  comparison_similarity_df['first_order_spearman'].max())\n",
        "    ax1.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, label='y=x')\n",
        "    \n",
        "    ax1.set_xlabel('Second-Order Similarity (RDM Correlation)', fontsize=12)\n",
        "    ax1.set_ylabel('First-Order Similarity (Category Embedding Correlation)', fontsize=12)\n",
        "    ax1.set_title('First-Order vs Second-Order Similarity', fontsize=13, pad=10)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add correlation coefficient\n",
        "    corr_coef = np.corrcoef(comparison_similarity_df['second_order_spearman'], \n",
        "                           comparison_similarity_df['first_order_spearman'])[0, 1]\n",
        "    ax1.text(0.05, 0.95, f'r = {corr_coef:.3f}', transform=ax1.transAxes,\n",
        "            fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    # 2. Distribution comparison\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.hist(comparison_similarity_df['first_order_spearman'], bins=15, alpha=0.7, \n",
        "            label='First-Order', color='#4ECDC4', edgecolor='black')\n",
        "    ax2.hist(comparison_similarity_df['second_order_spearman'], bins=15, alpha=0.7, \n",
        "            label='Second-Order', color='#FF6B6B', edgecolor='black')\n",
        "    ax2.axvline(comparison_similarity_df['first_order_spearman'].mean(), \n",
        "               color='#4ECDC4', linestyle='--', linewidth=2, \n",
        "               label=f'First-Order mean: {comparison_similarity_df[\"first_order_spearman\"].mean():.3f}')\n",
        "    ax2.axvline(comparison_similarity_df['second_order_spearman'].mean(), \n",
        "               color='#FF6B6B', linestyle='--', linewidth=2,\n",
        "               label=f'Second-Order mean: {comparison_similarity_df[\"second_order_spearman\"].mean():.3f}')\n",
        "    ax2.set_xlabel('Correlation', fontsize=12)\n",
        "    ax2.set_ylabel('Frequency', fontsize=12)\n",
        "    ax2.set_title('Distribution Comparison', fontsize=13, pad=10)\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Box plot comparison\n",
        "    ax3 = axes[1, 0]\n",
        "    box_data = [comparison_similarity_df['first_order_spearman'], \n",
        "                comparison_similarity_df['second_order_spearman']]\n",
        "    bp = ax3.boxplot(box_data, labels=['First-Order', 'Second-Order'], patch_artist=True)\n",
        "    colors_box = ['#4ECDC4', '#FF6B6B']\n",
        "    for patch, color in zip(bp['boxes'], colors_box):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.7)\n",
        "    ax3.set_ylabel('Correlation', fontsize=12)\n",
        "    ax3.set_title('Box Plot Comparison', fontsize=13, pad=10)\n",
        "    ax3.grid(True, alpha=0.3, axis='y')\n",
        "    ax3.set_ylim([0, 1])\n",
        "    \n",
        "    # 4. Difference distribution\n",
        "    ax4 = axes[1, 1]\n",
        "    differences = comparison_similarity_df['difference']\n",
        "    ax4.hist(differences, bins=15, alpha=0.7, color='#45B7D1', edgecolor='black')\n",
        "    ax4.axvline(0, color='red', linestyle='--', linewidth=2, label='No difference')\n",
        "    ax4.axvline(differences.mean(), color='green', linestyle='--', linewidth=2, \n",
        "               label=f'Mean: {differences.mean():.3f}')\n",
        "    ax4.set_xlabel('Difference (First-Order - Second-Order)', fontsize=12)\n",
        "    ax4.set_ylabel('Frequency', fontsize=12)\n",
        "    ax4.set_title('Difference Distribution', fontsize=13, pad=10)\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('First-Order vs Second-Order Similarity Comparison\\n(Within-Kid: Younger vs Older)', \n",
        "                 fontsize=14, y=0.995, fontweight='bold')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "    plt.savefig(output_dir / \"first_order_vs_second_order_comparison.png\", dpi=200, bbox_inches='tight')\n",
        "    print(f\"Saved comparison to {output_dir / 'first_order_vs_second_order_comparison.png'}\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(f\"\\nSummary comparison:\")\n",
        "    print(f\"  First-Order mean: {comparison_similarity_df['first_order_spearman'].mean():.3f} ± {comparison_similarity_df['first_order_spearman'].std():.3f}\")\n",
        "    print(f\"  Second-Order mean: {comparison_similarity_df['second_order_spearman'].mean():.3f} ± {comparison_similarity_df['second_order_spearman'].std():.3f}\")\n",
        "    print(f\"  Mean difference: {differences.mean():.3f} ± {differences.std():.3f}\")\n",
        "    print(f\"  Correlation between measures: {corr_coef:.3f}\")\n",
        "    print(f\"  Subjects with first-order > second-order: {len(comparison_similarity_df[differences > 0])} / {len(comparison_similarity_df)}\")\n",
        "    \n",
        "    comparison_similarity_df.to_csv(output_dir / \"first_vs_second_order_comparison.csv\", index=False)\n",
        "    print(f\"Saved comparison data to {output_dir / 'first_vs_second_order_comparison.csv'}\")\n",
        "    \n",
        "    # Visualize between-kid first-order similarity\n",
        "    if 'between_kid_summary_df' in globals() and len(between_kid_summary_df) > 0:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "        # 1. Distribution by comparison type\n",
        "        ax1 = axes[0, 0]\n",
        "        comparison_types = ['younger_younger', 'older_older', 'younger_older', 'older_younger']\n",
        "        colors_comp = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
        "        \n",
        "        for comp_type, color in zip(comparison_types, colors_comp):\n",
        "            type_data = between_kid_summary_df[between_kid_summary_df['comparison_type'] == comp_type]\n",
        "            if len(type_data) > 0:\n",
        "                ax1.hist(type_data['mean_spearman_correlation'], bins=20, alpha=0.6, \n",
        "                        label=comp_type.replace('_', ' ').title(), color=color, edgecolor='black')\n",
        "        \n",
        "        ax1.set_xlabel('First-Order Correlation', fontsize=12)\n",
        "        ax1.set_ylabel('Frequency', fontsize=12)\n",
        "        ax1.set_title('Between-Kid First-Order Similarity by Type', fontsize=13, pad=10)\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # 2. Box plot by comparison type\n",
        "        ax2 = axes[0, 1]\n",
        "        box_data = []\n",
        "        labels = []\n",
        "        for comp_type in comparison_types:\n",
        "            type_data = between_kid_summary_df[between_kid_summary_df['comparison_type'] == comp_type]\n",
        "            if len(type_data) > 0:\n",
        "                box_data.append(type_data['mean_spearman_correlation'].values)\n",
        "                labels.append(comp_type.replace('_', '\\n').title())\n",
        "        \n",
        "        if len(box_data) > 0:\n",
        "            bp = ax2.boxplot(box_data, labels=labels, patch_artist=True)\n",
        "            for patch, color in zip(bp['boxes'], colors_comp[:len(bp['boxes'])]):\n",
        "                patch.set_facecolor(color)\n",
        "                patch.set_alpha(0.7)\n",
        "            ax2.set_ylabel('First-Order Correlation', fontsize=12)\n",
        "            ax2.set_title('Box Plot by Comparison Type', fontsize=13, pad=10)\n",
        "            ax2.grid(True, alpha=0.3, axis='y')\n",
        "            ax2.set_ylim([0, 1])\n",
        "            plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # 3. Mean correlations by type (bar plot)\n",
        "        ax3 = axes[1, 0]\n",
        "        means = []\n",
        "        stds = []\n",
        "        type_labels = []\n",
        "        for comp_type in comparison_types:\n",
        "            type_data = between_kid_summary_df[between_kid_summary_df['comparison_type'] == comp_type]\n",
        "            if len(type_data) > 0:\n",
        "                means.append(type_data['mean_spearman_correlation'].mean())\n",
        "                stds.append(type_data['mean_spearman_correlation'].std())\n",
        "                type_labels.append(comp_type.replace('_', ' ').title())\n",
        "        \n",
        "        if len(means) > 0:\n",
        "            bars = ax3.bar(range(len(type_labels)), means, yerr=stds, \n",
        "                          color=colors_comp[:len(type_labels)], alpha=0.7, \n",
        "                          capsize=5, edgecolor='black')\n",
        "            ax3.set_xticks(range(len(type_labels)))\n",
        "            ax3.set_xticklabels(type_labels, rotation=45, ha='right')\n",
        "            ax3.set_ylabel('Mean First-Order Correlation', fontsize=12)\n",
        "            ax3.set_title('Mean Correlations by Comparison Type', fontsize=13, pad=10)\n",
        "            ax3.grid(True, alpha=0.3, axis='y')\n",
        "            ax3.set_ylim([0, 1])\n",
        "        \n",
        "        # 4. Heatmap: subject pairs x comparison type\n",
        "        ax4 = axes[1, 1]\n",
        "        pivot_data = between_kid_summary_df.pivot_table(\n",
        "            index=['subject_id_1', 'subject_id_2'], \n",
        "            columns='comparison_type', \n",
        "            values='mean_spearman_correlation'\n",
        "        )\n",
        "        \n",
        "        if len(pivot_data) > 0:\n",
        "            # Create a simplified heatmap (sample if too many pairs)\n",
        "            if len(pivot_data) > 50:\n",
        "                # Sample for visualization\n",
        "                pivot_data_viz = pivot_data.sample(50, random_state=42).sort_index()\n",
        "            else:\n",
        "                pivot_data_viz = pivot_data.sort_index()\n",
        "            \n",
        "            im = ax4.imshow(pivot_data_viz.values, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "            ax4.set_xticks(range(len(pivot_data_viz.columns)))\n",
        "            ax4.set_xticklabels([col.replace('_', '\\n').title() for col in pivot_data_viz.columns], \n",
        "                               fontsize=9)\n",
        "            ax4.set_ylabel('Subject Pairs (sample)', fontsize=12)\n",
        "            ax4.set_title('First-Order Correlations: Subject Pairs × Type', fontsize=13, pad=10)\n",
        "            plt.colorbar(im, ax=ax4, label='Correlation')\n",
        "        \n",
        "        plt.suptitle('Between-Kid First-Order Similarity', \n",
        "                     fontsize=14, y=0.995, fontweight='bold')\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "        plt.savefig(output_dir / \"between_kid_first_order_visualization.png\", dpi=200, bbox_inches='tight')\n",
        "        print(f\"Saved between-kid visualization to {output_dir / 'between_kid_first_order_visualization.png'}\")\n",
        "        plt.close()\n",
        "    \n",
        "    print(\"\\nFirst-order similarity analysis complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating category-wise visualizations...\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating category-wise visualizations...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# WITHIN-KID: Category-wise correlations\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mcategory_aggregated\u001b[49m) > \u001b[32m0\u001b[39m:\n\u001b[32m      8\u001b[39m     fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m16\u001b[39m, \u001b[32m12\u001b[39m))\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# 1. Bar plot: Top and bottom categories\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'category_aggregated' is not defined"
          ]
        }
      ],
      "source": [
        "# Visualize category-wise first-order correlations\n",
        "print(\"Creating category-wise visualizations...\")\n",
        "\n",
        "# ============================================================================\n",
        "# WITHIN-KID: Category-wise correlations\n",
        "# ============================================================================\n",
        "if len(category_aggregated) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Bar plot: Top and bottom categories\n",
        "    ax1 = axes[0, 0]\n",
        "    top_n = 20\n",
        "    top_cats = category_aggregated.head(top_n)\n",
        "    bottom_cats = category_aggregated.tail(top_n)\n",
        "    \n",
        "    # Combine top and bottom\n",
        "    plot_cats = pd.concat([top_cats, bottom_cats]).sort_values('mean_spearman', ascending=True)\n",
        "    colors_cats = ['#4ECDC4' if cat in top_cats['category'].values else '#FF6B6B' \n",
        "                   for cat in plot_cats['category']]\n",
        "    \n",
        "    y_pos = np.arange(len(plot_cats))\n",
        "    bars = ax1.barh(y_pos, plot_cats['mean_spearman'], xerr=plot_cats['std_spearman'],\n",
        "                   color=colors_cats, alpha=0.7, edgecolor='black', capsize=3)\n",
        "    ax1.set_yticks(y_pos)\n",
        "    ax1.set_yticklabels(plot_cats['category'], fontsize=9)\n",
        "    ax1.set_xlabel('Mean Spearman Correlation (across subjects)', fontsize=12)\n",
        "    ax1.set_title(f'Top {top_n} and Bottom {top_n} Categories\\n(Within-Kid: Younger vs Older)', fontsize=13, pad=10)\n",
        "    ax1.axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
        "    ax1.grid(True, alpha=0.3, axis='x')\n",
        "    ax1.set_xlim([0, 1])\n",
        "    \n",
        "    # 2. Distribution of correlations per category\n",
        "    ax2 = axes[0, 1]\n",
        "    # Sample categories for violin plot (too many to show all)\n",
        "    if len(category_aggregated) > 30:\n",
        "        sample_cats = pd.concat([category_aggregated.head(15), category_aggregated.tail(15)])\n",
        "    else:\n",
        "        sample_cats = category_aggregated\n",
        "    \n",
        "    violin_data = []\n",
        "    violin_labels = []\n",
        "    for _, row in sample_cats.iterrows():\n",
        "        cat_data = within_kid_category_wise_df[within_kid_category_wise_df['category'] == row['category']]['spearman_correlation'].values\n",
        "        if len(cat_data) > 0:\n",
        "            violin_data.append(cat_data)\n",
        "            violin_labels.append(row['category'])\n",
        "    \n",
        "    if len(violin_data) > 0:\n",
        "        parts = ax2.violinplot(violin_data, positions=range(len(violin_labels)), \n",
        "                              showmeans=True, showmedians=True, widths=0.8)\n",
        "        for pc in parts['bodies']:\n",
        "            pc.set_facecolor('#45B7D1')\n",
        "            pc.set_alpha(0.7)\n",
        "        ax2.set_xticks(range(len(violin_labels)))\n",
        "        ax2.set_xticklabels(violin_labels, rotation=90, ha='right', fontsize=8)\n",
        "        ax2.set_ylabel('Spearman Correlation', fontsize=12)\n",
        "        ax2.set_title('Distribution of Correlations by Category\\n(Within-Kid)', fontsize=13, pad=10)\n",
        "        ax2.grid(True, alpha=0.3, axis='y')\n",
        "        ax2.set_ylim([0, 1])\n",
        "    \n",
        "    # 3. Heatmap: Categories x Subjects\n",
        "    ax3 = axes[1, 0]\n",
        "    # Get top categories for heatmap\n",
        "    top_cats_for_heatmap = category_aggregated.head(30)['category'].values\n",
        "    heatmap_data = []\n",
        "    for cat in top_cats_for_heatmap:\n",
        "        cat_subj_data = []\n",
        "        for subject_id in within_kid_summary_df['subject_id']:\n",
        "            cat_subj_corr = within_kid_category_wise_df[\n",
        "                (within_kid_category_wise_df['category'] == cat) & \n",
        "                (within_kid_category_wise_df['subject_id'] == subject_id)\n",
        "            ]['spearman_correlation'].values\n",
        "            if len(cat_subj_corr) > 0:\n",
        "                cat_subj_data.append(cat_subj_corr[0])\n",
        "            else:\n",
        "                cat_subj_data.append(np.nan)\n",
        "        heatmap_data.append(cat_subj_data)\n",
        "    \n",
        "    heatmap_array = np.array(heatmap_data)\n",
        "    im = ax3.imshow(heatmap_array, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "    ax3.set_yticks(range(len(top_cats_for_heatmap)))\n",
        "    ax3.set_yticklabels(top_cats_for_heatmap, fontsize=8)\n",
        "    ax3.set_xticks(range(len(within_kid_summary_df)))\n",
        "    ax3.set_xticklabels(within_kid_summary_df['subject_id'], rotation=90, ha='right', fontsize=8)\n",
        "    ax3.set_xlabel('Subject ID', fontsize=12)\n",
        "    ax3.set_ylabel('Category', fontsize=12)\n",
        "    ax3.set_title('Top 30 Categories: Correlation by Subject\\n(Within-Kid)', fontsize=13, pad=10)\n",
        "    plt.colorbar(im, ax=ax3, label='Correlation')\n",
        "    \n",
        "    # 4. Scatter: Mean correlation vs number of subjects\n",
        "    ax4 = axes[1, 1]\n",
        "    ax4.scatter(category_aggregated['n_subjects'], category_aggregated['mean_spearman'],\n",
        "               alpha=0.6, s=100, edgecolors='black', linewidth=1)\n",
        "    ax4.set_xlabel('Number of Subjects with Category', fontsize=12)\n",
        "    ax4.set_ylabel('Mean Spearman Correlation', fontsize=12)\n",
        "    ax4.set_title('Correlation vs Category Prevalence\\n(Within-Kid)', fontsize=13, pad=10)\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add correlation coefficient\n",
        "    corr_coef = np.corrcoef(category_aggregated['n_subjects'], \n",
        "                           category_aggregated['mean_spearman'])[0, 1]\n",
        "    ax4.text(0.05, 0.95, f'r = {corr_coef:.3f}', transform=ax4.transAxes,\n",
        "            fontsize=12, verticalalignment='top', \n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    plt.suptitle('Within-Kid First-Order Similarity: Category-Wise Analysis\\n(Younger vs Older for Same Subject)', \n",
        "                 fontsize=14, y=0.995, fontweight='bold')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "    plt.savefig(output_dir / \"within_kid_first_order_category_wise_visualization.png\", dpi=200, bbox_inches='tight')\n",
        "    print(f\"Saved within-kid category-wise visualization to {output_dir / 'within_kid_first_order_category_wise_visualization.png'}\")\n",
        "    plt.close()\n",
        "\n",
        "# ============================================================================\n",
        "# BETWEEN-KID: Category-wise correlations\n",
        "# ============================================================================\n",
        "if len(category_agg_all) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # 1. Bar plot: Top and bottom categories (across all comparison types)\n",
        "    ax1 = axes[0, 0]\n",
        "    top_n = 20\n",
        "    top_cats = category_agg_all.head(top_n)\n",
        "    bottom_cats = category_agg_all.tail(top_n)\n",
        "    \n",
        "    plot_cats = pd.concat([top_cats, bottom_cats]).sort_values('mean_spearman', ascending=True)\n",
        "    colors_cats = ['#4ECDC4' if cat in top_cats['category'].values else '#FF6B6B' \n",
        "                   for cat in plot_cats['category']]\n",
        "    \n",
        "    y_pos = np.arange(len(plot_cats))\n",
        "    bars = ax1.barh(y_pos, plot_cats['mean_spearman'], xerr=plot_cats['std_spearman'],\n",
        "                   color=colors_cats, alpha=0.7, edgecolor='black', capsize=3)\n",
        "    ax1.set_yticks(y_pos)\n",
        "    ax1.set_yticklabels(plot_cats['category'], fontsize=9)\n",
        "    ax1.set_xlabel('Mean Spearman Correlation (across subject pairs)', fontsize=12)\n",
        "    ax1.set_title(f'Top {top_n} and Bottom {top_n} Categories\\n(Between-Kid: All Comparison Types)', fontsize=13, pad=10)\n",
        "    ax1.axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
        "    ax1.grid(True, alpha=0.3, axis='x')\n",
        "    ax1.set_xlim([0, 1])\n",
        "    \n",
        "    # 2. Comparison by type for top categories\n",
        "    ax2 = axes[0, 1]\n",
        "    top_cats_list = category_agg_all.head(15)['category'].values\n",
        "    comparison_types = ['younger_younger', 'older_older', 'younger_older', 'older_younger']\n",
        "    x_pos = np.arange(len(top_cats_list))\n",
        "    width = 0.2\n",
        "    \n",
        "    for i, comp_type in enumerate(comparison_types):\n",
        "        type_means = []\n",
        "        for cat in top_cats_list:\n",
        "            cat_type_data = category_comparison_agg[\n",
        "                (category_comparison_agg['category'] == cat) & \n",
        "                (category_comparison_agg['comparison_type'] == comp_type)\n",
        "            ]\n",
        "            if len(cat_type_data) > 0:\n",
        "                type_means.append(cat_type_data['mean_spearman'].values[0])\n",
        "            else:\n",
        "                type_means.append(np.nan)\n",
        "        \n",
        "        ax2.bar(x_pos + i*width, type_means, width, \n",
        "               label=comp_type.replace('_', ' ').title(), alpha=0.7)\n",
        "    \n",
        "    ax2.set_xticks(x_pos + width * 1.5)\n",
        "    ax2.set_xticklabels(top_cats_list, rotation=90, ha='right', fontsize=8)\n",
        "    ax2.set_ylabel('Mean Correlation', fontsize=12)\n",
        "    ax2.set_title('Top 15 Categories by Comparison Type\\n(Between-Kid)', fontsize=13, pad=10)\n",
        "    ax2.legend(fontsize=9, ncol=2)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    ax2.set_ylim([0, 1])\n",
        "    \n",
        "    # 3. Heatmap: Categories x Comparison Types\n",
        "    ax3 = axes[1, 0]\n",
        "    top_cats_heatmap = category_agg_all.head(25)['category'].values\n",
        "    heatmap_data = []\n",
        "    for cat in top_cats_heatmap:\n",
        "        cat_type_means = []\n",
        "        for comp_type in comparison_types:\n",
        "            cat_type_data = category_comparison_agg[\n",
        "                (category_comparison_agg['category'] == cat) & \n",
        "                (category_comparison_agg['comparison_type'] == comp_type)\n",
        "            ]\n",
        "            if len(cat_type_data) > 0:\n",
        "                cat_type_means.append(cat_type_data['mean_spearman'].values[0])\n",
        "            else:\n",
        "                cat_type_means.append(np.nan)\n",
        "        heatmap_data.append(cat_type_means)\n",
        "    \n",
        "    heatmap_array = np.array(heatmap_data)\n",
        "    im = ax3.imshow(heatmap_array, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "    ax3.set_yticks(range(len(top_cats_heatmap)))\n",
        "    ax3.set_yticklabels(top_cats_heatmap, fontsize=8)\n",
        "    ax3.set_xticks(range(len(comparison_types)))\n",
        "    ax3.set_xticklabels([ct.replace('_', '\\n').title() for ct in comparison_types], fontsize=10)\n",
        "    ax3.set_xlabel('Comparison Type', fontsize=12)\n",
        "    ax3.set_ylabel('Category', fontsize=12)\n",
        "    ax3.set_title('Top 25 Categories: Correlation by Comparison Type\\n(Between-Kid)', fontsize=13, pad=10)\n",
        "    plt.colorbar(im, ax=ax3, label='Correlation')\n",
        "    \n",
        "    # 4. Mean correlations by comparison type (bar plot)\n",
        "    ax4 = axes[1, 1]\n",
        "    type_means_all = []\n",
        "    type_stds_all = []\n",
        "    type_labels = []\n",
        "    for comp_type in comparison_types:\n",
        "        type_data = category_comparison_agg[category_comparison_agg['comparison_type'] == comp_type]\n",
        "        if len(type_data) > 0:\n",
        "            type_means_all.append(type_data['mean_spearman'].mean())\n",
        "            type_stds_all.append(type_data['mean_spearman'].std())\n",
        "            type_labels.append(comp_type.replace('_', ' ').title())\n",
        "    \n",
        "    if len(type_means_all) > 0:\n",
        "        bars = ax4.bar(range(len(type_labels)), type_means_all, yerr=type_stds_all,\n",
        "                      color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'], \n",
        "                      alpha=0.7, capsize=5, edgecolor='black')\n",
        "        ax4.set_xticks(range(len(type_labels)))\n",
        "        ax4.set_xticklabels(type_labels, rotation=45, ha='right')\n",
        "        ax4.set_ylabel('Mean Correlation (across categories)', fontsize=12)\n",
        "        ax4.set_title('Mean Correlations by Comparison Type\\n(Between-Kid)', fontsize=13, pad=10)\n",
        "        ax4.grid(True, alpha=0.3, axis='y')\n",
        "        ax4.set_ylim([0, 1])\n",
        "    \n",
        "    plt.suptitle('Between-Kid First-Order Similarity: Category-Wise Analysis', \n",
        "                 fontsize=14, y=0.995, fontweight='bold')\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "    plt.savefig(output_dir / \"between_kid_first_order_category_wise_visualization.png\", dpi=200, bbox_inches='tight')\n",
        "    print(f\"Saved between-kid category-wise visualization to {output_dir / 'between_kid_first_order_category_wise_visualization.png'}\")\n",
        "    plt.close()\n",
        "\n",
        "print(\"\\nCategory-wise visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "DEMONSTRATION: RDM Correlation Logic with NaN Values\n",
            "======================================================================\n",
            "\n",
            "1. SETUP: Full category order (5 categories)\n",
            "   Ordered categories: ['cat1', 'cat2', 'cat3', 'cat4', 'cat5']\n",
            "\n",
            "2. EXAMPLE SUBJECT:\n",
            "   Younger bin has: cat1, cat2, cat3, cat4 (4 categories)\n",
            "   Older bin has:   cat2, cat3, cat4, cat5 (4 categories)\n",
            "\n",
            "3. COMMON CATEGORIES:\n",
            "   Common categories: ['cat2', 'cat3', 'cat4'] (3 categories)\n",
            "   Note: cat1 only in younger, cat5 only in older - these are excluded\n",
            "   IMPORTANT: Categories are in predefined order, not alphabetical!\n",
            "\n",
            "4. RDM STRUCTURE:\n",
            "   Full RDMs are 5×5 (one row/column per category in ordered_cats)\n",
            "   Missing categories have NaN in their rows/columns\n",
            "\n",
            "   Younger RDM structure:\n",
            "     cat1   cat2   cat3   cat4   cat5\n",
            "     cat1:   data\n",
            "     cat2:   data\n",
            "     cat3:   data\n",
            "     cat4:   data\n",
            "     cat5:    NaN\n",
            "\n",
            "5. SUBMATRIX EXTRACTION:\n",
            "   Common category indices in full RDM: [1, 2, 3]\n",
            "   Extract 3×3 submatrix using these indices\n",
            "   This gives us only the common categories: ['cat2', 'cat3', 'cat4']\n",
            "\n",
            "6. UPPER TRIANGLE:\n",
            "   For 3 categories, we get 3 unique pairs\n",
            "   (excluding diagonal: 3 self-pairs)\n",
            "   Example pairs: (cat2-cat3), (cat2-cat4), (cat3-cat4)\n",
            "\n",
            "7. CORRELATION:\n",
            "   - Extract distance values for these pairs from both RDMs\n",
            "   - Filter out any NaN values (shouldn't be any for common categories)\n",
            "   - Compute Spearman correlation on the paired distance values\n",
            "   - Result: Single correlation coefficient (-1 to 1)\n",
            "\n",
            "8. WHY THIS WORKS:\n",
            "   ✓ Only uses categories present in BOTH bins (fair comparison)\n",
            "   ✓ Same category pairs compared in both RDMs\n",
            "   ✓ NaN values are excluded (don't affect correlation)\n",
            "   ✓ Correlation reflects structural similarity, not data availability\n",
            "\n",
            "======================================================================\n",
            "For actual subjects, this process uses 163 categories\n",
            "Common categories typically range from 130-160 per subject\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Demonstration: How RDM Correlation Works with NaN Values\n",
        "# This cell demonstrates the correlation logic with a simple example\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DEMONSTRATION: RDM Correlation Logic with NaN Values\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Example: Simple 5-category case\n",
        "print(\"\\n1. SETUP: Full category order (5 categories)\")\n",
        "ordered_cats = ['cat1', 'cat2', 'cat3', 'cat4', 'cat5']\n",
        "print(f\"   Ordered categories: {ordered_cats}\")\n",
        "\n",
        "print(\"\\n2. EXAMPLE SUBJECT:\")\n",
        "print(\"   Younger bin has: cat1, cat2, cat3, cat4 (4 categories)\")\n",
        "print(\"   Older bin has:   cat2, cat3, cat4, cat5 (4 categories)\")\n",
        "available_younger = ['cat1', 'cat2', 'cat3', 'cat4']\n",
        "available_older = ['cat2', 'cat3', 'cat4', 'cat5']\n",
        "\n",
        "print(\"\\n3. COMMON CATEGORIES:\")\n",
        "# Preserve predefined order, not alphabetical\n",
        "common = [cat for cat in ordered_cats if cat in available_younger and cat in available_older]\n",
        "print(f\"   Common categories: {common} ({len(common)} categories)\")\n",
        "print(\"   Note: cat1 only in younger, cat5 only in older - these are excluded\")\n",
        "print(\"   IMPORTANT: Categories are in predefined order, not alphabetical!\")\n",
        "\n",
        "print(\"\\n4. RDM STRUCTURE:\")\n",
        "print(\"   Full RDMs are 5×5 (one row/column per category in ordered_cats)\")\n",
        "print(\"   Missing categories have NaN in their rows/columns\")\n",
        "print(\"\\n   Younger RDM structure:\")\n",
        "print(\"   \" + \" \".join([f\"{c:>6}\" for c in ordered_cats]))\n",
        "for i, cat in enumerate(ordered_cats):\n",
        "    if cat in available_younger:\n",
        "        status = \"  data\"\n",
        "    else:\n",
        "        status = \"   NaN\"\n",
        "    print(f\"   {cat:>6}: {status}\")\n",
        "\n",
        "print(\"\\n5. SUBMATRIX EXTRACTION:\")\n",
        "common_indices = [ordered_cats.index(c) for c in common]\n",
        "print(f\"   Common category indices in full RDM: {common_indices}\")\n",
        "print(f\"   Extract 3×3 submatrix using these indices\")\n",
        "print(f\"   This gives us only the common categories: {common}\")\n",
        "\n",
        "print(\"\\n6. UPPER TRIANGLE:\")\n",
        "n_common = len(common)\n",
        "n_pairs = n_common * (n_common - 1) // 2\n",
        "print(f\"   For {n_common} categories, we get {n_pairs} unique pairs\")\n",
        "print(f\"   (excluding diagonal: {n_common} self-pairs)\")\n",
        "print(f\"   Example pairs: (cat2-cat3), (cat2-cat4), (cat3-cat4)\")\n",
        "\n",
        "print(\"\\n7. CORRELATION:\")\n",
        "print(\"   - Extract distance values for these pairs from both RDMs\")\n",
        "print(\"   - Filter out any NaN values (shouldn't be any for common categories)\")\n",
        "print(\"   - Compute Spearman correlation on the paired distance values\")\n",
        "print(\"   - Result: Single correlation coefficient (-1 to 1)\")\n",
        "\n",
        "print(\"\\n8. WHY THIS WORKS:\")\n",
        "print(\"   ✓ Only uses categories present in BOTH bins (fair comparison)\")\n",
        "print(\"   ✓ Same category pairs compared in both RDMs\")\n",
        "print(\"   ✓ NaN values are excluded (don't affect correlation)\")\n",
        "print(\"   ✓ Correlation reflects structural similarity, not data availability\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"For actual subjects, this process uses 163 categories\")\n",
        "print(\"Common categories typically range from 130-160 per subject\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing trajectories: 100%|██████████| 18/18 [00:00<00:00, 406.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trajectory analysis:\n",
            "  Total subjects analyzed: 18\n",
            "  Mean RDM correlation (younger vs older): 0.756\n",
            "  Std RDM correlation: 0.073\n",
            "  Median age threshold: 16.0 months\n",
            "\n",
            "Saved trajectory correlations to developmental_trajectory_rdms_clip/trajectory_correlations.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def compute_rdm_correlation(rdm1, rdm2, ordered_categories_list, available_cats1, available_cats2):\n",
        "    \"\"\"\n",
        "    Compute correlation between two RDMs that use the full ordered_categories list with NaN for missing categories.\n",
        "    Only uses categories present in both RDMs (non-NaN in both).\n",
        "    \n",
        "    Args:\n",
        "        rdm1: numpy array of shape (n_categories, n_categories) with NaN for missing categories\n",
        "        rdm2: numpy array of shape (n_categories, n_categories) with NaN for missing categories\n",
        "        ordered_categories_list: full list of categories in order (used for indexing)\n",
        "        available_cats1: list of categories actually present in rdm1\n",
        "        available_cats2: list of categories actually present in rdm2\n",
        "    \n",
        "    Returns:\n",
        "        corr: correlation coefficient (or np.nan if insufficient data)\n",
        "        n_common: number of common categories\n",
        "    \"\"\"\n",
        "    # Find common categories (categories present in both RDMs)\n",
        "    # IMPORTANT: Preserve predefined order from ordered_categories_list, NOT alphabetical order\n",
        "    # This ensures submatrices are extracted in the same order for both RDMs\n",
        "    # and maintains consistency with visualizations which use the predefined order\n",
        "    common_categories = [cat for cat in ordered_categories_list \n",
        "                        if cat in available_cats1 and cat in available_cats2]\n",
        "    \n",
        "    if len(common_categories) < 2:\n",
        "        return np.nan, len(common_categories)\n",
        "    \n",
        "    # Get indices for common categories in the ordered_categories_list\n",
        "    common_indices = [ordered_categories_list.index(cat) for cat in common_categories]\n",
        "    \n",
        "    # Extract submatrices for common categories\n",
        "    rdm1_subset = rdm1[np.ix_(common_indices, common_indices)]\n",
        "    rdm2_subset = rdm2[np.ix_(common_indices, common_indices)]\n",
        "    \n",
        "    # Get upper triangle (excluding diagonal) for both RDMs\n",
        "    mask = np.triu(np.ones_like(rdm1_subset, dtype=bool), k=1)\n",
        "    rdm1_flat = rdm1_subset[mask]\n",
        "    rdm2_flat = rdm2_subset[mask]\n",
        "    \n",
        "    # Filter out NaN values (shouldn't be any if categories are truly common, but check anyway)\n",
        "    valid_mask = ~(np.isnan(rdm1_flat) | np.isnan(rdm2_flat))\n",
        "    rdm1_valid = rdm1_flat[valid_mask]\n",
        "    rdm2_valid = rdm2_flat[valid_mask]\n",
        "    \n",
        "    # Compute Spearman correlation (more robust to outliers)\n",
        "    if len(rdm1_valid) > 0:\n",
        "        corr, _ = spearmanr(rdm1_valid, rdm2_valid)\n",
        "        return corr, len(common_categories)\n",
        "    else:\n",
        "        return np.nan, len(common_categories)\n",
        "\n",
        "# Compute RDM correlations between younger and older bins for each subject\n",
        "trajectory_data = []\n",
        "\n",
        "for subject_id, bin_rdms in tqdm(subject_age_rdms.items(), desc=\"Analyzing trajectories\"):\n",
        "    if 'younger' not in bin_rdms or 'older' not in bin_rdms:\n",
        "        continue\n",
        "    \n",
        "    rdm_younger = bin_rdms['younger']\n",
        "    rdm_older = bin_rdms['older']\n",
        "    cats_younger = subject_age_rdm_categories[subject_id]['younger']\n",
        "    cats_older = subject_age_rdm_categories[subject_id]['older']\n",
        "    \n",
        "    # Use ordered_categories as reference and available categories for filtering\n",
        "    corr, n_common = compute_rdm_correlation(\n",
        "        rdm_younger, rdm_older, \n",
        "        ordered_categories,  # Full ordered list for indexing\n",
        "        cats_younger,  # Available categories in younger bin\n",
        "        cats_older     # Available categories in older bin\n",
        "    )\n",
        "    \n",
        "    trajectory_data.append({\n",
        "        'subject_id': subject_id,\n",
        "        'age_bin_1': 'younger',\n",
        "        'age_bin_2': 'older',\n",
        "        'median_age_threshold': overall_median_age,\n",
        "        'rdm_correlation': corr,\n",
        "        'n_common_categories': n_common,\n",
        "        'n_categories_younger': len(cats_younger),\n",
        "        'n_categories_older': len(cats_older)\n",
        "    })\n",
        "\n",
        "trajectory_df = pd.DataFrame(trajectory_data)\n",
        "trajectory_df.to_csv(output_dir / \"trajectory_correlations.csv\", index=False)\n",
        "\n",
        "print(f\"\\nTrajectory analysis:\")\n",
        "print(f\"  Total subjects analyzed: {len(trajectory_df)}\")\n",
        "print(f\"  Mean RDM correlation (younger vs older): {trajectory_df['rdm_correlation'].mean():.3f}\")\n",
        "print(f\"  Std RDM correlation: {trajectory_df['rdm_correlation'].std():.3f}\")\n",
        "print(f\"  Median age threshold: {overall_median_age:.1f} months\")\n",
        "print(f\"\\nSaved trajectory correlations to {output_dir / 'trajectory_correlations.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Category-Based Correlations\n",
        "\n",
        "Compute correlations between younger and older RDMs separately for each broad semantic category group (animals, bodyparts, big_objects, small_objects, others). This allows us to examine whether developmental stability varies across different semantic domains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing category-based correlations...\n",
            "Category group sizes: [('animals', 19), ('bodyparts', 14), ('big_objects', 32), ('small_objects', 96), ('others', 2)]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category correlations: 100%|██████████| 18/18 [00:00<00:00, 445.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Category-based correlation analysis:\n",
            "  Total subject-group combinations: 90\n",
            "\n",
            "Mean correlations by category group:\n",
            "  animals        : 0.502 (n=18 valid, 18 total)\n",
            "  bodyparts      : 0.789 (n=18 valid, 18 total)\n",
            "  big_objects    : 0.736 (n=18 valid, 18 total)\n",
            "  small_objects  : 0.773 (n=18 valid, 18 total)\n",
            "  others         : No valid correlations (n=18 total)\n",
            "\n",
            "Saved category group correlations to developmental_trajectory_rdms_clip/category_group_correlations.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute category-based correlations for each semantic group\n",
        "category_correlation_data = []\n",
        "\n",
        "# Get category groups from organized structure\n",
        "category_groups = {\n",
        "    'animals': organized['animals'],\n",
        "    'bodyparts': organized['bodyparts'],\n",
        "    'big_objects': organized['big_objects'],\n",
        "    'small_objects': organized['small_objects'],\n",
        "    'others': organized['others']\n",
        "}\n",
        "\n",
        "print(\"Computing category-based correlations...\")\n",
        "print(f\"Category group sizes: {[(name, len(cats)) for name, cats in category_groups.items()]}\")\n",
        "\n",
        "for subject_id, bin_rdms in tqdm(subject_age_rdms.items(), desc=\"Category correlations\"):\n",
        "    if 'younger' not in bin_rdms or 'older' not in bin_rdms:\n",
        "        continue\n",
        "    \n",
        "    rdm_younger = bin_rdms['younger']\n",
        "    rdm_older = bin_rdms['older']\n",
        "    cats_younger = subject_age_rdm_categories[subject_id]['younger']\n",
        "    cats_older = subject_age_rdm_categories[subject_id]['older']\n",
        "    \n",
        "    # Compute correlation for each category group\n",
        "    for group_name, group_categories in category_groups.items():\n",
        "        # Find common categories in this group that are present in both age bins\n",
        "        common_in_group = [cat for cat in group_categories \n",
        "                          if cat in cats_younger and cat in ordered_categories and cat in cats_older]\n",
        "        \n",
        "        if len(common_in_group) < 2:\n",
        "            # Not enough categories in this group for correlation\n",
        "            category_correlation_data.append({\n",
        "                'subject_id': subject_id,\n",
        "                'category_group': group_name,\n",
        "                'n_common_categories': len(common_in_group),\n",
        "                'correlation': np.nan,\n",
        "                'n_categories_younger': len([c for c in group_categories if c in cats_younger]),\n",
        "                'n_categories_older': len([c for c in group_categories if c in cats_older])\n",
        "            })\n",
        "            continue\n",
        "        \n",
        "        # Get indices for common categories in this group\n",
        "        common_indices = [ordered_categories.index(cat) for cat in common_in_group]\n",
        "        \n",
        "        # Extract submatrices for this group\n",
        "        rdm_younger_group = rdm_younger[np.ix_(common_indices, common_indices)]\n",
        "        rdm_older_group = rdm_older[np.ix_(common_indices, common_indices)]\n",
        "        \n",
        "        # Get upper triangle (excluding diagonal)\n",
        "        mask = np.triu(np.ones_like(rdm_younger_group, dtype=bool), k=1)\n",
        "        rdm_younger_flat = rdm_younger_group[mask]\n",
        "        rdm_older_flat = rdm_older_group[mask]\n",
        "        \n",
        "        # Filter out NaN values\n",
        "        valid_mask = ~(np.isnan(rdm_younger_flat) | np.isnan(rdm_older_flat))\n",
        "        rdm_younger_valid = rdm_younger_flat[valid_mask]\n",
        "        rdm_older_valid = rdm_older_flat[valid_mask]\n",
        "        \n",
        "        # Compute Spearman correlation\n",
        "        if len(rdm_younger_valid) > 0:\n",
        "            corr, _ = spearmanr(rdm_younger_valid, rdm_older_valid)\n",
        "        else:\n",
        "            corr = np.nan\n",
        "        \n",
        "        category_correlation_data.append({\n",
        "            'subject_id': subject_id,\n",
        "            'category_group': group_name,\n",
        "            'n_common_categories': len(common_in_group),\n",
        "            'correlation': corr,\n",
        "            'n_categories_younger': len([c for c in group_categories if c in cats_younger]),\n",
        "            'n_categories_older': len([c for c in group_categories if c in cats_older])\n",
        "        })\n",
        "\n",
        "category_corr_df = pd.DataFrame(category_correlation_data)\n",
        "category_corr_df.to_csv(output_dir / \"category_group_correlations.csv\", index=False)\n",
        "\n",
        "print(f\"\\nCategory-based correlation analysis:\")\n",
        "print(f\"  Total subject-group combinations: {len(category_corr_df)}\")\n",
        "print(f\"\\nMean correlations by category group:\")\n",
        "for group_name in category_groups.keys():\n",
        "    group_data = category_corr_df[category_corr_df['category_group'] == group_name]\n",
        "    valid_corrs = group_data['correlation'].dropna()\n",
        "    if len(valid_corrs) > 0:\n",
        "        print(f\"  {group_name:15s}: {valid_corrs.mean():.3f} (n={len(valid_corrs)} valid, {len(group_data)} total)\")\n",
        "    else:\n",
        "        print(f\"  {group_name:15s}: No valid correlations (n={len(group_data)} total)\")\n",
        "\n",
        "print(f\"\\nSaved category group correlations to {output_dir / 'category_group_correlations.csv'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Category-Based Correlations\n",
        "\n",
        "Create visualizations to examine how developmental stability (correlation between younger and older RDMs) varies across different semantic category groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating visualizations for category-based correlations...\n",
            "Saved category correlation visualization to developmental_trajectory_rdms_clip/category_group_correlations_visualization.png\n",
            "Saved detailed heatmap to developmental_trajectory_rdms_clip/category_group_correlations_heatmap.png\n",
            "\n",
            "Visualization complete!\n"
          ]
        }
      ],
      "source": [
        "# Visualize category-based correlations\n",
        "print(\"Creating visualizations for category-based correlations...\")\n",
        "\n",
        "# Filter out NaN correlations for plotting\n",
        "valid_category_corr_df = category_corr_df[category_corr_df['correlation'].notna()].copy()\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "# 1. Box plot comparing correlations across category groups\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "category_order = ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']\n",
        "box_data = [valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation'].values \n",
        "            for group in category_order if group in valid_category_corr_df['category_group'].values]\n",
        "\n",
        "# Filter out empty groups\n",
        "box_data_filtered = []\n",
        "labels_filtered = []\n",
        "for i, group in enumerate(category_order):\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation'].values\n",
        "    box_data_filtered.append(group_data)\n",
        "    labels_filtered.append(group.replace('_', ' ').title())\n",
        "\n",
        "bp = ax1.boxplot(box_data_filtered, labels=labels_filtered, patch_artist=True)\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
        "for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax1.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax1.set_title('Distribution of Correlations by Category Group', fontsize=13, pad=10)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.set_ylim([0, 1])\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# 2. Bar plot of mean correlations by group\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "mean_corrs = []\n",
        "std_corrs = []\n",
        "group_labels = []\n",
        "for group in category_order:\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation']\n",
        "    mean_corrs.append(group_data.mean())\n",
        "    std_corrs.append(group_data.std())\n",
        "    group_labels.append(group.replace('_', ' ').title())\n",
        "\n",
        "bars = ax2.bar(range(len(group_labels)), mean_corrs, yerr=std_corrs, \n",
        "               color=colors[:len(group_labels)], alpha=0.7, capsize=5, edgecolor='black')\n",
        "ax2.set_xticks(range(len(group_labels)))\n",
        "ax2.set_xticklabels(group_labels, rotation=45, ha='right')\n",
        "ax2.set_ylabel('Mean RDM Correlation', fontsize=12)\n",
        "ax2.set_title('Mean Correlations by Category Group', fontsize=13, pad=10)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.set_ylim([0, 1])\n",
        "ax2.axhline(y=valid_category_corr_df['correlation'].mean(), color='red', \n",
        "           linestyle='--', linewidth=2, label=f'Overall mean: {valid_category_corr_df[\"correlation\"].mean():.3f}')\n",
        "ax2.legend()\n",
        "\n",
        "# 3. Heatmap: subjects x category groups\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "pivot_data = valid_category_corr_df.pivot(index='subject_id', columns='category_group', values='correlation')\n",
        "# Reorder columns\n",
        "pivot_data = pivot_data[[col for col in category_order if col in pivot_data.columns]]\n",
        "# Sort subjects by overall correlation (average across groups)\n",
        "pivot_data['mean_corr'] = pivot_data.mean(axis=1)\n",
        "pivot_data = pivot_data.sort_values('mean_corr', ascending=False)\n",
        "pivot_data = pivot_data.drop('mean_corr', axis=1)\n",
        "\n",
        "im = ax3.imshow(pivot_data.values, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "ax3.set_xticks(range(len(pivot_data.columns)))\n",
        "ax3.set_xticklabels([col.replace('_', ' ').title() for col in pivot_data.columns], \n",
        "                    rotation=45, ha='right')\n",
        "ax3.set_yticks(range(len(pivot_data.index)))\n",
        "ax3.set_yticklabels(pivot_data.index, fontsize=8)\n",
        "ax3.set_title('Correlation Heatmap: Subjects × Category Groups', fontsize=13, pad=10)\n",
        "plt.colorbar(im, ax=ax3, label='RDM Correlation')\n",
        "\n",
        "# 4. Violin plot for better distribution visualization\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "violin_data = []\n",
        "violin_labels = []\n",
        "for group in category_order:\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation'].values\n",
        "    # Only add groups with non-empty data (filter out empty arrays)\n",
        "    if len(group_data) > 0:\n",
        "        violin_data.append(group_data)\n",
        "        violin_labels.append(group.replace('_', ' ').title())\n",
        "\n",
        "\n",
        "if len(violin_data) > 0:\n",
        "    parts = ax4.violinplot(violin_data, positions=range(len(violin_labels)), showmeans=True, showmedians=True)\n",
        "    for i, pc in enumerate(parts['bodies']):\n",
        "        pc.set_facecolor(colors[i % len(colors)])\n",
        "        pc.set_alpha(0.7)\n",
        "    ax4.set_xticks(range(len(violin_labels)))\n",
        "    ax4.set_xticklabels(violin_labels, rotation=45, ha='right')\n",
        "    ax4.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "    ax4.set_title('Distribution of Correlations (Violin Plot)', fontsize=13, pad=10)\n",
        "    ax4.grid(True, alpha=0.3, axis='y')\n",
        "    ax4.set_ylim([0, 1])\n",
        "else:\n",
        "    ax4.text(0.5, 0.5, 'No valid data for violin plot', ha='center', va='center', transform=ax4.transAxes)\n",
        "    ax4.set_title('Distribution of Correlations (Violin Plot)', fontsize=13, pad=10)\n",
        "\n",
        "# 5. Scatter plot: correlation vs number of common categories\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "for group in category_order:\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]\n",
        "    ax5.scatter(group_data['n_common_categories'], group_data['correlation'], \n",
        "                   label=group.replace('_', ' ').title(), alpha=0.6, s=60)\n",
        "\n",
        "ax5.set_xlabel('Number of Common Categories', fontsize=12)\n",
        "ax5.set_ylabel('RDM Correlation', fontsize=12)\n",
        "ax5.set_title('Correlation vs Category Count', fontsize=13, pad=10)\n",
        "ax5.legend(loc='best', fontsize=9)\n",
        "ax5.grid(True, alpha=0.3)\n",
        "ax5.set_ylim([0, 1])\n",
        "\n",
        "# 6. Individual subject trajectories (bar plot for each subject)\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "# Get top 10 subjects by overall correlation for cleaner visualization\n",
        "subject_means = valid_category_corr_df.groupby('subject_id')['correlation'].mean().sort_values(ascending=False)\n",
        "top_subjects = subject_means.head(10).index\n",
        "\n",
        "x_pos = np.arange(len(top_subjects))\n",
        "bar_width = 0.15  # Use different variable name to avoid conflicts\n",
        "for i, group in enumerate(category_order):\n",
        "    if group in valid_category_corr_df['category_group'].values:\n",
        "        group_corrs = []\n",
        "        for subj in top_subjects:\n",
        "            subj_group_data = valid_category_corr_df[\n",
        "                (valid_category_corr_df['subject_id'] == subj) & \n",
        "                (valid_category_corr_df['category_group'] == group)\n",
        "            ]\n",
        "            if len(subj_group_data) > 0:\n",
        "                group_corrs.append(subj_group_data['correlation'].values[0])\n",
        "            else:\n",
        "                group_corrs.append(np.nan)\n",
        "        \n",
        "        # Convert to numpy array and only plot if we have at least some valid data\n",
        "        group_corrs = np.array(group_corrs)\n",
        "        if not np.all(np.isnan(group_corrs)):\n",
        "            ax6.bar(x_pos + i*bar_width, group_corrs, bar_width, \n",
        "                   label=group.replace('_', ' ').title(), alpha=0.7, color=colors[i % len(colors)])\n",
        "\n",
        "ax6.set_xlabel('Subject ID', fontsize=12)\n",
        "ax6.set_ylabel('RDM Correlation', fontsize=12)\n",
        "ax6.set_title('Top 10 Subjects: Correlations by Category Group', fontsize=13, pad=10)\n",
        "ax6.set_xticks(x_pos + bar_width * 2)\n",
        "ax6.set_xticklabels(top_subjects, rotation=45, ha='right', fontsize=8)\n",
        "ax6.legend(loc='upper left', fontsize=8, ncol=2)\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "ax6.set_ylim([0, 1])\n",
        "\n",
        "plt.suptitle('Category-Based RDM Correlations: Younger vs Older Age Bins', \n",
        "             fontsize=16, y=0.995, fontweight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"category_group_correlations_visualization.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved category correlation visualization to {output_dir / 'category_group_correlations_visualization.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Create a separate detailed heatmap with all subjects\n",
        "fig, ax = plt.subplots(figsize=(10, 14))\n",
        "pivot_data_all = valid_category_corr_df.pivot(index='subject_id', columns='category_group', values='correlation')\n",
        "pivot_data_all = pivot_data_all[[col for col in category_order if col in pivot_data_all.columns]]\n",
        "# Sort by overall mean correlation\n",
        "pivot_data_all['mean_corr'] = pivot_data_all.mean(axis=1)\n",
        "pivot_data_all = pivot_data_all.sort_values('mean_corr', ascending=False)\n",
        "pivot_data_all = pivot_data_all.drop('mean_corr', axis=1)\n",
        "\n",
        "im = ax.imshow(pivot_data_all.values, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "ax.set_xticks(range(len(pivot_data_all.columns)))\n",
        "ax.set_xticklabels([col.replace('_', ' ').title() for col in pivot_data_all.columns],\n",
        "                   rotation=45, ha='right', fontsize=11)\n",
        "for i, (xlabel, ylabel) in enumerate(zip(ax.get_xticklabels(), ax.get_yticklabels())):\n",
        "    if i < len(ordered_categories):\n",
        "        cat_name = ordered_categories[i]\n",
        "        color = get_category_color(cat_name, cdi_category_map)\n",
        "        xlabel.set_color(color)\n",
        "        ylabel.set_color(color)\n",
        "ax.set_yticks(range(len(pivot_data_all.index)))\n",
        "ax.set_yticklabels(pivot_data_all.index, fontsize=9)\n",
        "ax.set_title('Category-Based RDM Correlations: All Subjects\\n(Younger vs Older Age Bins)', \n",
        "             fontsize=14, pad=15, fontweight='bold')\n",
        "cbar = plt.colorbar(im, ax=ax, label='RDM Correlation (Spearman)', fraction=0.046, pad=0.04)\n",
        "\n",
        "# Add text annotations for correlation values\n",
        "for i in range(len(pivot_data_all.index)):\n",
        "    for j in range(len(pivot_data_all.columns)):\n",
        "        val = pivot_data_all.iloc[i, j]\n",
        "        ax.text(j, i, f'{val:.2f}', ha='center', va='center', \n",
        "                   fontsize=7, color='white' if val < 0.5 else 'black', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"category_group_correlations_heatmap.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved detailed heatmap to {output_dir / 'category_group_correlations_heatmap.png'}\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualization complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Developmental Trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating RDM visualizations for all subjects (younger vs older)...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating RDM plots: 100%|██████████| 18/18 [00:00<00:00, 364722.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved RDM visualizations for 18 subjects\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create side-by-side RDM visualization for each subject (younger vs older)\n",
        "print(\"Creating RDM visualizations for all subjects (younger vs older)...\")\n",
        "\n",
        "for subject_id in tqdm(subject_age_rdms.keys(), desc=\"Creating RDM plots\"):\n",
        "    bin_rdms = subject_age_rdms[subject_id]\n",
        "    bin_masks = subject_age_rdm_masks[subject_id]\n",
        "    \n",
        "    continue\n",
        "    \n",
        "    # Create figure with 2 subplots side by side\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    \n",
        "    # Find global min/max for consistent color scale (excluding NaN)\n",
        "    all_rdm_values = []\n",
        "    for rdm in bin_rdms.values():\n",
        "        valid_values = rdm[~np.isnan(rdm)]\n",
        "        all_rdm_values.extend(valid_values)\n",
        "    vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "    vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "    \n",
        "    for idx, bin_name in enumerate(['younger', 'older']):\n",
        "        rdm = bin_rdms[bin_name]\n",
        "        mask = bin_masks[bin_name]\n",
        "        available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "        group_boundaries = subject_age_group_boundaries[subject_id][bin_name]\n",
        "        \n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Determine font sizes based on number of categories in predefined order\n",
        "        n_cats_total = len(ordered_categories)\n",
        "        n_cats_available = len(available_cats)\n",
        "        \n",
        "        if n_cats_total <= 50:\n",
        "            label_fontsize = 10\n",
        "            tick_fontsize = 12\n",
        "        elif n_cats_total <= 100:\n",
        "            label_fontsize = 8\n",
        "            tick_fontsize = 10\n",
        "        else:\n",
        "            label_fontsize = 6\n",
        "            tick_fontsize = 8\n",
        "        \n",
        "        # Create masked array for visualization (white cells for missing categories)\n",
        "        rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "        cmap = plt.cm.get_cmap('viridis').copy()  # Get a copy to avoid modifying global colormap\n",
        "        cmap.set_bad(color='white', alpha=1.0)  # White for NA cells\n",
        "        im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "        \n",
        "            # Draw vertical line\n",
        "            # Draw horizontal line\n",
        "        \n",
        "        # Set category names as axis labels (use full predefined order)\n",
        "        ax.set_xticks(range(len(ordered_categories)))\n",
        "        ax.set_yticks(range(len(ordered_categories)))\n",
        "        # Show only every Nth label to avoid overlap\n",
        "        n_cats = len(ordered_categories)\n",
        "        if n_cats <= 50:\n",
        "            tick_step = 1\n",
        "            tick_step = 2\n",
        "        else:\n",
        "            tick_step = max(1, n_cats // 50)  # Show ~50 labels max\n",
        "        \n",
        "        ax.set_xticks(range(0, n_cats, tick_step))\n",
        "        ax.set_yticks(range(0, n_cats, tick_step))\n",
        "        ax.set_xticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                     rotation=90, ha='right', fontsize=max(8, tick_fontsize) if 'tick_fontsize' in locals() else 8)\n",
        "        ax.set_yticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                     fontsize=max(8, tick_fontsize) if 'tick_fontsize' in locals() else 8)\n",
        "        \n",
        "        # Apply colors to visible labels based on CDI category\n",
        "        for label in ax.get_xticklabels():\n",
        "            cat_name = label.get_text()\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n",
        "        for label in ax.get_yticklabels():\n",
        "            cat_name = label.get_text()\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n",
        "        # Apply colors to labels based on CDI category\n",
        "        for i, (xlabel, ylabel) in enumerate(zip(ax.get_xticklabels(), ax.get_yticklabels())):\n",
        "            cat_name = ordered_categories[i]\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "\n",
        "        ax.set_yticklabels(ordered_categories, fontsize=tick_fontsize)\n",
        "        \n",
        "        \n",
        "        # Create title with age range info and category count\n",
        "        if bin_name == \"younger\":\n",
        "            title = f\"Younger (≤{overall_median_age:.0f} months)\\n({n_cats_available}/{n_cats_total} categories)\"\n",
        "        else:\n",
        "            title = f\"Older (>{overall_median_age:.0f} months)\\n({n_cats_available}/{n_cats_total} categories)\"\n",
        "        \n",
        "        ax.set_title(title, fontsize=12, pad=10)\n",
        "        \n",
        "        # Add colorbar\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    \n",
        "    plt.suptitle(f\"Developmental Trajectory: {subject_id}\\n(Median split at {overall_median_age:.1f} months)\", \n",
        "                 fontsize=14, y=0.995)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "    plt.savefig(output_dir / f\"trajectory_{subject_id}.png\", dpi=200, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "print(f\"\\nSaved RDM visualizations for {len(subject_age_rdms)} subjects\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grouped Developmental Trajectory Visualization\n",
        "\n",
        "Create a grouped visualization combining multiple subjects' developmental trajectory plots together in one figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating grouped developmental trajectory visualization...\n",
            "Plotting 18 subjects in grouped visualization...\n",
            "Saved grouped visualization to developmental_trajectory_rdms_clip/grouped_trajectory_18_subjects.png\n",
            "\n",
            "Creating additional grouped visualization with first 12 subjects for better readability...\n",
            "Saved 12-subject grouped visualization to developmental_trajectory_rdms_clip/grouped_trajectory_12_subjects.png\n",
            "\n",
            "Grouped visualization complete!\n"
          ]
        }
      ],
      "source": [
        "# Create grouped visualization combining N subjects' developmental trajectory plots\n",
        "print(\"Creating grouped developmental trajectory visualization...\")\n",
        "\n",
        "# Load CDI category mapping for label coloring\n",
        "cdi_category_map = load_cdi_category_mapping(cdi_path)\n",
        "\n",
        "\n",
        "# Get all subjects with valid data\n",
        "valid_subjects = [sid for sid in subject_age_rdms.keys() \n",
        "                  if 'younger' in subject_age_rdms[sid] and 'older' in subject_age_rdms[sid]]\n",
        "\n",
        "if len(valid_subjects) == 0:\n",
        "    print(\"No subjects with valid data for grouped visualization\")\n",
        "else:\n",
        "    # Number of subjects to plot (can be adjusted)\n",
        "    # Set to None to plot all subjects, or specify a number\n",
        "    n_subjects_to_plot = None  # Change to a number like 6, 9, 12, etc. to limit\n",
        "    \n",
        "    subjects_to_plot = valid_subjects[:n_subjects_to_plot] if n_subjects_to_plot else valid_subjects\n",
        "    n_subjects = len(subjects_to_plot)\n",
        "    \n",
        "    print(f\"Plotting {n_subjects} subjects in grouped visualization...\")\n",
        "    \n",
        "    # Calculate global min/max for consistent color scale across all subjects\n",
        "    all_rdm_values = []\n",
        "    for subject_id in subjects_to_plot:\n",
        "        bin_rdms = subject_age_rdms[subject_id]\n",
        "        for bin_name in ['younger', 'older']:\n",
        "            rdm = bin_rdms[bin_name]\n",
        "            # Ensure rdm is a numpy array and handle NaN values\n",
        "            if isinstance(rdm, np.ndarray):\n",
        "                valid_values = rdm[~np.isnan(rdm)]\n",
        "                if len(valid_values) > 0:\n",
        "                    all_rdm_values.extend(valid_values.tolist())\n",
        "    \n",
        "    vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "    vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "    \n",
        "    # Create figure with n_subjects rows and 2 columns (younger, older)\n",
        "    # Adjust figure size based on number of subjects\n",
        "    fig_height = max(4, n_subjects * 2.5)  # At least 4 inches, 2.5 inches per subject\n",
        "    fig_width = 16  # Keep consistent width\n",
        "    \n",
        "    fig, axes = plt.subplots(n_subjects, 2, figsize=(fig_width, fig_height))\n",
        "    \n",
        "    # Handle case where there's only one subject (axes would be 1D)\n",
        "    if n_subjects == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    # Determine font sizes based on number of categories\n",
        "    n_cats_total = len(ordered_categories)\n",
        "    if n_cats_total <= 50:\n",
        "        tick_fontsize = 8\n",
        "    elif n_cats_total <= 100:\n",
        "        tick_fontsize = 6\n",
        "    else:\n",
        "        tick_fontsize = 4\n",
        "    \n",
        "    # Plot each subject\n",
        "    for row_idx, subject_id in enumerate(subjects_to_plot):\n",
        "        bin_rdms = subject_age_rdms[subject_id]\n",
        "        bin_masks = subject_age_rdm_masks[subject_id]\n",
        "        \n",
        "        for col_idx, bin_name in enumerate(['younger', 'older']):\n",
        "            rdm = bin_rdms[bin_name]\n",
        "            mask = bin_masks[bin_name]\n",
        "            available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "            group_boundaries = subject_age_group_boundaries[subject_id][bin_name]\n",
        "            \n",
        "            ax = axes[row_idx, col_idx]\n",
        "            \n",
        "            # Ensure rdm is a numpy array with correct shape\n",
        "            if not isinstance(rdm, np.ndarray):\n",
        "                rdm = np.array(rdm)\n",
        "            # Ensure mask is a numpy array with correct shape\n",
        "            if not isinstance(mask, np.ndarray):\n",
        "                mask = np.array(mask)\n",
        "            # Ensure shapes match\n",
        "            if rdm.shape != mask.shape:\n",
        "                print(f\"Warning: Shape mismatch for {subject_id} {bin_name}: rdm {rdm.shape} vs mask {mask.shape}\")\n",
        "                # Try to reshape or skip if incompatible\n",
        "                if rdm.size == 0 or mask.size == 0:\n",
        "                    continue\n",
        "                if rdm.size == mask.size:\n",
        "                    rdm = rdm.reshape(mask.shape)\n",
        "                else:\n",
        "                    print(f\"  Skipping {subject_id} {bin_name} due to incompatible shapes\")\n",
        "                    continue\n",
        "            \n",
        "            # Create masked array for visualization\n",
        "            rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "            cmap = plt.cm.get_cmap('viridis').copy()\n",
        "            cmap.set_bad(color='white', alpha=1.0)\n",
        "            im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "            \n",
        "            \n",
        "            # Set category names as axis labels (only show every Nth label to avoid crowding)\n",
        "            n_cats = len(ordered_categories)\n",
        "            if n_cats <= 50:\n",
        "                tick_step = 1\n",
        "            elif n_cats <= 100:\n",
        "                tick_step = 2\n",
        "            else:\n",
        "                tick_step = max(1, n_cats // 50)\n",
        "            \n",
        "            ax.set_xticks(range(0, n_cats, tick_step))\n",
        "            ax.set_yticks(range(0, n_cats, tick_step))\n",
        "            ax.set_xticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)], \n",
        "                    rotation=90, ha=\"right\", fontsize=tick_fontsize)\n",
        "\n",
        "            # Apply colors to labels based on CDI category\n",
        "            for i, (xlabel, ylabel) in enumerate(zip(ax.get_xticklabels(), ax.get_yticklabels())):\n",
        "                if i < len(ordered_categories):\n",
        "                    cat_name = ordered_categories[i]\n",
        "                    color = get_category_color(cat_name, cdi_category_map)\n",
        "                    xlabel.set_color(color)\n",
        "                    ylabel.set_color(color)\n",
        "            ax.set_yticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)], \n",
        "                             fontsize=tick_fontsize)\n",
        "            \n",
        "            # Create title with subject ID and age info\n",
        "            n_cats_available = len(available_cats)\n",
        "            if bin_name == 'younger':\n",
        "                title = f\"{subject_id} - Younger (≤{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "            else:\n",
        "                title = f\"{subject_id} - Older (>{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "            \n",
        "            ax.set_title(title, fontsize=10, pad=5)\n",
        "            \n",
        "            # Add colorbar only to the rightmost plots\n",
        "            if col_idx == 1:  # Right column\n",
        "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    \n",
        "    # Add overall title\n",
        "    plt.suptitle(f'Grouped Developmental Trajectories: {n_subjects} Subjects\\n(Median split at {overall_median_age:.1f} months)', \n",
        "                 fontsize=16, y=0.998, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "    \n",
        "    # Save the grouped visualization\n",
        "    output_filename = f\"grouped_trajectory_{n_subjects}_subjects.png\"\n",
        "    plt.savefig(output_dir / output_filename, dpi=200, bbox_inches='tight')\n",
        "    print(f\"Saved grouped visualization to {output_dir / output_filename}\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Also create a version with fewer subjects if there are many (for better readability)\n",
        "    if n_subjects > 12:\n",
        "        print(f\"\\nCreating additional grouped visualization with first 12 subjects for better readability...\")\n",
        "        subjects_to_plot_12 = valid_subjects[:12]\n",
        "        \n",
        "        fig_height_12 = 12 * 2.5\n",
        "        fig, axes = plt.subplots(12, 2, figsize=(fig_width, fig_height_12))\n",
        "        \n",
        "        for row_idx, subject_id in enumerate(subjects_to_plot_12):\n",
        "            bin_rdms = subject_age_rdms[subject_id]\n",
        "            bin_masks = subject_age_rdm_masks[subject_id]\n",
        "            \n",
        "            for col_idx, bin_name in enumerate(['younger', 'older']):\n",
        "                rdm = bin_rdms[bin_name]\n",
        "                mask = bin_masks[bin_name]\n",
        "                available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "                group_boundaries = subject_age_group_boundaries[subject_id][bin_name]\n",
        "                \n",
        "                ax = axes[row_idx, col_idx]\n",
        "                \n",
        "                # Ensure rdm is a numpy array with correct shape\n",
        "                if not isinstance(rdm, np.ndarray):\n",
        "                    rdm = np.array(rdm)\n",
        "                # Ensure mask is a numpy array with correct shape\n",
        "                if not isinstance(mask, np.ndarray):\n",
        "                    mask = np.array(mask)\n",
        "                # Ensure shapes match\n",
        "                if rdm.shape != mask.shape:\n",
        "                    print(f\"Warning: Shape mismatch for {subject_id} {bin_name}: rdm {rdm.shape} vs mask {mask.shape}\")\n",
        "                    # Try to reshape or skip if incompatible\n",
        "                    if rdm.size == 0 or mask.size == 0:\n",
        "                        continue\n",
        "                    if rdm.size == mask.size:\n",
        "                        rdm = rdm.reshape(mask.shape)\n",
        "                    else:\n",
        "                        print(f\"  Skipping {subject_id} {bin_name} due to incompatible shapes\")\n",
        "                        continue\n",
        "                \n",
        "                rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "                cmap = plt.cm.get_cmap('viridis').copy()\n",
        "                cmap.set_bad(color='white', alpha=1.0)\n",
        "                im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "                \n",
        "                \n",
        "                n_cats = len(ordered_categories)\n",
        "                if n_cats <= 50:\n",
        "                    tick_step = 1\n",
        "                elif n_cats <= 100:\n",
        "                    tick_step = 2\n",
        "                else:\n",
        "                    tick_step = max(1, n_cats // 50)\n",
        "                \n",
        "                ax.set_xticks(range(0, n_cats, tick_step))\n",
        "                ax.set_yticks(range(0, n_cats, tick_step))\n",
        "                ax.set_xticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)], \n",
        "                                             rotation=90, ha=\"right\", fontsize=tick_fontsize)\n",
        "                # Apply colors to labels based on CDI category\n",
        "                for i, (xlabel, ylabel) in enumerate(zip(ax.get_xticklabels(), ax.get_yticklabels())):\n",
        "                    if i < len(ordered_categories):\n",
        "                        cat_name = ordered_categories[i]\n",
        "                        color = get_category_color(cat_name, cdi_category_map)\n",
        "                        xlabel.set_color(color)\n",
        "                        ylabel.set_color(color)\n",
        "                ax.set_yticklabels([ordered_categories[i] for i in range(0, n_cats, tick_step)], \n",
        "                                 fontsize=tick_fontsize)\n",
        "                \n",
        "                n_cats_available = len(available_cats)\n",
        "                if bin_name == 'younger':\n",
        "                    title = f\"{subject_id} - Younger (≤{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "                else:\n",
        "                    title = f\"{subject_id} - Older (>{overall_median_age:.0f}mo)\\n({n_cats_available}/{n_cats_total} cats)\"\n",
        "                \n",
        "                ax.set_title(title, fontsize=10, pad=5)\n",
        "                \n",
        "                if col_idx == 1:\n",
        "                    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "        \n",
        "        plt.suptitle(f'Grouped Developmental Trajectories: First 12 Subjects\\n(Median split at {overall_median_age:.1f} months)', \n",
        "                     fontsize=16, y=0.998, fontweight='bold')\n",
        "        \n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "        \n",
        "        output_filename_12 = f\"grouped_trajectory_12_subjects.png\"\n",
        "        plt.savefig(output_dir / output_filename_12, dpi=200, bbox_inches='tight')\n",
        "        print(f\"Saved 12-subject grouped visualization to {output_dir / output_filename_12}\")\n",
        "        plt.close()\n",
        "\n",
        "print(\"\\nGrouped visualization complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot RDM Stability Across Development\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved RDM stability analysis to developmental_trajectory_rdms_clip/rdm_stability_analysis.png\n"
          ]
        }
      ],
      "source": [
        "# Plot RDM correlation distribution between younger and older bins\n",
        "# Filter out NaN correlations\n",
        "valid_correlations = trajectory_df['rdm_correlation'].dropna()\n",
        "\n",
        "if len(valid_correlations) > 0:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Histogram of RDM correlations\n",
        "    axes[0].hist(valid_correlations, bins=20, alpha=0.7, edgecolor='black')\n",
        "    mean_corr = valid_correlations.mean()\n",
        "    axes[0].axvline(mean_corr, color='red', linestyle='--', \n",
        "                    label=f'Mean: {mean_corr:.3f}')\n",
        "    axes[0].set_xlabel('RDM Correlation (Spearman)')\n",
        "    axes[0].set_ylabel('Number of Subjects')\n",
        "    axes[0].set_title(f'Distribution of Younger vs Older RDM Correlations\\n(n={len(valid_correlations)} valid)')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Box plot\n",
        "    axes[1].boxplot(valid_correlations, vert=True)\n",
        "    axes[1].set_ylabel('RDM Correlation (Spearman)')\n",
        "    axes[1].set_title(f'RDM Correlation: Younger vs Older\\n(n={len(valid_correlations)} valid)')\n",
        "    axes[1].set_xticklabels(['All Subjects'])\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir / \"rdm_stability_analysis.png\", dpi=150, bbox_inches='tight')\n",
        "    print(f\"Saved RDM stability analysis to {output_dir / 'rdm_stability_analysis.png'}\")\n",
        "    plt.close()\n",
        "else:\n",
        "    print(\"Warning: No valid correlations to plot (all are NaN)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary statistics:\n",
            "       median_age_threshold  n_categories  mean_distance  std_distance  \\\n",
            "count                  36.0     36.000000      36.000000     36.000000   \n",
            "mean                   16.0    150.916667       0.970143      0.269097   \n",
            "std                     0.0     12.748950       0.015751      0.012754   \n",
            "min                    16.0     88.000000       0.907006      0.229432   \n",
            "25%                    16.0    149.000000       0.962922      0.263846   \n",
            "50%                    16.0    154.500000       0.973334      0.271045   \n",
            "75%                    16.0    157.000000       0.980742      0.277700   \n",
            "max                    16.0    161.000000       0.989174      0.287583   \n",
            "\n",
            "       min_distance  max_distance  \n",
            "count     36.000000     36.000000  \n",
            "mean       0.040484      1.628654  \n",
            "std        0.020743      0.046012  \n",
            "min        0.012637      1.428745  \n",
            "25%        0.022898      1.621835  \n",
            "50%        0.037880      1.636737  \n",
            "75%        0.056602      1.655754  \n",
            "max        0.078758      1.683532  \n",
            "\n",
            "Saved summary to developmental_trajectory_rdms_clip/summary_statistics.csv\n"
          ]
        }
      ],
      "source": [
        "# Create summary statistics\n",
        "summary_data = []\n",
        "\n",
        "for subject_id, bin_rdms in subject_age_rdms.items():\n",
        "    for bin_name in ['younger', 'older']:\n",
        "        if bin_name not in bin_rdms:\n",
        "            continue\n",
        "            \n",
        "        rdm = bin_rdms[bin_name]\n",
        "        categories = subject_age_rdm_categories[subject_id][bin_name]\n",
        "        \n",
        "        # Use nan-aware functions to handle NaN values (missing categories)\n",
        "        valid_rdm = rdm[~np.isnan(rdm)]\n",
        "        valid_rdm_positive = valid_rdm[valid_rdm > 0]  # Exclude diagonal zeros\n",
        "        \n",
        "        summary_data.append({\n",
        "            'subject_id': subject_id,\n",
        "            'age_bin': bin_name,\n",
        "            'median_age_threshold': overall_median_age,\n",
        "            'n_categories': len(categories),\n",
        "            'mean_distance': float(np.nanmean(rdm)) if len(valid_rdm) > 0 else np.nan,\n",
        "            'std_distance': float(np.nanstd(rdm)) if len(valid_rdm) > 0 else np.nan,\n",
        "            'min_distance': float(valid_rdm_positive.min()) if len(valid_rdm_positive) > 0 else np.nan,\n",
        "            'max_distance': float(np.nanmax(rdm)) if len(valid_rdm) > 0 else np.nan\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df.to_csv(output_dir / \"summary_statistics.csv\", index=False)\n",
        "\n",
        "print(\"Summary statistics:\")\n",
        "print(summary_df.describe())\n",
        "print(f\"\\nSaved summary to {output_dir / 'summary_statistics.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-Kid Correlations\n",
        "\n",
        "In addition to within-kid correlations (comparing younger vs. older periods for the same child), we also compute cross-kid correlations to understand how similar children are to each other. This analysis includes:\n",
        "\n",
        "1. **Younger-Younger correlations**: Compare younger timepoints across different children\n",
        "   - Measures similarity in representational structure during early development\n",
        "   - Helps identify whether children have similar early object representations\n",
        "\n",
        "2. **Younger-Older correlations**: Compare younger timepoint of one child with older timepoint of another child\n",
        "   - Measures whether early representations of one child are similar to later representations of another child\n",
        "   - Can reveal developmental patterns and individual differences\n",
        "\n",
        "3. **Older-Older correlations**: Compare older timepoints across different children\n",
        "   - Measures similarity in representational structure during later development\n",
        "   - Helps identify whether children converge to similar representations as they develop\n",
        "\n",
        "These cross-kid correlations complement the within-kid analysis by providing insights into:\n",
        "- **Individual differences**: How much do children vary in their object representations?\n",
        "- **Developmental timing**: Do some children's early representations resemble other children's later representations?\n",
        "- **Common developmental patterns**: Are there shared trajectories across children?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing cross-kid correlations...\n",
            "Computing correlations for 18 subjects\n",
            "Total pairs: 153\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-kid correlations: 100%|██████████| 18/18 [00:01<00:00, 12.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-kid correlation analysis:\n",
            "  Total subject pairs: 153\n",
            "  Total correlation measurements: 612\n",
            "\n",
            "Mean correlations by type:\n",
            "  younger_younger     : 0.675 ± 0.101 (n=153 valid, 153 total)\n",
            "  younger_older       : 0.660 ± 0.096 (n=153 valid, 153 total)\n",
            "  older_younger       : 0.672 ± 0.064 (n=153 valid, 153 total)\n",
            "  older_older         : 0.659 ± 0.056 (n=153 valid, 153 total)\n",
            "\n",
            "Saved cross-kid correlations to developmental_trajectory_rdms_clip/cross_kid_correlations.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute cross-kid correlations\n",
        "print(\"Computing cross-kid correlations...\")\n",
        "\n",
        "# Get list of subjects with both younger and older RDMs\n",
        "valid_subjects = [sid for sid in subject_age_rdms.keys() \n",
        "                  if 'younger' in subject_age_rdms[sid] and 'older' in subject_age_rdms[sid]]\n",
        "\n",
        "print(f\"Computing correlations for {len(valid_subjects)} subjects\")\n",
        "print(f\"Total pairs: {len(valid_subjects) * (len(valid_subjects) - 1) // 2}\")\n",
        "\n",
        "# Store cross-kid correlation data\n",
        "cross_kid_data = []\n",
        "\n",
        "# Compute all pairwise correlations\n",
        "for i, subject_id_1 in enumerate(tqdm(valid_subjects, desc=\"Cross-kid correlations\")):\n",
        "    for subject_id_2 in valid_subjects[i+1:]:  # Only compute upper triangle (avoid duplicates)\n",
        "        \n",
        "        # Get RDMs and categories for both subjects\n",
        "        rdm1_younger = subject_age_rdms[subject_id_1]['younger']\n",
        "        rdm1_older = subject_age_rdms[subject_id_1]['older']\n",
        "        cats1_younger = subject_age_rdm_categories[subject_id_1]['younger']\n",
        "        cats1_older = subject_age_rdm_categories[subject_id_1]['older']\n",
        "        \n",
        "        rdm2_younger = subject_age_rdms[subject_id_2]['younger']\n",
        "        rdm2_older = subject_age_rdms[subject_id_2]['older']\n",
        "        cats2_younger = subject_age_rdm_categories[subject_id_2]['younger']\n",
        "        cats2_older = subject_age_rdm_categories[subject_id_2]['older']\n",
        "        \n",
        "        # 1. Younger-Younger correlation (subject 1 younger vs subject 2 younger)\n",
        "        corr_yy, n_common_yy = compute_rdm_correlation(\n",
        "            rdm1_younger, rdm2_younger,\n",
        "            ordered_categories,\n",
        "            cats1_younger, cats2_younger\n",
        "        )\n",
        "        \n",
        "        # 2. Younger-Older correlation (subject 1 younger vs subject 2 older)\n",
        "        corr_yo, n_common_yo = compute_rdm_correlation(\n",
        "            rdm1_younger, rdm2_older,\n",
        "            ordered_categories,\n",
        "            cats1_younger, cats2_older\n",
        "        )\n",
        "        \n",
        "        # 3. Older-Younger correlation (subject 1 older vs subject 2 younger)\n",
        "        corr_oy, n_common_oy = compute_rdm_correlation(\n",
        "            rdm1_older, rdm2_younger,\n",
        "            ordered_categories,\n",
        "            cats1_older, cats2_younger\n",
        "        )\n",
        "        \n",
        "        # 4. Older-Older correlation (subject 1 older vs subject 2 older)\n",
        "        corr_oo, n_common_oo = compute_rdm_correlation(\n",
        "            rdm1_older, rdm2_older,\n",
        "            ordered_categories,\n",
        "            cats1_older, cats2_older\n",
        "        )\n",
        "        \n",
        "        # Store results\n",
        "        cross_kid_data.append({\n",
        "            'subject_id_1': subject_id_1,\n",
        "            'subject_id_2': subject_id_2,\n",
        "            'correlation_type': 'younger_younger',\n",
        "            'correlation': corr_yy,\n",
        "            'n_common_categories': n_common_yy,\n",
        "            'n_categories_subject1': len(cats1_younger),\n",
        "            'n_categories_subject2': len(cats2_younger)\n",
        "        })\n",
        "        \n",
        "        cross_kid_data.append({\n",
        "            'subject_id_1': subject_id_1,\n",
        "            'subject_id_2': subject_id_2,\n",
        "            'correlation_type': 'younger_older',\n",
        "            'correlation': corr_yo,\n",
        "            'n_common_categories': n_common_yo,\n",
        "            'n_categories_subject1': len(cats1_younger),\n",
        "            'n_categories_subject2': len(cats2_older)\n",
        "        })\n",
        "        \n",
        "        cross_kid_data.append({\n",
        "            'subject_id_1': subject_id_1,\n",
        "            'subject_id_2': subject_id_2,\n",
        "            'correlation_type': 'older_younger',\n",
        "            'correlation': corr_oy,\n",
        "            'n_common_categories': n_common_oy,\n",
        "            'n_categories_subject1': len(cats1_older),\n",
        "            'n_categories_subject2': len(cats2_younger)\n",
        "        })\n",
        "        \n",
        "        cross_kid_data.append({\n",
        "            'subject_id_1': subject_id_1,\n",
        "            'subject_id_2': subject_id_2,\n",
        "            'correlation_type': 'older_older',\n",
        "            'correlation': corr_oo,\n",
        "            'n_common_categories': n_common_oo,\n",
        "            'n_categories_subject1': len(cats1_older),\n",
        "            'n_categories_subject2': len(cats2_older)\n",
        "        })\n",
        "\n",
        "# Create DataFrame\n",
        "cross_kid_df = pd.DataFrame(cross_kid_data)\n",
        "cross_kid_df.to_csv(output_dir / \"cross_kid_correlations.csv\", index=False)\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nCross-kid correlation analysis:\")\n",
        "print(f\"  Total subject pairs: {len(valid_subjects) * (len(valid_subjects) - 1) // 2}\")\n",
        "print(f\"  Total correlation measurements: {len(cross_kid_df)}\")\n",
        "\n",
        "print(f\"\\nMean correlations by type:\")\n",
        "for corr_type in ['younger_younger', 'younger_older', 'older_younger', 'older_older']:\n",
        "    type_data = cross_kid_df[cross_kid_df['correlation_type'] == corr_type]\n",
        "    valid_corrs = type_data['correlation'].dropna()\n",
        "    if len(valid_corrs) > 0:\n",
        "        print(f\"  {corr_type:20s}: {valid_corrs.mean():.3f} ± {valid_corrs.std():.3f} (n={len(valid_corrs)} valid, {len(type_data)} total)\")\n",
        "    else:\n",
        "        print(f\"  {corr_type:20s}: No valid correlations (n={len(type_data)} total)\")\n",
        "\n",
        "print(f\"\\nSaved cross-kid correlations to {output_dir / 'cross_kid_correlations.csv'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating visualizations for cross-kid correlations...\n",
            "Saved cross-kid correlation visualization to developmental_trajectory_rdms_clip/cross_kid_correlations_visualization.png\n",
            "\n",
            "Visualization complete!\n"
          ]
        }
      ],
      "source": [
        "# Visualize cross-kid correlations\n",
        "print(\"Creating visualizations for cross-kid correlations...\")\n",
        "\n",
        "# Filter out NaN correlations for plotting\n",
        "valid_cross_kid_df = cross_kid_df[cross_kid_df['correlation'].notna()].copy()\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "# 1. Box plot comparing correlation types\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "correlation_types = ['younger_younger', 'younger_older', 'older_younger', 'older_older']\n",
        "box_data = [valid_cross_kid_df[valid_cross_kid_df['correlation_type'] == ct]['correlation'].values \n",
        "            for ct in correlation_types]\n",
        "labels = ['Younger-Younger', 'Younger-Older', 'Older-Younger', 'Older-Older']\n",
        "\n",
        "bp = ax1.boxplot(box_data, labels=labels, patch_artist=True)\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#95E1D3', '#FFA07A']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax1.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax1.set_title('Distribution of Cross-Kid Correlations', fontsize=13, pad=10)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.set_ylim([0, 1])\n",
        "\n",
        "# 2. Violin plot\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "violin_data = [valid_cross_kid_df[valid_cross_kid_df['correlation_type'] == ct]['correlation'].values \n",
        "               for ct in correlation_types]\n",
        "parts = ax2.violinplot(violin_data, positions=range(len(labels)), showmeans=True, showmedians=True)\n",
        "for i, pc in enumerate(parts['bodies']):\n",
        "    pc.set_facecolor(colors[i])\n",
        "    pc.set_alpha(0.7)\n",
        "ax2.set_xticks(range(len(labels)))\n",
        "ax2.set_xticklabels(labels, rotation=45, ha='right')\n",
        "ax2.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax2.set_title('Distribution of Cross-Kid Correlations (Violin)', fontsize=13, pad=10)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.set_ylim([0, 1])\n",
        "\n",
        "# 3. Histogram overlay\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "for i, ct in enumerate(correlation_types):\n",
        "    type_data = valid_cross_kid_df[valid_cross_kid_df['correlation_type'] == ct]['correlation'].values\n",
        "    ax3.hist(type_data, bins=30, alpha=0.6, label=labels[i], color=colors[i], density=True)\n",
        "ax3.set_xlabel('RDM Correlation', fontsize=12)\n",
        "ax3.set_ylabel('Density', fontsize=12)\n",
        "ax3.set_title('Distribution of Cross-Kid Correlations (Histogram)', fontsize=13, pad=10)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.set_xlim([0, 1])\n",
        "\n",
        "# 4. Scatter: correlation vs number of common categories\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "for i, ct in enumerate(correlation_types):\n",
        "    type_data = valid_cross_kid_df[valid_cross_kid_df['correlation_type'] == ct]\n",
        "    ax4.scatter(type_data['n_common_categories'], type_data['correlation'], \n",
        "               label=labels[i], alpha=0.6, s=60, color=colors[i])\n",
        "ax4.set_xlabel('Number of Common Categories', fontsize=12)\n",
        "ax4.set_ylabel('RDM Correlation', fontsize=12)\n",
        "ax4.set_title('Correlation vs Common Categories', fontsize=13, pad=10)\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "ax4.set_ylim([0, 1])\n",
        "\n",
        "# 5. Comparison: Cross-kid vs Within-kid correlations (all types)\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "# Get within-kid correlations from trajectory_df\n",
        "within_kid_corrs = trajectory_df['rdm_correlation'].dropna().values\n",
        "\n",
        "# Get all cross-kid correlation types\n",
        "correlation_types = ['younger_younger', 'younger_older', 'older_younger', 'older_older']\n",
        "correlation_labels = ['Younger-Younger', 'Younger-Older', 'Older-Younger', 'Older-Older']\n",
        "\n",
        "cross_kid_data = [valid_cross_kid_df[valid_cross_kid_df['correlation_type'] == ct]['correlation'].values \n",
        "                  for ct in correlation_types]\n",
        "\n",
        "# Create grouped box plot: within-kid + all cross-kid types\n",
        "all_data = [within_kid_corrs] + cross_kid_data\n",
        "all_labels = ['Within-Kid\\n(Younger-Older)'] + [f'Cross-Kid\\n({label})' for label in correlation_labels]\n",
        "\n",
        "x_pos = np.arange(len(all_labels))\n",
        "bp2 = ax5.boxplot(all_data, labels=all_labels, patch_artist=True)\n",
        "\n",
        "# Color within-kid differently from cross-kid\n",
        "bp2['boxes'][0].set_facecolor('#FFD93D')\n",
        "bp2['boxes'][0].set_alpha(0.7)\n",
        "for i in range(1, len(bp2['boxes'])):\n",
        "    bp2['boxes'][i].set_facecolor('#FF6B6B')\n",
        "    bp2['boxes'][i].set_alpha(0.7)\n",
        "\n",
        "ax5.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax5.set_title('Within-Kid vs Cross-Kid Correlations\\n(All Types)', fontsize=13, pad=10)\n",
        "ax5.grid(True, alpha=0.3, axis='y')\n",
        "ax5.set_ylim([0, 1])\n",
        "plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=9)\n",
        "\n",
        "# 6. Heatmap of cross-kid correlations (younger-younger only, for clarity)\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "yy_df = valid_cross_kid_df[valid_cross_kid_df['correlation_type'] == 'younger_younger'].copy()\n",
        "# Create pivot table for heatmap\n",
        "pivot_data = yy_df.pivot(index='subject_id_1', columns='subject_id_2', values='correlation')\n",
        "# Make symmetric (fill lower triangle)\n",
        "pivot_data = pivot_data.fillna(pivot_data.T)\n",
        "# Sort by mean correlation for better visualization\n",
        "pivot_data['mean_corr'] = pivot_data.mean(axis=1)\n",
        "pivot_data = pivot_data.sort_values('mean_corr', ascending=False)\n",
        "pivot_data = pivot_data.drop('mean_corr', axis=1)\n",
        "pivot_data = pivot_data.T\n",
        "pivot_data['mean_corr'] = pivot_data.mean(axis=1)\n",
        "pivot_data = pivot_data.sort_values('mean_corr', ascending=False)\n",
        "pivot_data = pivot_data.drop('mean_corr', axis=1)\n",
        "\n",
        "im = ax6.imshow(pivot_data.values, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "ax6.set_xticks(range(len(pivot_data.columns)))\n",
        "ax6.set_xticklabels(pivot_data.columns, rotation=45, ha='right', fontsize=8)\n",
        "ax6.set_yticks(range(len(pivot_data.index)))\n",
        "ax6.set_yticklabels(pivot_data.index, fontsize=8)\n",
        "ax6.set_xlabel('Subject ID 1', fontsize=11)\n",
        "ax6.set_ylabel('Subject ID 2', fontsize=11)\n",
        "ax6.set_title('Cross-Kid Correlations (Younger-Younger)\\nHeatmap', fontsize=13, pad=10)\n",
        "cbar = plt.colorbar(im, ax=ax6, label='RDM Correlation', fraction=0.046, pad=0.04)\n",
        "\n",
        "plt.suptitle('Cross-Kid RDM Correlations Analysis', \n",
        "             fontsize=16, y=0.995, fontweight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"cross_kid_correlations_visualization.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved cross-kid correlation visualization to {output_dir / 'cross_kid_correlations_visualization.png'}\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross-Kid Category Group Correlations\n",
        "\n",
        "Compute cross-kid correlations separately for each semantic category group (animals, bodyparts, big_objects, small_objects, others). This allows us to examine whether similarity between children varies across different semantic domains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing cross-kid category group correlations...\n",
            "Category group sizes: [('animals', 19), ('bodyparts', 14), ('big_objects', 32), ('small_objects', 96), ('others', 2)]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-kid category correlations: 100%|██████████| 18/18 [00:01<00:00, 13.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-kid category group correlation analysis:\n",
            "  Total measurements: 3060\n",
            "\n",
            "Mean correlations by category group and correlation type:\n",
            "\n",
            "  animals:\n",
            "    younger_younger     : 0.458 ± 0.149 (n=153)\n",
            "    younger_older       : 0.420 ± 0.156 (n=153)\n",
            "    older_younger       : 0.417 ± 0.121 (n=153)\n",
            "    older_older         : 0.403 ± 0.130 (n=153)\n",
            "\n",
            "  bodyparts:\n",
            "    younger_younger     : 0.782 ± 0.099 (n=153)\n",
            "    younger_older       : 0.750 ± 0.107 (n=153)\n",
            "    older_younger       : 0.743 ± 0.107 (n=153)\n",
            "    older_older         : 0.715 ± 0.113 (n=153)\n",
            "\n",
            "  big_objects:\n",
            "    younger_younger     : 0.631 ± 0.100 (n=153)\n",
            "    younger_older       : 0.602 ± 0.099 (n=153)\n",
            "    older_younger       : 0.607 ± 0.089 (n=153)\n",
            "    older_older         : 0.579 ± 0.094 (n=153)\n",
            "\n",
            "  small_objects:\n",
            "    younger_younger     : 0.689 ± 0.110 (n=153)\n",
            "    younger_older       : 0.681 ± 0.109 (n=153)\n",
            "    older_younger       : 0.696 ± 0.069 (n=153)\n",
            "    older_older         : 0.690 ± 0.061 (n=153)\n",
            "  others: No valid correlations\n",
            "\n",
            "Saved cross-kid category group correlations to developmental_trajectory_rdms_clip/cross_kid_category_group_correlations.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute cross-kid category group correlations\n",
        "print(\"Computing cross-kid category group correlations...\")\n",
        "\n",
        "# Get category groups from organized structure\n",
        "category_groups = {\n",
        "    'animals': organized['animals'],\n",
        "    'bodyparts': organized['bodyparts'],\n",
        "    'big_objects': organized['big_objects'],\n",
        "    'small_objects': organized['small_objects'],\n",
        "    'others': organized['others']\n",
        "}\n",
        "\n",
        "print(f\"Category group sizes: {[(name, len(cats)) for name, cats in category_groups.items()]}\")\n",
        "\n",
        "# Get list of subjects with both younger and older RDMs\n",
        "valid_subjects = [sid for sid in subject_age_rdms.keys() \n",
        "                  if 'younger' in subject_age_rdms[sid] and 'older' in subject_age_rdms[sid]]\n",
        "\n",
        "# Store cross-kid category group correlation data\n",
        "cross_kid_category_data = []\n",
        "\n",
        "# Compute all pairwise correlations by category group\n",
        "for i, subject_id_1 in enumerate(tqdm(valid_subjects, desc=\"Cross-kid category correlations\")):\n",
        "    for subject_id_2 in valid_subjects[i+1:]:  # Only compute upper triangle (avoid duplicates)\n",
        "        \n",
        "        # Get RDMs and categories for both subjects\n",
        "        rdm1_younger = subject_age_rdms[subject_id_1]['younger']\n",
        "        rdm1_older = subject_age_rdms[subject_id_1]['older']\n",
        "        cats1_younger = subject_age_rdm_categories[subject_id_1]['younger']\n",
        "        cats1_older = subject_age_rdm_categories[subject_id_1]['older']\n",
        "        \n",
        "        rdm2_younger = subject_age_rdms[subject_id_2]['younger']\n",
        "        rdm2_older = subject_age_rdms[subject_id_2]['older']\n",
        "        cats2_younger = subject_age_rdm_categories[subject_id_2]['younger']\n",
        "        cats2_older = subject_age_rdm_categories[subject_id_2]['older']\n",
        "        \n",
        "        # Compute correlation for each category group and each correlation type\n",
        "        for group_name, group_categories in category_groups.items():\n",
        "            for corr_type, (rdm1, rdm2, cats1, cats2) in [\n",
        "                ('younger_younger', (rdm1_younger, rdm2_younger, cats1_younger, cats2_younger)),\n",
        "                ('younger_older', (rdm1_younger, rdm2_older, cats1_younger, cats2_older)),\n",
        "                ('older_younger', (rdm1_older, rdm2_younger, cats1_older, cats2_younger)),\n",
        "                ('older_older', (rdm1_older, rdm2_older, cats1_older, cats2_older))\n",
        "            ]:\n",
        "                # Find common categories in this group that are present in both RDMs\n",
        "                common_in_group = [cat for cat in group_categories \n",
        "                                  if cat in cats1 and cat in ordered_categories and cat in cats2]\n",
        "                \n",
        "                if len(common_in_group) < 2:\n",
        "                    # Not enough categories in this group for correlation\n",
        "                    cross_kid_category_data.append({\n",
        "                        'subject_id_1': subject_id_1,\n",
        "                        'subject_id_2': subject_id_2,\n",
        "                        'correlation_type': corr_type,\n",
        "                        'category_group': group_name,\n",
        "                        'correlation': np.nan,\n",
        "                        'n_common_categories': len(common_in_group),\n",
        "                        'n_categories_subject1': len([c for c in group_categories if c in cats1]),\n",
        "                        'n_categories_subject2': len([c for c in group_categories if c in cats2])\n",
        "                    })\n",
        "                    continue\n",
        "                \n",
        "                # Get indices for common categories in this group\n",
        "                common_indices = [ordered_categories.index(cat) for cat in common_in_group]\n",
        "                \n",
        "                # Extract submatrices for this group\n",
        "                rdm1_group = rdm1[np.ix_(common_indices, common_indices)]\n",
        "                rdm2_group = rdm2[np.ix_(common_indices, common_indices)]\n",
        "                \n",
        "                # Get upper triangle (excluding diagonal)\n",
        "                mask = np.triu(np.ones_like(rdm1_group, dtype=bool), k=1)\n",
        "                rdm1_flat = rdm1_group[mask]\n",
        "                rdm2_flat = rdm2_group[mask]\n",
        "                \n",
        "                # Filter out NaN values\n",
        "                valid_mask = ~(np.isnan(rdm1_flat) | np.isnan(rdm2_flat))\n",
        "                rdm1_valid = rdm1_flat[valid_mask]\n",
        "                rdm2_valid = rdm2_flat[valid_mask]\n",
        "                \n",
        "                # Compute Spearman correlation\n",
        "                if len(rdm1_valid) > 0:\n",
        "                    corr, _ = spearmanr(rdm1_valid, rdm2_valid)\n",
        "                else:\n",
        "                    corr = np.nan\n",
        "                \n",
        "                cross_kid_category_data.append({\n",
        "                    'subject_id_1': subject_id_1,\n",
        "                    'subject_id_2': subject_id_2,\n",
        "                    'correlation_type': corr_type,\n",
        "                    'category_group': group_name,\n",
        "                    'correlation': corr,\n",
        "                    'n_common_categories': len(common_in_group),\n",
        "                    'n_categories_subject1': len([c for c in group_categories if c in cats1]),\n",
        "                    'n_categories_subject2': len([c for c in group_categories if c in cats2])\n",
        "                })\n",
        "\n",
        "# Create DataFrame\n",
        "cross_kid_category_df = pd.DataFrame(cross_kid_category_data)\n",
        "cross_kid_category_df.to_csv(output_dir / \"cross_kid_category_group_correlations.csv\", index=False)\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nCross-kid category group correlation analysis:\")\n",
        "print(f\"  Total measurements: {len(cross_kid_category_df)}\")\n",
        "\n",
        "print(f\"\\nMean correlations by category group and correlation type:\")\n",
        "for group_name in category_groups.keys():\n",
        "    group_data = cross_kid_category_df[cross_kid_category_df['category_group'] == group_name]\n",
        "    valid_corrs = group_data['correlation'].dropna()\n",
        "    if len(valid_corrs) > 0:\n",
        "        print(f\"\\n  {group_name}:\")\n",
        "        for corr_type in ['younger_younger', 'younger_older', 'older_younger', 'older_older']:\n",
        "            type_data = group_data[group_data['correlation_type'] == corr_type]['correlation'].dropna()\n",
        "            if len(type_data) > 0:\n",
        "                print(f\"    {corr_type:20s}: {type_data.mean():.3f} ± {type_data.std():.3f} (n={len(type_data)})\")\n",
        "    else:\n",
        "        print(f\"  {group_name}: No valid correlations\")\n",
        "\n",
        "print(f\"\\nSaved cross-kid category group correlations to {output_dir / 'cross_kid_category_group_correlations.csv'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Null Model Comparison\n",
        "\n",
        "To validate that the observed cross-kid correlations are meaningful and not due to chance, we compare them to a null model. The null model permutes the rows/columns of one RDM randomly, destroying the category structure while preserving the distribution of distance values. If real correlations are significantly higher than null correlations, this confirms that children's object representations share meaningful structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing null model correlations...\n",
            "This may take a few minutes...\n",
            "Computing null model for 50 subject pairs with 100 permutations each...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null model: 100%|██████████| 50/50 [00:36<00:00,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Null model analysis:\n",
            "  Total comparisons: 200\n",
            "  Permutations per comparison: 100\n",
            "\n",
            "Real vs Null correlations:\n",
            "  Real correlation mean: 0.641 ± 0.115\n",
            "  Null correlation mean: 0.000 ± 0.011\n",
            "  Difference: 0.641\n",
            "\n",
            "Z-scores (how many std devs above null):\n",
            "  Mean z-score: 63.915 ± 20.278\n",
            "  Min z-score: 18.150\n",
            "  Max z-score: 102.882\n",
            "  Proportion with z > 2: 100.0%\n",
            "  Proportion with z > 3: 100.0%\n",
            "\n",
            "By correlation type:\n",
            "  younger_younger     : Real=0.630, Null=-0.000, Z=61.445\n",
            "  younger_older       : Real=0.617, Null=0.000, Z=59.793\n",
            "  older_younger       : Real=0.665, Null=0.000, Z=69.146\n",
            "  older_older         : Real=0.654, Null=-0.000, Z=65.277\n",
            "\n",
            "Saved null model results to developmental_trajectory_rdms_clip/null_model_correlations.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Null model: Permute RDM rows/columns to destroy structure\n",
        "print(\"Computing null model correlations...\")\n",
        "print(\"This may take a few minutes...\")\n",
        "\n",
        "n_permutations = 100  # Number of permutations for null distribution\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "# Get list of subjects with both younger and older RDMs\n",
        "valid_subjects = [sid for sid in subject_age_rdms.keys() \n",
        "                  if 'younger' in subject_age_rdms[sid] and 'older' in subject_age_rdms[sid]]\n",
        "\n",
        "# Store null model data\n",
        "null_model_data = []\n",
        "\n",
        "# Sample a subset of subject pairs for null model (to save computation time)\n",
        "# Use same pairs as in real analysis, but compute fewer permutations\n",
        "n_pairs_to_sample = min(50, len(valid_subjects) * (len(valid_subjects) - 1) // 2)\n",
        "sampled_pairs = []\n",
        "\n",
        "for i, subject_id_1 in enumerate(valid_subjects):\n",
        "    for subject_id_2 in valid_subjects[i+1:]:\n",
        "        sampled_pairs.append((subject_id_1, subject_id_2))\n",
        "        if len(sampled_pairs) >= n_pairs_to_sample:\n",
        "            break\n",
        "    if len(sampled_pairs) >= n_pairs_to_sample:\n",
        "        break\n",
        "\n",
        "print(f\"Computing null model for {len(sampled_pairs)} subject pairs with {n_permutations} permutations each...\")\n",
        "\n",
        "for subject_id_1, subject_id_2 in tqdm(sampled_pairs, desc=\"Null model\"):\n",
        "    # Get RDMs and categories for both subjects\n",
        "    rdm1_younger = subject_age_rdms[subject_id_1]['younger']\n",
        "    rdm1_older = subject_age_rdms[subject_id_1]['older']\n",
        "    cats1_younger = subject_age_rdm_categories[subject_id_1]['younger']\n",
        "    cats1_older = subject_age_rdm_categories[subject_id_1]['older']\n",
        "    \n",
        "    rdm2_younger = subject_age_rdms[subject_id_2]['younger']\n",
        "    rdm2_older = subject_age_rdms[subject_id_2]['older']\n",
        "    cats2_younger = subject_age_rdm_categories[subject_id_2]['younger']\n",
        "    cats2_older = subject_age_rdm_categories[subject_id_2]['older']\n",
        "    \n",
        "    # For each correlation type, compute null distribution\n",
        "    for corr_type, (rdm1, rdm2, cats1, cats2) in [\n",
        "        ('younger_younger', (rdm1_younger, rdm2_younger, cats1_younger, cats2_younger)),\n",
        "        ('younger_older', (rdm1_younger, rdm2_older, cats1_younger, cats2_older)),\n",
        "        ('older_younger', (rdm1_older, rdm2_younger, cats1_older, cats2_younger)),\n",
        "        ('older_older', (rdm1_older, rdm2_older, cats1_older, cats2_older))\n",
        "    ]:\n",
        "        # Find common categories\n",
        "        common_categories = [cat for cat in ordered_categories \n",
        "                           if cat in cats1 and cat in cats2]\n",
        "        \n",
        "        if len(common_categories) < 2:\n",
        "            continue\n",
        "        \n",
        "        # Get indices for common categories\n",
        "        common_indices = [ordered_categories.index(cat) for cat in common_categories]\n",
        "        \n",
        "        # Extract submatrices for common categories\n",
        "        rdm1_subset = rdm1[np.ix_(common_indices, common_indices)].copy()\n",
        "        rdm2_subset = rdm2[np.ix_(common_indices, common_indices)].copy()\n",
        "        \n",
        "        # Get upper triangle for real correlation\n",
        "        mask = np.triu(np.ones_like(rdm1_subset, dtype=bool), k=1)\n",
        "        rdm1_flat = rdm1_subset[mask]\n",
        "        rdm2_flat = rdm2_subset[mask]\n",
        "        valid_mask = ~(np.isnan(rdm1_flat) | np.isnan(rdm2_flat))\n",
        "        rdm1_valid = rdm1_flat[valid_mask]\n",
        "        rdm2_valid = rdm2_flat[valid_mask]\n",
        "        \n",
        "        if len(rdm1_valid) < 2:\n",
        "            continue\n",
        "        \n",
        "        # Compute real correlation\n",
        "        real_corr, _ = spearmanr(rdm1_valid, rdm2_valid)\n",
        "        \n",
        "        # Compute null correlations by permuting rdm2\n",
        "        null_corrs = []\n",
        "        n_common = len(common_indices)\n",
        "        \n",
        "        for perm in range(n_permutations):\n",
        "            # Create random permutation of indices\n",
        "            perm_indices = np.random.permutation(n_common)\n",
        "            \n",
        "            # Permute both rows and columns of rdm2_subset\n",
        "            rdm2_permuted = rdm2_subset[np.ix_(perm_indices, perm_indices)]\n",
        "            \n",
        "            # Get upper triangle\n",
        "            rdm2_perm_flat = rdm2_permuted[mask]\n",
        "            rdm2_perm_valid = rdm2_perm_flat[valid_mask]\n",
        "            \n",
        "            # Compute correlation\n",
        "            if len(rdm2_perm_valid) > 0:\n",
        "                null_corr, _ = spearmanr(rdm1_valid, rdm2_perm_valid)\n",
        "                null_corrs.append(null_corr)\n",
        "        \n",
        "        # Store results\n",
        "        if len(null_corrs) > 0:\n",
        "            null_model_data.append({\n",
        "                'subject_id_1': subject_id_1,\n",
        "                'subject_id_2': subject_id_2,\n",
        "                'correlation_type': corr_type,\n",
        "                'real_correlation': real_corr,\n",
        "                'null_mean': np.mean(null_corrs),\n",
        "                'null_std': np.std(null_corrs),\n",
        "                'null_min': np.min(null_corrs),\n",
        "                'null_max': np.max(null_corrs),\n",
        "                'null_median': np.median(null_corrs),\n",
        "                'n_permutations': len(null_corrs),\n",
        "                'n_common_categories': len(common_categories),\n",
        "                'z_score': (real_corr - np.mean(null_corrs)) / (np.std(null_corrs) + 1e-10),  # Add small epsilon to avoid division by zero\n",
        "                'p_value_approx': np.mean(np.array(null_corrs) >= real_corr)  # Approximate p-value\n",
        "            })\n",
        "\n",
        "# Create DataFrame\n",
        "null_model_df = pd.DataFrame(null_model_data)\n",
        "null_model_df.to_csv(output_dir / \"null_model_correlations.csv\", index=False)\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\nNull model analysis:\")\n",
        "print(f\"  Total comparisons: {len(null_model_df)}\")\n",
        "print(f\"  Permutations per comparison: {n_permutations}\")\n",
        "\n",
        "print(f\"\\nReal vs Null correlations:\")\n",
        "print(f\"  Real correlation mean: {null_model_df['real_correlation'].mean():.3f} ± {null_model_df['real_correlation'].std():.3f}\")\n",
        "print(f\"  Null correlation mean: {null_model_df['null_mean'].mean():.3f} ± {null_model_df['null_std'].mean():.3f}\")\n",
        "print(f\"  Difference: {(null_model_df['real_correlation'].mean() - null_model_df['null_mean'].mean()):.3f}\")\n",
        "\n",
        "print(f\"\\nZ-scores (how many std devs above null):\")\n",
        "print(f\"  Mean z-score: {null_model_df['z_score'].mean():.3f} ± {null_model_df['z_score'].std():.3f}\")\n",
        "print(f\"  Min z-score: {null_model_df['z_score'].min():.3f}\")\n",
        "print(f\"  Max z-score: {null_model_df['z_score'].max():.3f}\")\n",
        "print(f\"  Proportion with z > 2: {(null_model_df['z_score'] > 2).mean():.1%}\")\n",
        "print(f\"  Proportion with z > 3: {(null_model_df['z_score'] > 3).mean():.1%}\")\n",
        "\n",
        "print(f\"\\nBy correlation type:\")\n",
        "for corr_type in ['younger_younger', 'younger_older', 'older_younger', 'older_older']:\n",
        "    type_data = null_model_df[null_model_df['correlation_type'] == corr_type]\n",
        "    if len(type_data) > 0:\n",
        "        print(f\"  {corr_type:20s}: Real={type_data['real_correlation'].mean():.3f}, Null={type_data['null_mean'].mean():.3f}, Z={type_data['z_score'].mean():.3f}\")\n",
        "\n",
        "print(f\"\\nSaved null model results to {output_dir / 'null_model_correlations.csv'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating null model visualization...\n",
            "Saved null model visualization to developmental_trajectory_rdms_clip/null_model_comparison.png\n",
            "\n",
            "Visualization complete!\n"
          ]
        }
      ],
      "source": [
        "# Visualize null model comparison\n",
        "print(\"Creating null model visualization...\")\n",
        "\n",
        "# Create figure\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "\n",
        "# 1. Histogram: Real vs Null distributions\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "ax1.hist(null_model_df['real_correlation'], bins=30, alpha=0.7, label='Real', color='#FF6B6B', density=True)\n",
        "ax1.hist(null_model_df['null_mean'], bins=30, alpha=0.7, label='Null (mean)', color='#95A5A6', density=True)\n",
        "ax1.axvline(null_model_df['real_correlation'].mean(), color='#FF6B6B', linestyle='--', linewidth=2, label=f\"Real mean: {null_model_df['real_correlation'].mean():.3f}\")\n",
        "ax1.axvline(null_model_df['null_mean'].mean(), color='#95A5A6', linestyle='--', linewidth=2, label=f\"Null mean: {null_model_df['null_mean'].mean():.3f}\")\n",
        "ax1.set_xlabel('RDM Correlation', fontsize=12)\n",
        "ax1.set_ylabel('Density', fontsize=12)\n",
        "ax1.set_title('Real vs Null Correlation Distributions', fontsize=13, pad=10)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Scatter: Real vs Null mean\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "ax2.scatter(null_model_df['null_mean'], null_model_df['real_correlation'], alpha=0.6, s=60)\n",
        "ax2.plot([0, 1], [0, 1], 'r--', alpha=0.5, label='y=x')\n",
        "ax2.set_xlabel('Null Correlation (mean)', fontsize=12)\n",
        "ax2.set_ylabel('Real Correlation', fontsize=12)\n",
        "ax2.set_title('Real vs Null Correlations', fontsize=13, pad=10)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim([-0.1, 0.3])\n",
        "ax2.set_ylim([0.3, 1.0])\n",
        "\n",
        "# 3. Z-score distribution\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "ax3.hist(null_model_df['z_score'], bins=30, alpha=0.7, color='#4ECDC4', edgecolor='black')\n",
        "ax3.axvline(0, color='red', linestyle='--', linewidth=2, label='Null (z=0)')\n",
        "ax3.axvline(2, color='orange', linestyle='--', linewidth=1, label='z=2')\n",
        "ax3.axvline(3, color='darkorange', linestyle='--', linewidth=1, label='z=3')\n",
        "ax3.set_xlabel('Z-Score', fontsize=12)\n",
        "ax3.set_ylabel('Frequency', fontsize=12)\n",
        "ax3.set_title('Z-Score Distribution\\n(Real correlations vs Null)', fontsize=13, pad=10)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Box plot: Real vs Null by correlation type\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "correlation_types = ['younger_younger', 'younger_older', 'older_younger', 'older_older']\n",
        "labels = ['Younger-Younger', 'Younger-Older', 'Older-Younger', 'Older-Older']\n",
        "\n",
        "real_data = [null_model_df[null_model_df['correlation_type'] == ct]['real_correlation'].values for ct in correlation_types]\n",
        "null_data = [null_model_df[null_model_df['correlation_type'] == ct]['null_mean'].values for ct in correlation_types]\n",
        "\n",
        "x_pos = np.arange(len(correlation_types))\n",
        "width = 0.35\n",
        "\n",
        "bp1 = ax4.boxplot(real_data, positions=x_pos - width/2, widths=width, patch_artist=True)\n",
        "bp2 = ax4.boxplot(null_data, positions=x_pos + width/2, widths=width, patch_artist=True)\n",
        "\n",
        "for patch in bp1['boxes']:\n",
        "    patch.set_facecolor('#FF6B6B')\n",
        "    patch.set_alpha(0.7)\n",
        "for patch in bp2['boxes']:\n",
        "    patch.set_facecolor('#95A5A6')\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax4.set_ylabel('RDM Correlation', fontsize=12)\n",
        "ax4.set_title('Real vs Null by Correlation Type', fontsize=13, pad=10)\n",
        "ax4.legend([bp1['boxes'][0], bp2['boxes'][0]], ['Real', 'Null'], loc='upper left')\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "ax4.set_xticks(x_pos)\n",
        "ax4.set_xticklabels(labels, rotation=45, ha='right')\n",
        "ax4.set_ylim([-0.1, 1.0])\n",
        "\n",
        "# 5. Difference (Real - Null) distribution\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "diff = null_model_df['real_correlation'] - null_model_df['null_mean']\n",
        "ax5.hist(diff, bins=30, alpha=0.7, color='#FFA07A', edgecolor='black')\n",
        "ax5.axvline(0, color='red', linestyle='--', linewidth=2, label='No difference')\n",
        "ax5.axvline(diff.mean(), color='blue', linestyle='--', linewidth=2, label=f\"Mean: {diff.mean():.3f}\")\n",
        "ax5.set_xlabel('Real - Null Correlation', fontsize=12)\n",
        "ax5.set_ylabel('Frequency', fontsize=12)\n",
        "ax5.set_title('Difference Distribution\\n(Real - Null)', fontsize=13, pad=10)\n",
        "ax5.legend()\n",
        "ax5.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Z-score by correlation type\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "z_data = [null_model_df[null_model_df['correlation_type'] == ct]['z_score'].values for ct in correlation_types]\n",
        "bp3 = ax6.boxplot(z_data, labels=labels, patch_artist=True)\n",
        "for patch in bp3['boxes']:\n",
        "    patch.set_facecolor('#4ECDC4')\n",
        "    patch.set_alpha(0.7)\n",
        "ax6.axhline(0, color='red', linestyle='--', linewidth=1, label='Null (z=0)')\n",
        "ax6.axhline(2, color='orange', linestyle='--', linewidth=1, label='z=2')\n",
        "ax6.axhline(3, color='darkorange', linestyle='--', linewidth=1, label='z=3')\n",
        "ax6.set_ylabel('Z-Score', fontsize=12)\n",
        "ax6.set_title('Z-Score by Correlation Type', fontsize=13, pad=10)\n",
        "ax6.legend(loc='upper left')\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "ax6.set_xticklabels(labels, rotation=45, ha='right')\n",
        "\n",
        "plt.suptitle('Null Model Comparison: Real vs Permuted RDMs', \n",
        "             fontsize=16, y=0.995, fontweight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"null_model_comparison.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved null model visualization to {output_dir / 'null_model_comparison.png'}\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating visualizations for cross-kid category group correlations...\n",
            "Saved cross-kid category group visualization to developmental_trajectory_rdms_clip/cross_kid_category_group_correlations_visualization.png\n",
            "\n",
            "Visualization complete!\n"
          ]
        }
      ],
      "source": [
        "# Visualize cross-kid category group correlations\n",
        "print(\"Creating visualizations for cross-kid category group correlations...\")\n",
        "\n",
        "# Filter out NaN correlations for plotting\n",
        "valid_category_df = cross_kid_category_df[cross_kid_category_df['correlation'].notna()].copy()\n",
        "\n",
        "# Create figure\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "# 1. Box plot comparing category groups (all correlation types combined)\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "category_order = ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']\n",
        "box_data = [valid_category_df[valid_category_df['category_group'] == group]['correlation'].values \n",
        "            for group in category_order if group in valid_category_df['category_group'].values]\n",
        "\n",
        "labels_filtered = []\n",
        "box_data_filtered = []\n",
        "for group in category_order:\n",
        "    group_data = valid_category_df[valid_category_df['category_group'] == group]['correlation'].values\n",
        "    if len(group_data) > 0:\n",
        "        box_data_filtered.append(group_data)\n",
        "        labels_filtered.append(group.replace('_', ' ').title())\n",
        "\n",
        "bp = ax1.boxplot(box_data_filtered, labels=labels_filtered, patch_artist=True)\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
        "for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax1.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax1.set_title('Cross-Kid Correlations by Category Group\\n(All correlation types)', fontsize=13, pad=10)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.set_ylim([0, 1])\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# 2. Heatmap: Mean correlations by category group and correlation type\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "pivot_data = valid_category_df.groupby(['category_group', 'correlation_type'])['correlation'].mean().unstack(fill_value=np.nan)\n",
        "pivot_data = pivot_data.reindex(category_order)\n",
        "pivot_data = pivot_data[['younger_younger', 'younger_older', 'older_younger', 'older_older']]\n",
        "\n",
        "im = ax2.imshow(pivot_data.values, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "ax2.set_xticks(range(len(pivot_data.columns)))\n",
        "ax2.set_xticklabels([col.replace('_', '-\\n').title() for col in pivot_data.columns], fontsize=9)\n",
        "ax2.set_yticks(range(len(pivot_data.index)))\n",
        "ax2.set_yticklabels([idx.replace('_', ' ').title() for idx in pivot_data.index], fontsize=10)\n",
        "ax2.set_xlabel('Correlation Type', fontsize=11)\n",
        "ax2.set_ylabel('Category Group', fontsize=11)\n",
        "ax2.set_title('Mean Cross-Kid Correlations\\nby Category Group & Type', fontsize=13, pad=10)\n",
        "cbar = plt.colorbar(im, ax=ax2, label='Mean Correlation', fraction=0.046, pad=0.04)\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(len(pivot_data.index)):\n",
        "    for j in range(len(pivot_data.columns)):\n",
        "        val = pivot_data.iloc[i, j]\n",
        "        if not np.isnan(val):\n",
        "            ax2.text(j, i, f'{val:.2f}', ha='center', va='center', \n",
        "                   fontsize=8, color='white' if val < 0.5 else 'black', fontweight='bold')\n",
        "\n",
        "# 3. Violin plot by category group\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "violin_data = [valid_category_df[valid_category_df['category_group'] == group]['correlation'].values \n",
        "               for group in category_order if group in valid_category_df['category_group'].values]\n",
        "parts = ax3.violinplot(violin_data, positions=range(len(labels_filtered)), showmeans=True, showmedians=True)\n",
        "for i, pc in enumerate(parts['bodies']):\n",
        "    pc.set_facecolor(colors[i % len(colors)])\n",
        "    pc.set_alpha(0.7)\n",
        "ax3.set_xticks(range(len(labels_filtered)))\n",
        "ax3.set_xticklabels(labels_filtered, rotation=45, ha='right')\n",
        "ax3.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax3.set_title('Distribution by Category Group\\n(Violin Plot)', fontsize=13, pad=10)\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "ax3.set_ylim([0, 1])\n",
        "\n",
        "# 4. Comparison: Cross-kid category groups vs Within-kid category groups\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "# Load within-kid category correlations if available\n",
        "try:\n",
        "    within_category_df = pd.read_csv(output_dir / \"category_group_correlations.csv\")\n",
        "    within_valid = within_category_df[within_category_df['correlation'].notna()]\n",
        "    \n",
        "    comparison_data = []\n",
        "    comparison_labels = []\n",
        "    for group in category_order:\n",
        "        cross_data = valid_category_df[valid_category_df['category_group'] == group]['correlation'].values\n",
        "        within_data = within_valid[within_valid['category_group'] == group]['correlation'].values\n",
        "        if len(cross_data) > 0 and len(within_data) > 0:\n",
        "            comparison_data.append(cross_data)\n",
        "            comparison_data.append(within_data)\n",
        "            comparison_labels.append(f\"{group.replace('_', ' ').title()}\\n(Cross)\")\n",
        "            comparison_labels.append(f\"{group.replace('_', ' ').title()}\\n(Within)\")\n",
        "    \n",
        "    if len(comparison_data) > 0:\n",
        "        bp2 = ax4.boxplot(comparison_data, labels=comparison_labels, patch_artist=True)\n",
        "        # Color cross-kid in one color, within-kid in another\n",
        "        for i, patch in enumerate(bp2['boxes']):\n",
        "            if i % 2 == 0:  # Cross-kid\n",
        "                patch.set_facecolor('#FF6B6B')\n",
        "            else:  # Within-kid\n",
        "                patch.set_facecolor('#4ECDC4')\n",
        "            patch.set_alpha(0.7)\n",
        "        ax4.set_ylabel('RDM Correlation', fontsize=12)\n",
        "        ax4.set_title('Cross-Kid vs Within-Kid\\nby Category Group', fontsize=13, pad=10)\n",
        "        ax4.legend([bp2['boxes'][0], bp2['boxes'][1]], ['Cross-Kid', 'Within-Kid'], loc='upper left')\n",
        "        ax4.grid(True, alpha=0.3, axis='y')\n",
        "        ax4.set_ylim([0, 1])\n",
        "        plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=8)\n",
        "except:\n",
        "    ax4.text(0.5, 0.5, 'Within-kid category\\ndata not available', \n",
        "            ha='center', va='center', transform=ax4.transAxes, fontsize=12)\n",
        "    ax4.set_title('Cross-Kid vs Within-Kid\\n(Data not available)', fontsize=13, pad=10)\n",
        "\n",
        "# 5. Scatter: Correlation vs number of common categories by group\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "for i, group in enumerate(category_order):\n",
        "    group_data = valid_category_df[valid_category_df['category_group'] == group]\n",
        "    if len(group_data) > 0:\n",
        "        ax5.scatter(group_data['n_common_categories'], group_data['correlation'], \n",
        "                   label=group.replace('_', ' ').title(), alpha=0.6, s=40, color=colors[i % len(colors)])\n",
        "ax5.set_xlabel('Number of Common Categories', fontsize=12)\n",
        "ax5.set_ylabel('RDM Correlation', fontsize=12)\n",
        "ax5.set_title('Correlation vs Common Categories\\nby Category Group', fontsize=13, pad=10)\n",
        "ax5.legend(loc='best', fontsize=8)\n",
        "ax5.grid(True, alpha=0.3)\n",
        "ax5.set_ylim([0, 1])\n",
        "\n",
        "# 6. Bar plot: Mean correlations by category group\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "mean_corrs = []\n",
        "std_corrs = []\n",
        "group_labels = []\n",
        "for group in category_order:\n",
        "    group_data = valid_category_df[valid_category_df['category_group'] == group]['correlation']\n",
        "    if len(group_data) > 0:\n",
        "        mean_corrs.append(group_data.mean())\n",
        "        std_corrs.append(group_data.std())\n",
        "        group_labels.append(group.replace('_', ' ').title())\n",
        "\n",
        "bars = ax6.bar(range(len(group_labels)), mean_corrs, yerr=std_corrs, \n",
        "              color=colors[:len(group_labels)], alpha=0.7, edgecolor='black')\n",
        "ax6.set_xticks(range(len(group_labels)))\n",
        "ax6.set_xticklabels(group_labels, rotation=45, ha='right')\n",
        "ax6.set_ylabel('Mean RDM Correlation', fontsize=12)\n",
        "ax6.set_title('Mean Cross-Kid Correlations\\nby Category Group', fontsize=13, pad=10)\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "ax6.set_ylim([0, 1])\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, mean, std) in enumerate(zip(bars, mean_corrs, std_corrs)):\n",
        "    height = bar.get_height()\n",
        "    ax6.text(bar.get_x() + bar.get_width()/2., height + std + 0.02,\n",
        "            f'{mean:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Cross-Kid Category Group Correlations Analysis', \n",
        "             fontsize=16, y=0.995, fontweight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"cross_kid_category_group_correlations_visualization.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved cross-kid category group visualization to {output_dir / 'cross_kid_category_group_correlations_visualization.png'}\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualization complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vislearnlabpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
