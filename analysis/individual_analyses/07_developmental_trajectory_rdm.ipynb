{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Developmental Trajectory RDM Analysis\n",
        "\n",
        "This notebook creates two Representational Dissimilarity Matrices (RDMs) for each individual subject, split by a median age threshold computed across all participants.\n",
        "This allows tracking how object representations change developmentally within each subject.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This analysis:\n",
        "1. Loads grouped embeddings (averaged by category, subject, and age_mo)\n",
        "2. Calculates the overall median age across all participants\n",
        "3. For each subject, splits data into \"younger\" (age_mo <= median) and \"older\" (age_mo > median) bins\n",
        "4. Computes RDM for each subject for each age bin (2 RDMs per subject)\n",
        "5. Handles data density differences (some subjects/ages have more data)\n",
        "6. Visualizes developmental trajectories\n",
        "7. Compares RDMs between younger and older periods within subjects\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Median split**: Uses overall median age across all participants to split each subject's data\n",
        "- **Two RDMs per subject**: One for \"younger\" period, one for \"older\" period\n",
        "- **Data density handling**: Minimum category threshold per age bin\n",
        "- **Trajectory analysis**: Compare RDMs between younger and older periods to see developmental changes\n",
        "- **Missing data handling**: Only includes subjects with sufficient data in both bins\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
        "from scipy.spatial.distance import squareform\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set matplotlib backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "print(\"All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized embeddings directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/facebook_dinov3-vitb16-pretrain-lvd1689m_grouped_by_age-mo_normalized\n",
            "Output directory: developmental_trajectory_rdms\n",
            "Excluded subject: 00270001\n",
            "CDI path: ../../data/cdi_words.csv\n",
            "Use clustering: True\n",
            "Use predefined category list: True\n",
            "Predefined category list path: ../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\n",
            "Min categories per age bin: 8\n",
            "\n",
            "Note: Using pre-normalized embeddings from notebook 05 (no normalization performed here)\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "# Path to normalized embeddings from notebook 05 (age-month level normalized embeddings)\n",
        "# These are saved in category folders: {normalized_embeddings_dir}/{category}/{subject_id}_{age_mo}_month_level_avg.npy\n",
        "normalized_embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/facebook_dinov3-vitb16-pretrain-lvd1689m_grouped_by_age-mo_normalized\")\n",
        "\n",
        "# Detect embedding type from path\n",
        "normalized_embeddings_dir_str = str(normalized_embeddings_dir).lower()\n",
        "if \"dinov3\" in normalized_embeddings_dir_str or \"dinov\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"dinov3\"\n",
        "elif \"clip\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"clip\"\n",
        "else:\n",
        "    embedding_type = \"unknown\"\n",
        "\n",
        "# Create output directory with embedding type in name\n",
        "output_dir = Path(f\"developmental_trajectory_rdms_{embedding_type}\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Subject to exclude from analyses (should match notebook 06)\n",
        "excluded_subject = \"00270001\"\n",
        "\n",
        "# Categories file (optional - to filter to specific categories)\n",
        "categories_file = Path(\"../../data/things_bv_overlap_categories_exclude_zero_precisions.txt\")\n",
        "\n",
        "# CDI words CSV file (required for category type organization)\n",
        "cdi_path = Path(\"../../data/cdi_words.csv\")\n",
        "\n",
        "# Hierarchical clustering options\n",
        "use_clustering = True  # Enable hierarchical clustering within category groups\n",
        "save_dendrograms = True  # Save dendrogram plots for each category group\n",
        "\n",
        "# Predefined category list for consistent RDM ordering (optional)\n",
        "# Set to None to use automatic organization, or provide path to category order file\n",
        "# This allows comparing RDMs across subjects with the same category ordering\n",
        "USE_PREDEFINED_CATEGORY_LIST = True  # If True, load category order from PREDEFINED_CATEGORY_LIST_PATH\n",
        "PREDEFINED_CATEGORY_LIST_PATH = \"../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\"  # Path to text file with category order (one category per line), or None\n",
        "# Example: PREDEFINED_CATEGORY_LIST_PATH = \"../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\"\n",
        "\n",
        "# Minimum categories required per age bin to compute RDM\n",
        "min_categories_per_age_bin = 8\n",
        "\n",
        "print(f\"Normalized embeddings directory: {normalized_embeddings_dir}\")\n",
        "print(f\"Detected embedding type: {embedding_type}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"Excluded subject: {excluded_subject}\")\n",
        "print(f\"CDI path: {cdi_path}\")\n",
        "print(f\"Use clustering: {use_clustering}\")\n",
        "print(f\"Use predefined category list: {USE_PREDEFINED_CATEGORY_LIST}\")\n",
        "if USE_PREDEFINED_CATEGORY_LIST and PREDEFINED_CATEGORY_LIST_PATH:\n",
        "    print(f\"Predefined category list path: {PREDEFINED_CATEGORY_LIST_PATH}\")\n",
        "print(f\"Min categories per age bin: {min_categories_per_age_bin}\")\n",
        "print(\"\\nNote: Using pre-normalized embeddings from notebook 05 (no normalization performed here)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded!\n"
          ]
        }
      ],
      "source": [
        "def load_category_types(cdi_path):\n",
        "    \"\"\"Load category type information from CDI words CSV\"\"\"\n",
        "    print(f\"Loading category types from {cdi_path}...\")\n",
        "    cdi_df = pd.read_csv(cdi_path)\n",
        "    \n",
        "    category_types = {}\n",
        "    for _, row in cdi_df.iterrows():\n",
        "        category_types[row['uni_lemma']] = {\n",
        "            'is_animate': bool(row.get('is_animate', 0)),\n",
        "            'is_bodypart': bool(row.get('is_bodypart', 0)),\n",
        "            'is_small': bool(row.get('is_small', 0)),\n",
        "            'is_big': bool(row.get('is_big', 0))\n",
        "        }\n",
        "    \n",
        "    print(f\"Loaded type information for {len(category_types)} categories\")\n",
        "    return category_types\n",
        "\n",
        "def cluster_categories_within_group(group_categories, cat_to_embedding, save_dendrogram=False, output_dir=None, group_name=None):\n",
        "    \"\"\"\n",
        "    Perform hierarchical clustering within a group of categories.\n",
        "    \n",
        "    Args:\n",
        "        group_categories: List of category names in the group\n",
        "        cat_to_embedding: Dictionary mapping category names to embeddings\n",
        "        save_dendrogram: Whether to save dendrogram plot (default: False)\n",
        "        output_dir: Output directory for saving dendrogram (required if save_dendrogram=True)\n",
        "        group_name: Name of the group for saving dendrogram (required if save_dendrogram=True)\n",
        "    \n",
        "    Returns:\n",
        "        List of category names reordered according to clustering dendrogram\n",
        "    \"\"\"\n",
        "    if len(group_categories) <= 1:\n",
        "        return group_categories, None\n",
        "    \n",
        "    # Get embeddings for this group\n",
        "    group_embeddings = np.array([cat_to_embedding[cat].flatten() for cat in group_categories])\n",
        "    \n",
        "    # Normalize embeddings (z-score normalization per embedding)\n",
        "    normalized_embeddings = (group_embeddings - group_embeddings.mean(axis=0)) / (group_embeddings.std(axis=0) + 1e-10)\n",
        "    \n",
        "    # Compute distance matrix (1 - cosine similarity)\n",
        "    similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    np.fill_diagonal(distance_matrix, 0)\n",
        "    \n",
        "    # Convert to condensed form for linkage\n",
        "    condensed_distances = squareform(distance_matrix)\n",
        "    \n",
        "    # Perform hierarchical clustering\n",
        "    linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "    \n",
        "    # Get optimal leaf ordering for better visualization\n",
        "    try:\n",
        "        linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "    except:\n",
        "        # If optimal leaf ordering fails, use original linkage\n",
        "        pass\n",
        "    \n",
        "    # Extract the order from the dendrogram\n",
        "    dendro_dict = dendrogram(linkage_matrix, no_plot=True)\n",
        "    leaf_order = dendro_dict['leaves']\n",
        "    \n",
        "    # Reorder categories according to clustering\n",
        "    clustered_categories = [group_categories[i] for i in leaf_order]\n",
        "    \n",
        "    # Save dendrogram if requested\n",
        "    if save_dendrogram and output_dir is not None and group_name is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        dendrogram(linkage_matrix, \n",
        "                  labels=group_categories,\n",
        "                  leaf_rotation=90,\n",
        "                  leaf_font_size=10)\n",
        "        plt.title(f'Hierarchical Clustering Dendrogram: {group_name.upper()}\\n({len(group_categories)} categories)',\n",
        "                 fontsize=16, pad=20)\n",
        "        plt.xlabel('Category', fontsize=12)\n",
        "        plt.ylabel('Distance', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save as PNG\n",
        "        output_path_png = output_dir / f'dendrogram_{group_name}.png'\n",
        "        plt.savefig(output_path_png, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_png}\")\n",
        "        \n",
        "        # Save as PDF\n",
        "        output_path_pdf = output_dir / f'dendrogram_{group_name}.pdf'\n",
        "        plt.savefig(output_path_pdf, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_pdf}\")\n",
        "        \n",
        "        plt.close()\n",
        "    \n",
        "    return clustered_categories, linkage_matrix\n",
        "\n",
        "print(\"Helper functions loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading categories from ../../data/things_bv_overlap_categories_exclude_zero_precisions.txt...\n",
            "Loaded 163 categories\n"
          ]
        }
      ],
      "source": [
        "# Load allowed categories if file exists\n",
        "allowed_categories = None\n",
        "if categories_file.exists():\n",
        "    print(f\"Loading categories from {categories_file}...\")\n",
        "    with open(categories_file, 'r') as f:\n",
        "        allowed_categories = set(line.strip() for line in f if line.strip())\n",
        "    print(f\"Loaded {len(allowed_categories)} categories\")\n",
        "else:\n",
        "    print(f\"Categories file not found, using all categories\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Embeddings by Age\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pre-normalized embeddings from 163 categories...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading categories: 100%|██████████| 163/163 [00:01<00:00, 105.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded embeddings for 31 subjects\n",
            "Age bins found: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37]\n",
            "Age range: 6 to 37 months\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def load_embeddings_by_age(embeddings_dir, allowed_categories=None, excluded_subject=None, age_binning_strategy='exact', age_bin_size=3):\n",
        "    \"\"\"\n",
        "    Load pre-normalized embeddings organized by subject, age_mo, and category.\n",
        "    These embeddings are already normalized from notebook 05.\n",
        "    \n",
        "    Returns:\n",
        "        subject_age_embeddings: dict[subject_id][age_mo_bin][category] = embedding array (already normalized)\n",
        "    \"\"\"\n",
        "    subject_age_embeddings = defaultdict(lambda: defaultdict(dict))\n",
        "    \n",
        "    # Get all category folders\n",
        "    category_folders = [f for f in embeddings_dir.iterdir() if f.is_dir()]\n",
        "    \n",
        "    if allowed_categories:\n",
        "        category_folders = [f for f in category_folders if f.name in allowed_categories]\n",
        "    \n",
        "    print(f\"Loading pre-normalized embeddings from {len(category_folders)} categories...\")\n",
        "    \n",
        "    for category_folder in tqdm(category_folders, desc=\"Loading categories\"):\n",
        "        category = category_folder.name\n",
        "        \n",
        "        # Get all embedding files in this category\n",
        "        embedding_files = list(category_folder.glob(\"*.npy\"))\n",
        "        \n",
        "        for emb_file in embedding_files:\n",
        "            # Parse filename: {subject_id}_{age_mo}_month_level_avg.npy\n",
        "            filename = emb_file.stem  # without .npy\n",
        "            parts = filename.split('_')\n",
        "            \n",
        "            if len(parts) < 2:\n",
        "                continue\n",
        "            \n",
        "            # Extract subject_id and age_mo\n",
        "            subject_id = parts[0]\n",
        "            \n",
        "            # Exclude subject if specified\n",
        "            if excluded_subject and subject_id == excluded_subject:\n",
        "                continue\n",
        "            \n",
        "            age_mo = int(parts[1]) if parts[1].isdigit() else None\n",
        "            \n",
        "            if age_mo is None:\n",
        "                continue\n",
        "            \n",
        "            # Apply age binning strategy\n",
        "            if age_binning_strategy == 'binned':\n",
        "                age_mo_bin = (age_mo // age_bin_size) * age_bin_size  # Round down to bin\n",
        "            else:\n",
        "                age_mo_bin = age_mo  # Use exact age\n",
        "            \n",
        "            try:\n",
        "                embedding = np.load(emb_file)\n",
        "                subject_age_embeddings[subject_id][age_mo_bin][category] = embedding\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {emb_file}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    return subject_age_embeddings\n",
        "\n",
        "# Load pre-normalized embeddings from notebook 05 (using exact ages - we'll do median split later)\n",
        "subject_age_embeddings = load_embeddings_by_age(\n",
        "    normalized_embeddings_dir,  # Use normalized embeddings from notebook 05\n",
        "    allowed_categories,\n",
        "    excluded_subject=excluded_subject,  # Exclude specified subject\n",
        "    age_binning_strategy='exact',  # Use exact ages\n",
        "    age_bin_size=1  # Not used when strategy is 'exact'\n",
        ")\n",
        "\n",
        "print(f\"\\nLoaded embeddings for {len(subject_age_embeddings)} subjects\")\n",
        "\n",
        "# Show age bin distribution\n",
        "all_age_bins = set()\n",
        "for subject_id, age_data in subject_age_embeddings.items():\n",
        "    all_age_bins.update(age_data.keys())\n",
        "\n",
        "print(f\"Age bins found: {sorted(all_age_bins)}\")\n",
        "print(f\"Age range: {min(all_age_bins)} to {max(all_age_bins)} months\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Overall Median Age\n",
        "\n",
        "We calculate the overall median age across all participants to split each subject's data into younger and older periods. Note: Embeddings are already normalized from notebook 05, so no normalization is performed here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall median age across all participants: 16.0 months\n",
            "Age range: 6 to 37 months\n",
            "Total age observations: 266\n",
            "\n",
            "Using pre-normalized embeddings for 31 subjects\n",
            "  Note: Embeddings were normalized in notebook 05 (within each subject across all age bins)\n",
            "  No additional normalization performed here\n",
            "\n",
            "Total unique categories across all subjects and ages: 163\n",
            "Note: RDMs will be computed with predefined category order after organization step.\n",
            "\n",
            "Identifying subjects with sufficient data in both age bins...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking subjects: 100%|██████████| 31/31 [00:00<00:00, 381.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Identified 18 subjects with sufficient data in both bins\n",
            "  Excluded 13 subjects without sufficient data in both bins\n",
            "\n",
            "Excluded subjects (13):\n",
            "  00220001: no older ages (younger: 155 cats, older: 0 cats)\n",
            "  00230001: no older ages (younger: 143 cats, older: 0 cats)\n",
            "  00340002: no older ages (younger: 99 cats, older: 0 cats)\n",
            "  00350001: no older ages (younger: 111 cats, older: 0 cats)\n",
            "  00350002: no older ages (younger: 123 cats, older: 0 cats)\n",
            "  00360001: no older ages (younger: 153 cats, older: 0 cats)\n",
            "  00390001: no older ages (younger: 141 cats, older: 0 cats)\n",
            "  00430002: no older ages (younger: 112 cats, older: 0 cats)\n",
            "  00440001: no older ages (younger: 134 cats, older: 0 cats)\n",
            "  00460001: no older ages (younger: 140 cats, older: 0 cats)\n",
            "  00550001: no older ages (younger: 132 cats, older: 0 cats)\n",
            "  00720001: no younger ages (younger: 0 cats, older: 154 cats)\n",
            "  00820001: no younger ages (younger: 0 cats, older: 160 cats)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## Calculate Overall Median Age Across All Participants\n",
        "\n",
        "# Collect all age_mo values across all subjects to compute overall median\n",
        "all_ages = []\n",
        "for subject_id, age_data in subject_age_embeddings.items():\n",
        "    all_ages.extend(age_data.keys())\n",
        "\n",
        "overall_median_age = np.median(all_ages)\n",
        "print(f\"Overall median age across all participants: {overall_median_age:.1f} months\")\n",
        "print(f\"Age range: {min(all_ages)} to {max(all_ages)} months\")\n",
        "print(f\"Total age observations: {len(all_ages)}\")\n",
        "\n",
        "## Use Pre-Normalized Embeddings from Notebook 05\n",
        "\n",
        "# Embeddings are already normalized from notebook 05, so we use them directly\n",
        "# Rename for consistency with rest of code\n",
        "subject_age_embeddings_normalized = subject_age_embeddings\n",
        "\n",
        "print(f\"\\nUsing pre-normalized embeddings for {len(subject_age_embeddings_normalized)} subjects\")\n",
        "print(\"  Note: Embeddings were normalized in notebook 05 (within each subject across all age bins)\")\n",
        "print(\"  No additional normalization performed here\")\n",
        "\n",
        "## Aggregate Embeddings by Median Split and Compute RDMs\n",
        "\n",
        "def aggregate_embeddings_by_bin(age_embeddings_dict, age_bin_name):\n",
        "    \"\"\"\n",
        "    Aggregate embeddings for a bin by averaging across all ages in that bin.\n",
        "    \n",
        "    Args:\n",
        "        age_embeddings_dict: dict[age_mo][category] = embedding array\n",
        "        age_bin_name: 'younger' or 'older'\n",
        "    \n",
        "    Returns:\n",
        "        aggregated_embeddings: dict[category] = averaged embedding array\n",
        "    \"\"\"\n",
        "    # Collect all embeddings for each category across ages in this bin\n",
        "    category_embeddings = defaultdict(list)\n",
        "    \n",
        "    for age_mo, categories in age_embeddings_dict.items():\n",
        "        for cat, embedding in categories.items():\n",
        "            category_embeddings[cat].append(embedding)\n",
        "    \n",
        "    # Average embeddings for each category\n",
        "    aggregated = {}\n",
        "    for cat, embeddings_list in category_embeddings.items():\n",
        "        if len(embeddings_list) > 0:\n",
        "            aggregated[cat] = np.mean(embeddings_list, axis=0)\n",
        "    \n",
        "    return aggregated\n",
        "\n",
        "def compute_rdm_for_bin_with_na(bin_embeddings_dict, ordered_categories_list):\n",
        "    \"\"\"\n",
        "    Compute RDM for a single age bin (younger or older) with NA for missing categories.\n",
        "    This ensures consistent ordering across bins using the predefined category order.\n",
        "    \n",
        "    Args:\n",
        "        bin_embeddings_dict: dict[category] = embedding array (should be normalized and aggregated)\n",
        "        ordered_categories_list: list of all categories in desired order (may include categories not present for this bin)\n",
        "    \n",
        "    Returns:\n",
        "        rdm: numpy array of shape (n_categories, n_categories) with np.nan for missing categories\n",
        "        mask: boolean array of shape (n_categories, n_categories) where True indicates NA (missing category)\n",
        "        available_categories: list of categories actually present for this bin\n",
        "    \"\"\"\n",
        "    n_categories = len(ordered_categories_list)\n",
        "    \n",
        "    # Find available categories (categories that exist for this bin)\n",
        "    available_categories = [cat for cat in ordered_categories_list if cat in bin_embeddings_dict]\n",
        "    \n",
        "    if len(available_categories) < min_categories_per_age_bin:\n",
        "        # Return RDM full of NaN if not enough categories\n",
        "        rdm = np.full((n_categories, n_categories), np.nan)\n",
        "        mask = np.ones((n_categories, n_categories), dtype=bool)\n",
        "        return rdm, mask, available_categories\n",
        "    \n",
        "    # Build embedding matrix for available categories (already normalized)\n",
        "    embedding_matrix = np.array([bin_embeddings_dict[cat].flatten() for cat in available_categories])\n",
        "    \n",
        "    # Ensure 2D shape: (n_available_categories, embedding_dim)\n",
        "    if embedding_matrix.ndim != 2:\n",
        "        raise ValueError(f\"Expected 2D embedding matrix, got shape {embedding_matrix.shape}\")\n",
        "    \n",
        "    # Compute cosine similarity for available categories\n",
        "    similarity_matrix_available = cosine_similarity(embedding_matrix)\n",
        "    \n",
        "    # Convert to distance (RDM) for available categories\n",
        "    distance_matrix_available = 1 - similarity_matrix_available\n",
        "    np.fill_diagonal(distance_matrix_available, 0)  # Ensure diagonal is 0\n",
        "    \n",
        "    # Make symmetric (in case of numerical errors)\n",
        "    distance_matrix_available = (distance_matrix_available + distance_matrix_available.T) / 2\n",
        "    \n",
        "    # Create full RDM with NaN for missing categories\n",
        "    rdm = np.full((n_categories, n_categories), np.nan)\n",
        "    mask = np.ones((n_categories, n_categories), dtype=bool)\n",
        "    \n",
        "    # Map available categories to their indices in ordered_categories_list\n",
        "    available_indices = [ordered_categories_list.index(cat) for cat in available_categories]\n",
        "    \n",
        "    # Fill in the RDM for available categories\n",
        "    for i, idx_i in enumerate(available_indices):\n",
        "        for j, idx_j in enumerate(available_indices):\n",
        "            rdm[idx_i, idx_j] = distance_matrix_available[i, j]\n",
        "            mask[idx_i, idx_j] = False  # False means not NA (data present)\n",
        "    \n",
        "    return rdm, mask, available_categories\n",
        "\n",
        "# Get all unique categories across all subjects and ages\n",
        "all_categories = set()\n",
        "for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
        "    for age_mo, categories in age_data.items():\n",
        "        all_categories.update(categories.keys())\n",
        "\n",
        "all_categories = sorted(list(all_categories))\n",
        "print(f\"\\nTotal unique categories across all subjects and ages: {len(all_categories)}\")\n",
        "print(\"Note: RDMs will be computed with predefined category order after organization step.\")\n",
        "\n",
        "# First, identify which subjects have sufficient data in both bins\n",
        "# We'll compute actual RDMs after category organization\n",
        "print(f\"\\nIdentifying subjects with sufficient data in both age bins...\")\n",
        "subject_age_rdms = {}  # Temporary storage - will be recomputed with predefined order\n",
        "subject_age_rdm_categories = {}  # Temporary storage\n",
        "excluded_subjects = []  # Track excluded subjects and reasons\n",
        "\n",
        "for subject_id, age_data in tqdm(subject_age_embeddings_normalized.items(), desc=\"Checking subjects\"):\n",
        "    # Split ages into younger and older bins\n",
        "    younger_ages = {age_mo: categories for age_mo, categories in age_data.items() \n",
        "                    if age_mo <= overall_median_age}\n",
        "    older_ages = {age_mo: categories for age_mo, categories in age_data.items() \n",
        "                  if age_mo > overall_median_age}\n",
        "    \n",
        "    subject_age_rdms[subject_id] = {}\n",
        "    subject_age_rdm_categories[subject_id] = {}\n",
        "    \n",
        "    # Process younger bin\n",
        "    younger_has_rdm = False\n",
        "    younger_n_cats = 0\n",
        "    if len(younger_ages) > 0:\n",
        "        younger_aggregated = aggregate_embeddings_by_bin(younger_ages, 'younger')\n",
        "        younger_n_cats = len(younger_aggregated)\n",
        "        if younger_n_cats >= min_categories_per_age_bin:\n",
        "            younger_has_rdm = True\n",
        "            subject_age_rdms[subject_id]['younger'] = True  # Placeholder\n",
        "            subject_age_rdm_categories[subject_id]['younger'] = list(younger_aggregated.keys())\n",
        "    else:\n",
        "        excluded_subjects.append({\n",
        "            'subject_id': subject_id,\n",
        "            'reason': 'no younger ages',\n",
        "            'younger_n_cats': 0,\n",
        "            'older_n_cats': len(aggregate_embeddings_by_bin(older_ages, 'older')) if len(older_ages) > 0 else 0\n",
        "        })\n",
        "    \n",
        "    # Process older bin\n",
        "    older_has_rdm = False\n",
        "    older_n_cats = 0\n",
        "    if len(older_ages) > 0:\n",
        "        older_aggregated = aggregate_embeddings_by_bin(older_ages, 'older')\n",
        "        older_n_cats = len(older_aggregated)\n",
        "        if older_n_cats >= min_categories_per_age_bin:\n",
        "            older_has_rdm = True\n",
        "            subject_age_rdms[subject_id]['older'] = True  # Placeholder\n",
        "            subject_age_rdm_categories[subject_id]['older'] = list(older_aggregated.keys())\n",
        "    else:\n",
        "        excluded_subjects.append({\n",
        "            'subject_id': subject_id,\n",
        "            'reason': 'no older ages',\n",
        "            'younger_n_cats': younger_n_cats,\n",
        "            'older_n_cats': 0\n",
        "        })\n",
        "    \n",
        "    # Filter out subjects without both bins\n",
        "    if not younger_has_rdm or not older_has_rdm:\n",
        "        if subject_id not in [s['subject_id'] for s in excluded_subjects]:\n",
        "            # Determine specific reason\n",
        "            if not younger_has_rdm and not older_has_rdm:\n",
        "                reason = 'both bins insufficient'\n",
        "            elif not younger_has_rdm:\n",
        "                reason = f'younger bin insufficient ({younger_n_cats} < {min_categories_per_age_bin} cats)'\n",
        "            else:\n",
        "                reason = f'older bin insufficient ({older_n_cats} < {min_categories_per_age_bin} cats)'\n",
        "            \n",
        "            excluded_subjects.append({\n",
        "                'subject_id': subject_id,\n",
        "                'reason': reason,\n",
        "                'younger_n_cats': younger_n_cats,\n",
        "                'older_n_cats': older_n_cats\n",
        "            })\n",
        "        \n",
        "        del subject_age_rdms[subject_id]\n",
        "        del subject_age_rdm_categories[subject_id]\n",
        "\n",
        "print(f\"\\nIdentified {len(subject_age_rdms)} subjects with sufficient data in both bins\")\n",
        "print(f\"  Excluded {len(excluded_subjects)} subjects without sufficient data in both bins\")\n",
        "\n",
        "# Show excluded subjects details\n",
        "if len(excluded_subjects) > 0:\n",
        "    print(f\"\\nExcluded subjects ({len(excluded_subjects)}):\")\n",
        "    excluded_df = pd.DataFrame(excluded_subjects)\n",
        "    excluded_df = excluded_df.sort_values('subject_id')\n",
        "    for _, row in excluded_df.iterrows():\n",
        "        print(f\"  {row['subject_id']}: {row['reason']} (younger: {row['younger_n_cats']} cats, older: {row['older_n_cats']} cats)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique categories across all subjects and ages: 163\n",
            "\n",
            "Organizing categories...\n",
            "  Loading predefined category order from ../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt...\n",
            "  Loaded 163 categories in predefined order\n",
            "Loading category types from ../../data/cdi_words.csv...\n",
            "Loaded type information for 295 categories\n",
            "\n",
            "Final ordered category list: 163 categories\n"
          ]
        }
      ],
      "source": [
        "# Organize Categories (with Predefined List Option)\n",
        "# This section organizes categories either by loading a predefined category list (for consistent ordering across subjects) or by automatic organization.\n",
        "\n",
        "# Get all unique categories across all subjects and ages (needed for organization)\n",
        "all_categories = set()\n",
        "for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
        "    for age_mo, categories in age_data.items():\n",
        "        all_categories.update(categories.keys())\n",
        "\n",
        "all_categories = sorted(list(all_categories))\n",
        "print(f\"Total unique categories across all subjects and ages: {len(all_categories)}\")\n",
        "\n",
        "# Organize categories: either load predefined list or organize automatically\n",
        "print(\"\\nOrganizing categories...\")\n",
        "\n",
        "if USE_PREDEFINED_CATEGORY_LIST and PREDEFINED_CATEGORY_LIST_PATH is not None:\n",
        "    # Load predefined category list\n",
        "    predefined_path = Path(PREDEFINED_CATEGORY_LIST_PATH)\n",
        "    if not predefined_path.exists():\n",
        "        raise FileNotFoundError(f\"Predefined category list file not found: {predefined_path}\")\n",
        "    \n",
        "    print(f\"  Loading predefined category order from {predefined_path}...\")\n",
        "    with open(predefined_path, 'r') as f:\n",
        "        # Skip comment lines (lines starting with #)\n",
        "        ordered_categories = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]\n",
        "    \n",
        "    # Verify that all categories in predefined list exist in our data\n",
        "    predefined_set = set(ordered_categories)\n",
        "    all_categories_set = set(all_categories)\n",
        "    \n",
        "    if predefined_set != all_categories_set:\n",
        "        missing_in_predefined = all_categories_set - predefined_set\n",
        "        extra_in_predefined = predefined_set - all_categories_set\n",
        "        if missing_in_predefined:\n",
        "            print(f\"  Warning: {len(missing_in_predefined)} categories in data but not in predefined list: {sorted(missing_in_predefined)[:5]}...\")\n",
        "        if extra_in_predefined:\n",
        "            print(f\"  Warning: {len(extra_in_predefined)} categories in predefined list but not in data: {sorted(extra_in_predefined)[:5]}...\")\n",
        "        # Use intersection: only categories that exist in both\n",
        "        ordered_categories = [cat for cat in ordered_categories if cat in all_categories_set]\n",
        "        print(f\"  Using intersection: {len(ordered_categories)} categories\")\n",
        "    \n",
        "    print(f\"  Loaded {len(ordered_categories)} categories in predefined order\")\n",
        "    \n",
        "    # Still organize into groups for visualization boundaries (even though order is predefined)\n",
        "    # Load category types for grouping\n",
        "    if cdi_path.exists():\n",
        "        category_types = load_category_types(cdi_path)\n",
        "    else:\n",
        "        print(f\"Warning: CDI path {cdi_path} not found. Cannot compute group boundaries.\")\n",
        "        category_types = {}\n",
        "    \n",
        "    # Organize predefined categories into groups for visualization boundaries\n",
        "    organized = {\n",
        "        'animals': [],\n",
        "        'bodyparts': [],\n",
        "        'big_objects': [],\n",
        "        'small_objects': [],\n",
        "        'others': []\n",
        "    }\n",
        "    \n",
        "    for cat in ordered_categories:\n",
        "        if cat not in category_types:\n",
        "            organized['others'].append(cat)\n",
        "            continue\n",
        "        \n",
        "        types = category_types[cat]\n",
        "        if types['is_animate']:\n",
        "            organized['animals'].append(cat)\n",
        "        elif types['is_bodypart']:\n",
        "            organized['bodyparts'].append(cat)\n",
        "        elif types['is_big']:\n",
        "            organized['big_objects'].append(cat)\n",
        "        elif types['is_small']:\n",
        "            organized['small_objects'].append(cat)\n",
        "        else:\n",
        "            organized['others'].append(cat)\n",
        "    \n",
        "else:\n",
        "    # Automatic organization by type (similar to notebook 02)\n",
        "    print(f\"  Organizing categories by type...\")\n",
        "    \n",
        "    # Load category types for organization\n",
        "    if cdi_path.exists():\n",
        "        category_types = load_category_types(cdi_path)\n",
        "    else:\n",
        "        print(f\"Warning: CDI path {cdi_path} not found. Skipping category organization.\")\n",
        "        category_types = {}\n",
        "    \n",
        "    # Get a representative set of embeddings for clustering (average across all subjects and ages)\n",
        "    representative_embeddings = {}\n",
        "    for cat in all_categories:\n",
        "        cat_embeddings = []\n",
        "        for subject_id, age_data in subject_age_embeddings_normalized.items():\n",
        "            for age_mo, categories in age_data.items():\n",
        "                if cat in categories:\n",
        "                    cat_embeddings.append(categories[cat])\n",
        "        if len(cat_embeddings) > 0:\n",
        "            # Average across all subjects and ages for this category\n",
        "            representative_embeddings[cat] = np.mean(cat_embeddings, axis=0)\n",
        "    \n",
        "    # Organize by type\n",
        "    organized = {\n",
        "        'animals': [],\n",
        "        'bodyparts': [],\n",
        "        'big_objects': [],\n",
        "        'small_objects': [],\n",
        "        'others': []\n",
        "    }\n",
        "    \n",
        "    for cat in all_categories:\n",
        "        if cat not in category_types:\n",
        "            organized['others'].append(cat)\n",
        "            continue\n",
        "        \n",
        "        types = category_types[cat]\n",
        "        if types['is_animate']:\n",
        "            organized['animals'].append(cat)\n",
        "        elif types['is_bodypart']:\n",
        "            organized['bodyparts'].append(cat)\n",
        "        elif types['is_big']:\n",
        "            organized['big_objects'].append(cat)\n",
        "        elif types['is_small']:\n",
        "            organized['small_objects'].append(cat)\n",
        "        else:\n",
        "            organized['others'].append(cat)\n",
        "    \n",
        "    print(f\"  Organized into: {len(organized['animals'])} animals, {len(organized['bodyparts'])} bodyparts, \"\n",
        "          f\"{len(organized['big_objects'])} big objects, {len(organized['small_objects'])} small objects, \"\n",
        "          f\"{len(organized['others'])} others\")\n",
        "    \n",
        "    # Apply hierarchical clustering if enabled\n",
        "    if use_clustering:\n",
        "        print(f\"  Applying hierarchical clustering within groups...\")\n",
        "        for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "            if len(organized[group_name]) > 1:\n",
        "                # Filter to categories that have representative embeddings\n",
        "                group_cats = [cat for cat in organized[group_name] if cat in representative_embeddings]\n",
        "                if len(group_cats) > 1:\n",
        "                    print(f\"    Clustering {group_name} ({len(group_cats)} categories)...\")\n",
        "                    organized[group_name], _ = cluster_categories_within_group(\n",
        "                        group_cats,\n",
        "                        representative_embeddings,\n",
        "                        save_dendrogram=save_dendrograms,\n",
        "                        output_dir=output_dir,\n",
        "                        group_name=group_name\n",
        "                    )\n",
        "                else:\n",
        "                    organized[group_name] = group_cats\n",
        "            else:\n",
        "                organized[group_name] = [cat for cat in organized[group_name] if cat in representative_embeddings]\n",
        "    else:\n",
        "        for group_name in organized:\n",
        "            organized[group_name] = sorted([cat for cat in organized[group_name] if cat in representative_embeddings])\n",
        "    \n",
        "    # Create ordered list\n",
        "    ordered_categories = (\n",
        "        organized['animals'] +\n",
        "        organized['bodyparts'] +\n",
        "        organized['big_objects'] +\n",
        "        organized['small_objects'] +\n",
        "        organized['others']\n",
        "    )\n",
        "\n",
        "print(f\"\\nFinal ordered category list: {len(ordered_categories)} categories\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "# No age binning needed - we're using median split (younger/older)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Recomputing RDMs with predefined category order (including NaN for missing categories)...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recomputing RDMs: 100%|██████████| 18/18 [00:00<00:00, 57.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recomputed RDMs for 18 subjects using predefined category order\n",
            "  All RDMs now use the same 163-category order with NaN for missing categories\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Recompute RDMs using predefined category order with NaN for missing categories\n",
        "print(\"\\nRecomputing RDMs with predefined category order (including NaN for missing categories)...\")\n",
        "subject_age_rdms_reorganized = {}\n",
        "subject_age_rdm_masks = {}  # Store masks indicating NA cells\n",
        "subject_age_rdm_categories_reorganized = {}\n",
        "subject_age_group_boundaries = {}  # Store group boundaries for visual separators\n",
        "\n",
        "for subject_id in tqdm(subject_age_rdms.keys(), desc=\"Recomputing RDMs\"):\n",
        "    subject_age_rdms_reorganized[subject_id] = {}\n",
        "    subject_age_rdm_masks[subject_id] = {}\n",
        "    subject_age_rdm_categories_reorganized[subject_id] = {}\n",
        "    subject_age_group_boundaries[subject_id] = {}\n",
        "    \n",
        "    # Get original data for this subject\n",
        "    original_rdms = subject_age_rdms[subject_id]\n",
        "    original_categories = subject_age_rdm_categories[subject_id]\n",
        "    \n",
        "    # Recompute each bin's RDM using predefined order\n",
        "    for bin_name in ['younger', 'older']:\n",
        "        if bin_name not in original_rdms:\n",
        "            continue\n",
        "        \n",
        "        # Get aggregated embeddings for this bin\n",
        "        if bin_name == 'younger':\n",
        "            relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                           if age_mo <= overall_median_age}\n",
        "        else:  # older\n",
        "            relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                            if age_mo > overall_median_age}\n",
        "        \n",
        "        # Aggregate embeddings for this bin\n",
        "        bin_embeddings = aggregate_embeddings_by_bin(relevant_ages, bin_name)\n",
        "        \n",
        "        # Compute RDM with NaN for missing categories using predefined order\n",
        "        rdm, mask, available_cats = compute_rdm_for_bin_with_na(bin_embeddings, ordered_categories)\n",
        "        \n",
        "        if rdm is not None:\n",
        "            subject_age_rdms_reorganized[subject_id][bin_name] = rdm\n",
        "            subject_age_rdm_masks[subject_id][bin_name] = mask\n",
        "            subject_age_rdm_categories_reorganized[subject_id][bin_name] = available_cats\n",
        "            \n",
        "            # Compute group boundaries based on full ordered_categories (for visualization)\n",
        "            group_boundaries = []\n",
        "            current_idx = 0\n",
        "            for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "                group_cats = [cat for cat in organized[group_name] if cat in ordered_categories]\n",
        "                if len(group_cats) > 0:\n",
        "                    group_start = current_idx\n",
        "                    group_end = current_idx + len(group_cats)\n",
        "                    group_boundaries.append({\n",
        "                        'name': group_name,\n",
        "                        'start': group_start,\n",
        "                        'end': group_end,\n",
        "                        'categories': group_cats\n",
        "                    })\n",
        "                    current_idx = group_end\n",
        "            \n",
        "            subject_age_group_boundaries[subject_id][bin_name] = group_boundaries\n",
        "\n",
        "# Update the main dictionaries\n",
        "subject_age_rdms = subject_age_rdms_reorganized\n",
        "subject_age_rdm_categories = subject_age_rdm_categories_reorganized\n",
        "\n",
        "print(f\"Recomputed RDMs for {len(subject_age_rdms)} subjects using predefined category order\")\n",
        "print(f\"  All RDMs now use the same {len(ordered_categories)}-category order with NaN for missing categories\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save RDMs for Each Subject (Younger and Older Bins)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving developmental trajectory RDMs...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving RDMs: 100%|██████████| 18/18 [01:27<00:00,  4.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved RDMs to developmental_trajectory_rdms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Save RDMs for each subject (younger and older bins)\n",
        "print(\"Saving developmental trajectory RDMs...\")\n",
        "\n",
        "for subject_id, bin_rdms in tqdm(subject_age_rdms.items(), desc=\"Saving RDMs\"):\n",
        "    subject_output_dir = output_dir / subject_id\n",
        "    subject_output_dir.mkdir(exist_ok=True, parents=True)\n",
        "    \n",
        "    for bin_name, rdm in bin_rdms.items():\n",
        "        available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "        \n",
        "        # Save as numpy array (includes NaN for missing categories)\n",
        "        np.save(subject_output_dir / f\"rdm_{bin_name}.npy\", rdm)\n",
        "        \n",
        "        # Save as CSV with category labels (use ordered_categories for full order)\n",
        "        rdm_df = pd.DataFrame(rdm, index=ordered_categories, columns=ordered_categories)\n",
        "        rdm_df.to_csv(subject_output_dir / f\"rdm_{bin_name}.csv\")\n",
        "        \n",
        "        # Save metadata\n",
        "        # Compute statistics only on valid (non-NaN) values\n",
        "        valid_rdm = rdm[~np.isnan(rdm)]\n",
        "        valid_rdm_positive = valid_rdm[valid_rdm > 0]\n",
        "        \n",
        "        metadata = {\n",
        "            'subject_id': subject_id,\n",
        "            'age_bin': bin_name,\n",
        "            'median_age_threshold': overall_median_age,\n",
        "            'n_categories_total': len(ordered_categories),\n",
        "            'n_categories_available': len(available_cats),\n",
        "            'n_categories_missing': len(ordered_categories) - len(available_cats),\n",
        "            'categories_available': available_cats,\n",
        "            'mean_distance': float(np.nanmean(rdm)),\n",
        "            'std_distance': float(np.nanstd(rdm)),\n",
        "            'min_distance': float(valid_rdm_positive.min()) if len(valid_rdm_positive) > 0 else np.nan,\n",
        "            'max_distance': float(np.nanmax(rdm))\n",
        "        }\n",
        "        \n",
        "        metadata_df = pd.DataFrame([metadata])\n",
        "        metadata_df.to_csv(subject_output_dir / f\"metadata_{bin_name}.csv\", index=False)\n",
        "\n",
        "        # Create and save individual dendrogram for this bin (using available categories only)\n",
        "        if len(available_cats) > 1:\n",
        "            # Get aggregated embeddings for this bin's available categories\n",
        "            # We need to reconstruct from the original normalized embeddings\n",
        "            bin_embeddings = {}\n",
        "            for cat in available_cats:\n",
        "                cat_embeddings = []\n",
        "                # Get all ages in this bin for this subject\n",
        "                if bin_name == 'younger':\n",
        "                    relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                                   if age_mo <= overall_median_age}\n",
        "                else:  # older\n",
        "                    relevant_ages = {age_mo: cats for age_mo, cats in subject_age_embeddings_normalized[subject_id].items() \n",
        "                                    if age_mo > overall_median_age}\n",
        "                \n",
        "                for age_mo, age_cats in relevant_ages.items():\n",
        "                    if cat in age_cats:\n",
        "                        cat_embeddings.append(age_cats[cat])\n",
        "                \n",
        "                if len(cat_embeddings) > 0:\n",
        "                    bin_embeddings[cat] = np.mean(cat_embeddings, axis=0)\n",
        "            \n",
        "            if len(bin_embeddings) > 1:\n",
        "                # Build embedding matrix\n",
        "                embedding_matrix = np.array([bin_embeddings[cat].flatten() for cat in available_cats])\n",
        "                \n",
        "                # Normalize embeddings\n",
        "                normalized_embeddings = (embedding_matrix - embedding_matrix.mean(axis=0)) / (embedding_matrix.std(axis=0) + 1e-10)\n",
        "                \n",
        "                # Compute distance matrix\n",
        "                similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "                distance_matrix = 1 - similarity_matrix\n",
        "                np.fill_diagonal(distance_matrix, 0)\n",
        "                \n",
        "                # Convert to condensed form for linkage\n",
        "                condensed_distances = squareform(distance_matrix)\n",
        "                \n",
        "                # Perform hierarchical clustering\n",
        "                linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "                \n",
        "                # Get optimal leaf ordering\n",
        "                try:\n",
        "                    linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "                except:\n",
        "                    pass\n",
        "                \n",
        "                # Create dendrogram\n",
        "                plt.figure(figsize=(max(16, len(available_cats) * 0.5), 10))\n",
        "                dendrogram(linkage_matrix, \n",
        "                          labels=available_cats,\n",
        "                          leaf_rotation=90,\n",
        "                          leaf_font_size=max(8, min(14, 200 // len(available_cats))))\n",
        "                plt.title(f'Dendrogram: {subject_id} {bin_name.capitalize()} (≤{overall_median_age:.0f}mo vs >{overall_median_age:.0f}mo)\\n({len(available_cats)}/{len(ordered_categories)} categories)',\n",
        "                         fontsize=16, pad=20)\n",
        "                plt.xlabel('Category', fontsize=14)\n",
        "                plt.ylabel('Distance', fontsize=14)\n",
        "                plt.tight_layout()\n",
        "                \n",
        "                # Save dendrogram\n",
        "                dendrogram_dir = subject_output_dir / \"dendrograms\"\n",
        "                dendrogram_dir.mkdir(exist_ok=True, parents=True)\n",
        "                dendrogram_path = dendrogram_dir / f\"dendrogram_{bin_name}.png\"\n",
        "                plt.savefig(dendrogram_path, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "                plt.close()\n",
        "\n",
        "print(f\"\\nSaved RDMs to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Developmental Trajectories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Explanation: RDM Correlation Logic\n",
        "\n",
        "### Overview\n",
        "This section explains in detail how we compute correlations between younger and older RDMs for each subject, including how we handle missing categories (NaN values) and whether correlations are comparable across subjects.\n",
        "\n",
        "### RDM Structure\n",
        "Each subject has two RDMs (younger and older), both with shape (163, 163) corresponding to the full predefined category order:\n",
        "- **Diagonal elements**: Always 0 (distance from category to itself)\n",
        "- **Off-diagonal elements**: Distance values (0-2 range) for category pairs that exist in that age bin\n",
        "- **Missing categories**: Represented as NaN (white cells in visualization)\n",
        "\n",
        "### Step-by-Step Correlation Process\n",
        "\n",
        "#### Step 1: Identify Common Categories\n",
        "- **Input**: Two lists of available categories (`available_cats1` for younger, `available_cats2` for older) and the full `ordered_categories_list` (predefined order)\n",
        "- **Process**: Find categories that are in BOTH available lists, preserving the predefined order (NOT alphabetical)\n",
        "- **Output**: `common_categories` - categories present in BOTH age bins, in predefined order\n",
        "- **Example**: If younger has 150 categories and older has 155 categories, they might share 140 categories\n",
        "- **Key Point**: Order matters! We use the predefined order to ensure submatrices are aligned correctly\n",
        "\n",
        "#### Step 2: Map to Full Category Order\n",
        "- **Input**: `common_categories` and the full `ordered_categories` list (163 categories)\n",
        "- **Process**: Find the indices of common categories in the full ordered list\n",
        "- **Output**: `common_indices` - positions in the 163x163 RDM matrices\n",
        "- **Purpose**: This ensures we extract the correct submatrices from the full RDMs\n",
        "\n",
        "#### Step 3: Extract Submatrices\n",
        "- **Input**: Full 163x163 RDMs and `common_indices`\n",
        "- **Process**: Extract square submatrices using `rdm[np.ix_(common_indices, common_indices)]`\n",
        "- **Output**: Two smaller square matrices (e.g., 140x140 if 140 common categories)\n",
        "- **Key Point**: These submatrices contain ONLY the common categories, but may still have NaN if there are any data issues\n",
        "\n",
        "#### Step 4: Extract Upper Triangle\n",
        "- **Process**: Use a triangular mask to extract only the upper triangle (excluding diagonal)\n",
        "- **Why**: RDMs are symmetric, so we only need half the values to avoid double-counting\n",
        "- **Output**: Two flattened arrays of pairwise distances\n",
        "- **Size**: If n common categories, we get n×(n-1)/2 distance values\n",
        "\n",
        "#### Step 5: Filter NaN Values\n",
        "- **Process**: Create a boolean mask identifying valid (non-NaN) values in BOTH arrays\n",
        "- **Filter**: Keep only pairs where BOTH RDMs have valid values\n",
        "- **Output**: Two arrays of the same length with only valid distance pairs\n",
        "- **Safety Check**: Even though we only use common categories, this ensures no NaN values slip through\n",
        "\n",
        "#### Step 6: Compute Spearman Correlation\n",
        "- **Method**: Spearman rank correlation (non-parametric, robust to outliers)\n",
        "- **Input**: Two arrays of valid distance values (same length, same category pairs)\n",
        "- **Output**: Correlation coefficient (-1 to 1)\n",
        "- **Interpretation**: \n",
        "  - High correlation (>0.7): Similar representational structure across age bins\n",
        "  - Low correlation (<0.5): Representational structure changed with development\n",
        "  - Near 0: No relationship between structures\n",
        "\n",
        "### Handling NaN Values\n",
        "\n",
        "**Where NaN values come from:**\n",
        "1. Categories not present in a particular age bin (expected)\n",
        "2. Categories present but with insufficient data (rare, but possible)\n",
        "\n",
        "**How we handle them:**\n",
        "1. **Pre-filtering**: We only use categories present in BOTH bins (common categories)\n",
        "2. **Submatrix extraction**: We extract only the common category submatrices\n",
        "3. **Post-filtering**: We filter out any remaining NaN values before correlation\n",
        "4. **Result**: The correlation is computed only on valid distance pairs\n",
        "\n",
        "**Why this works:**\n",
        "- By using only common categories, we ensure we're comparing the same category pairs\n",
        "- The correlation reflects how similarly those common categories are organized in younger vs older periods\n",
        "- Missing categories don't affect the correlation (they're simply excluded)\n",
        "\n",
        "### Comparability Across Subjects\n",
        "\n",
        "**Are correlations comparable across subjects?**\n",
        "\n",
        "**YES, with important caveats:**\n",
        "\n",
        "1. **Same correlation metric**: All subjects use Spearman correlation on the same type of data (distance matrices)\n",
        "\n",
        "2. **Different category sets**: Each subject may have different numbers of common categories:\n",
        "   - Subject A: 140 common categories → 9,730 distance pairs\n",
        "   - Subject B: 150 common categories → 11,175 distance pairs\n",
        "   - Subject C: 130 common categories → 8,385 distance pairs\n",
        "\n",
        "3. **Interpretation considerations**:\n",
        "   - **Absolute correlation values ARE comparable**: A correlation of 0.8 means the same thing for all subjects (strong similarity between age bins)\n",
        "   - **Statistical power varies**: Subjects with more common categories have more data points, so their correlations may be more reliable\n",
        "   - **Missing categories don't bias**: As long as we use only common categories, missing categories don't affect the correlation value\n",
        "\n",
        "4. **What makes correlations comparable**:\n",
        "   - Same age split (median = 16 months for all)\n",
        "   - Same normalization (within-subject z-score normalization)\n",
        "   - Same distance metric (cosine distance)\n",
        "   - Same correlation method (Spearman)\n",
        "   - Only common categories used (fair comparison)\n",
        "\n",
        "5. **What to consider when comparing**:\n",
        "   - **Number of common categories**: Tracked in `n_common_categories` - more categories = more reliable\n",
        "   - **Category composition**: Different subjects may have different sets of common categories\n",
        "   - **Data density**: Subjects with more data in both bins may have more stable RDMs\n",
        "\n",
        "### Example Walkthrough\n",
        "\n",
        "**Subject 00240001:**\n",
        "- Younger bin: 155 categories available\n",
        "- Older bin: 160 categories available\n",
        "- Common categories: 150 categories\n",
        "- Extracted submatrices: 150×150 (22,500 cells)\n",
        "- Upper triangle: 11,175 distance pairs\n",
        "- After NaN filtering: 11,175 valid pairs (assuming all common categories have data)\n",
        "- Spearman correlation: 0.756\n",
        "- **Interpretation**: Strong similarity (0.756) between younger and older representational structures, based on 150 common categories\n",
        "\n",
        "**Subject 00320001:**\n",
        "- Younger bin: 140 categories available\n",
        "- Older bin: 145 categories available\n",
        "- Common categories: 135 categories\n",
        "- Extracted submatrices: 135×135 (18,225 cells)\n",
        "- Upper triangle: 9,045 distance pairs\n",
        "- After NaN filtering: 9,045 valid pairs\n",
        "- Spearman correlation: 0.682\n",
        "- **Interpretation**: Moderate similarity (0.682) between age bins, based on 135 common categories\n",
        "\n",
        "**Comparison**: Subject 00240001 has a higher correlation (0.756 vs 0.682), suggesting more stable representational structure across development. However, we should also consider that Subject 00240001 has more common categories (150 vs 135), which provides more data for the correlation.\n",
        "\n",
        "### Summary\n",
        "\n",
        "The correlation logic:\n",
        "1. ✅ Uses only categories present in BOTH age bins (fair comparison)\n",
        "2. ✅ Filters out all NaN values before correlation\n",
        "3. ✅ Uses Spearman correlation (robust, non-parametric)\n",
        "4. ✅ Produces comparable values across subjects\n",
        "5. ⚠️ But correlations should be interpreted with awareness of the number of common categories\n",
        "\n",
        "**Key insight**: The correlation tells us how similarly categories are organized in younger vs older periods, but only for the categories that exist in both periods. This is appropriate for developmental trajectory analysis because we want to know: \"For the categories this child experienced at both ages, how stable was their representational structure?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "DEMONSTRATION: RDM Correlation Logic with NaN Values\n",
            "======================================================================\n",
            "\n",
            "1. SETUP: Full category order (5 categories)\n",
            "   Ordered categories: ['cat1', 'cat2', 'cat3', 'cat4', 'cat5']\n",
            "\n",
            "2. EXAMPLE SUBJECT:\n",
            "   Younger bin has: cat1, cat2, cat3, cat4 (4 categories)\n",
            "   Older bin has:   cat2, cat3, cat4, cat5 (4 categories)\n",
            "\n",
            "3. COMMON CATEGORIES:\n",
            "   Common categories: ['cat2', 'cat3', 'cat4'] (3 categories)\n",
            "   Note: cat1 only in younger, cat5 only in older - these are excluded\n",
            "   IMPORTANT: Categories are in predefined order, not alphabetical!\n",
            "\n",
            "4. RDM STRUCTURE:\n",
            "   Full RDMs are 5×5 (one row/column per category in ordered_cats)\n",
            "   Missing categories have NaN in their rows/columns\n",
            "\n",
            "   Younger RDM structure:\n",
            "     cat1   cat2   cat3   cat4   cat5\n",
            "     cat1:   data\n",
            "     cat2:   data\n",
            "     cat3:   data\n",
            "     cat4:   data\n",
            "     cat5:    NaN\n",
            "\n",
            "5. SUBMATRIX EXTRACTION:\n",
            "   Common category indices in full RDM: [1, 2, 3]\n",
            "   Extract 3×3 submatrix using these indices\n",
            "   This gives us only the common categories: ['cat2', 'cat3', 'cat4']\n",
            "\n",
            "6. UPPER TRIANGLE:\n",
            "   For 3 categories, we get 3 unique pairs\n",
            "   (excluding diagonal: 3 self-pairs)\n",
            "   Example pairs: (cat2-cat3), (cat2-cat4), (cat3-cat4)\n",
            "\n",
            "7. CORRELATION:\n",
            "   - Extract distance values for these pairs from both RDMs\n",
            "   - Filter out any NaN values (shouldn't be any for common categories)\n",
            "   - Compute Spearman correlation on the paired distance values\n",
            "   - Result: Single correlation coefficient (-1 to 1)\n",
            "\n",
            "8. WHY THIS WORKS:\n",
            "   ✓ Only uses categories present in BOTH bins (fair comparison)\n",
            "   ✓ Same category pairs compared in both RDMs\n",
            "   ✓ NaN values are excluded (don't affect correlation)\n",
            "   ✓ Correlation reflects structural similarity, not data availability\n",
            "\n",
            "======================================================================\n",
            "For actual subjects, this process uses 163 categories\n",
            "Common categories typically range from 130-160 per subject\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Demonstration: How RDM Correlation Works with NaN Values\n",
        "# This cell demonstrates the correlation logic with a simple example\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DEMONSTRATION: RDM Correlation Logic with NaN Values\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Example: Simple 5-category case\n",
        "print(\"\\n1. SETUP: Full category order (5 categories)\")\n",
        "ordered_cats = ['cat1', 'cat2', 'cat3', 'cat4', 'cat5']\n",
        "print(f\"   Ordered categories: {ordered_cats}\")\n",
        "\n",
        "print(\"\\n2. EXAMPLE SUBJECT:\")\n",
        "print(\"   Younger bin has: cat1, cat2, cat3, cat4 (4 categories)\")\n",
        "print(\"   Older bin has:   cat2, cat3, cat4, cat5 (4 categories)\")\n",
        "available_younger = ['cat1', 'cat2', 'cat3', 'cat4']\n",
        "available_older = ['cat2', 'cat3', 'cat4', 'cat5']\n",
        "\n",
        "print(\"\\n3. COMMON CATEGORIES:\")\n",
        "# Preserve predefined order, not alphabetical\n",
        "common = [cat for cat in ordered_cats if cat in available_younger and cat in available_older]\n",
        "print(f\"   Common categories: {common} ({len(common)} categories)\")\n",
        "print(\"   Note: cat1 only in younger, cat5 only in older - these are excluded\")\n",
        "print(\"   IMPORTANT: Categories are in predefined order, not alphabetical!\")\n",
        "\n",
        "print(\"\\n4. RDM STRUCTURE:\")\n",
        "print(\"   Full RDMs are 5×5 (one row/column per category in ordered_cats)\")\n",
        "print(\"   Missing categories have NaN in their rows/columns\")\n",
        "print(\"\\n   Younger RDM structure:\")\n",
        "print(\"   \" + \" \".join([f\"{c:>6}\" for c in ordered_cats]))\n",
        "for i, cat in enumerate(ordered_cats):\n",
        "    if cat in available_younger:\n",
        "        status = \"  data\"\n",
        "    else:\n",
        "        status = \"   NaN\"\n",
        "    print(f\"   {cat:>6}: {status}\")\n",
        "\n",
        "print(\"\\n5. SUBMATRIX EXTRACTION:\")\n",
        "common_indices = [ordered_cats.index(c) for c in common]\n",
        "print(f\"   Common category indices in full RDM: {common_indices}\")\n",
        "print(f\"   Extract 3×3 submatrix using these indices\")\n",
        "print(f\"   This gives us only the common categories: {common}\")\n",
        "\n",
        "print(\"\\n6. UPPER TRIANGLE:\")\n",
        "n_common = len(common)\n",
        "n_pairs = n_common * (n_common - 1) // 2\n",
        "print(f\"   For {n_common} categories, we get {n_pairs} unique pairs\")\n",
        "print(f\"   (excluding diagonal: {n_common} self-pairs)\")\n",
        "print(f\"   Example pairs: (cat2-cat3), (cat2-cat4), (cat3-cat4)\")\n",
        "\n",
        "print(\"\\n7. CORRELATION:\")\n",
        "print(\"   - Extract distance values for these pairs from both RDMs\")\n",
        "print(\"   - Filter out any NaN values (shouldn't be any for common categories)\")\n",
        "print(\"   - Compute Spearman correlation on the paired distance values\")\n",
        "print(\"   - Result: Single correlation coefficient (-1 to 1)\")\n",
        "\n",
        "print(\"\\n8. WHY THIS WORKS:\")\n",
        "print(\"   ✓ Only uses categories present in BOTH bins (fair comparison)\")\n",
        "print(\"   ✓ Same category pairs compared in both RDMs\")\n",
        "print(\"   ✓ NaN values are excluded (don't affect correlation)\")\n",
        "print(\"   ✓ Correlation reflects structural similarity, not data availability\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"For actual subjects, this process uses 163 categories\")\n",
        "print(\"Common categories typically range from 130-160 per subject\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing trajectories: 100%|██████████| 18/18 [00:00<00:00, 384.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trajectory analysis:\n",
            "  Total subjects analyzed: 18\n",
            "  Mean RDM correlation (younger vs older): 0.771\n",
            "  Std RDM correlation: 0.080\n",
            "  Median age threshold: 16.0 months\n",
            "\n",
            "Saved trajectory correlations to developmental_trajectory_rdms/trajectory_correlations.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def compute_rdm_correlation(rdm1, rdm2, ordered_categories_list, available_cats1, available_cats2):\n",
        "    \"\"\"\n",
        "    Compute correlation between two RDMs that use the full ordered_categories list with NaN for missing categories.\n",
        "    Only uses categories present in both RDMs (non-NaN in both).\n",
        "    \n",
        "    Args:\n",
        "        rdm1: numpy array of shape (n_categories, n_categories) with NaN for missing categories\n",
        "        rdm2: numpy array of shape (n_categories, n_categories) with NaN for missing categories\n",
        "        ordered_categories_list: full list of categories in order (used for indexing)\n",
        "        available_cats1: list of categories actually present in rdm1\n",
        "        available_cats2: list of categories actually present in rdm2\n",
        "    \n",
        "    Returns:\n",
        "        corr: correlation coefficient (or np.nan if insufficient data)\n",
        "        n_common: number of common categories\n",
        "    \"\"\"\n",
        "    # Find common categories (categories present in both RDMs)\n",
        "    # IMPORTANT: Preserve predefined order from ordered_categories_list, NOT alphabetical order\n",
        "    # This ensures submatrices are extracted in the same order for both RDMs\n",
        "    # and maintains consistency with visualizations which use the predefined order\n",
        "    common_categories = [cat for cat in ordered_categories_list \n",
        "                        if cat in available_cats1 and cat in available_cats2]\n",
        "    \n",
        "    if len(common_categories) < 2:\n",
        "        return np.nan, len(common_categories)\n",
        "    \n",
        "    # Get indices for common categories in the ordered_categories_list\n",
        "    common_indices = [ordered_categories_list.index(cat) for cat in common_categories]\n",
        "    \n",
        "    # Extract submatrices for common categories\n",
        "    rdm1_subset = rdm1[np.ix_(common_indices, common_indices)]\n",
        "    rdm2_subset = rdm2[np.ix_(common_indices, common_indices)]\n",
        "    \n",
        "    # Get upper triangle (excluding diagonal) for both RDMs\n",
        "    mask = np.triu(np.ones_like(rdm1_subset, dtype=bool), k=1)\n",
        "    rdm1_flat = rdm1_subset[mask]\n",
        "    rdm2_flat = rdm2_subset[mask]\n",
        "    \n",
        "    # Filter out NaN values (shouldn't be any if categories are truly common, but check anyway)\n",
        "    valid_mask = ~(np.isnan(rdm1_flat) | np.isnan(rdm2_flat))\n",
        "    rdm1_valid = rdm1_flat[valid_mask]\n",
        "    rdm2_valid = rdm2_flat[valid_mask]\n",
        "    \n",
        "    # Compute Spearman correlation (more robust to outliers)\n",
        "    if len(rdm1_valid) > 0:\n",
        "        corr, _ = spearmanr(rdm1_valid, rdm2_valid)\n",
        "        return corr, len(common_categories)\n",
        "    else:\n",
        "        return np.nan, len(common_categories)\n",
        "\n",
        "# Compute RDM correlations between younger and older bins for each subject\n",
        "trajectory_data = []\n",
        "\n",
        "for subject_id, bin_rdms in tqdm(subject_age_rdms.items(), desc=\"Analyzing trajectories\"):\n",
        "    if 'younger' not in bin_rdms or 'older' not in bin_rdms:\n",
        "        continue\n",
        "    \n",
        "    rdm_younger = bin_rdms['younger']\n",
        "    rdm_older = bin_rdms['older']\n",
        "    cats_younger = subject_age_rdm_categories[subject_id]['younger']\n",
        "    cats_older = subject_age_rdm_categories[subject_id]['older']\n",
        "    \n",
        "    # Use ordered_categories as reference and available categories for filtering\n",
        "    corr, n_common = compute_rdm_correlation(\n",
        "        rdm_younger, rdm_older, \n",
        "        ordered_categories,  # Full ordered list for indexing\n",
        "        cats_younger,  # Available categories in younger bin\n",
        "        cats_older     # Available categories in older bin\n",
        "    )\n",
        "    \n",
        "    trajectory_data.append({\n",
        "        'subject_id': subject_id,\n",
        "        'age_bin_1': 'younger',\n",
        "        'age_bin_2': 'older',\n",
        "        'median_age_threshold': overall_median_age,\n",
        "        'rdm_correlation': corr,\n",
        "        'n_common_categories': n_common,\n",
        "        'n_categories_younger': len(cats_younger),\n",
        "        'n_categories_older': len(cats_older)\n",
        "    })\n",
        "\n",
        "trajectory_df = pd.DataFrame(trajectory_data)\n",
        "trajectory_df.to_csv(output_dir / \"trajectory_correlations.csv\", index=False)\n",
        "\n",
        "print(f\"\\nTrajectory analysis:\")\n",
        "print(f\"  Total subjects analyzed: {len(trajectory_df)}\")\n",
        "print(f\"  Mean RDM correlation (younger vs older): {trajectory_df['rdm_correlation'].mean():.3f}\")\n",
        "print(f\"  Std RDM correlation: {trajectory_df['rdm_correlation'].std():.3f}\")\n",
        "print(f\"  Median age threshold: {overall_median_age:.1f} months\")\n",
        "print(f\"\\nSaved trajectory correlations to {output_dir / 'trajectory_correlations.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Category-Based Correlations\n",
        "\n",
        "Compute correlations between younger and older RDMs separately for each broad semantic category group (animals, bodyparts, big_objects, small_objects, others). This allows us to examine whether developmental stability varies across different semantic domains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing category-based correlations...\n",
            "Category group sizes: [('animals', 19), ('bodyparts', 14), ('big_objects', 32), ('small_objects', 96), ('others', 2)]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category correlations: 100%|██████████| 18/18 [00:00<00:00, 414.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Category-based correlation analysis:\n",
            "  Total subject-group combinations: 90\n",
            "\n",
            "Mean correlations by category group:\n",
            "  animals        : 0.522 (n=18 valid, 18 total)\n",
            "  bodyparts      : 0.847 (n=18 valid, 18 total)\n",
            "  big_objects    : 0.752 (n=18 valid, 18 total)\n",
            "  small_objects  : 0.775 (n=18 valid, 18 total)\n",
            "  others         : No valid correlations (n=18 total)\n",
            "\n",
            "Saved category group correlations to developmental_trajectory_rdms/category_group_correlations.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute category-based correlations for each semantic group\n",
        "category_correlation_data = []\n",
        "\n",
        "# Get category groups from organized structure\n",
        "category_groups = {\n",
        "    'animals': organized['animals'],\n",
        "    'bodyparts': organized['bodyparts'],\n",
        "    'big_objects': organized['big_objects'],\n",
        "    'small_objects': organized['small_objects'],\n",
        "    'others': organized['others']\n",
        "}\n",
        "\n",
        "print(\"Computing category-based correlations...\")\n",
        "print(f\"Category group sizes: {[(name, len(cats)) for name, cats in category_groups.items()]}\")\n",
        "\n",
        "for subject_id, bin_rdms in tqdm(subject_age_rdms.items(), desc=\"Category correlations\"):\n",
        "    if 'younger' not in bin_rdms or 'older' not in bin_rdms:\n",
        "        continue\n",
        "    \n",
        "    rdm_younger = bin_rdms['younger']\n",
        "    rdm_older = bin_rdms['older']\n",
        "    cats_younger = subject_age_rdm_categories[subject_id]['younger']\n",
        "    cats_older = subject_age_rdm_categories[subject_id]['older']\n",
        "    \n",
        "    # Compute correlation for each category group\n",
        "    for group_name, group_categories in category_groups.items():\n",
        "        # Find common categories in this group that are present in both age bins\n",
        "        common_in_group = [cat for cat in group_categories \n",
        "                          if cat in cats_younger and cat in ordered_categories and cat in cats_older]\n",
        "        \n",
        "        if len(common_in_group) < 2:\n",
        "            # Not enough categories in this group for correlation\n",
        "            category_correlation_data.append({\n",
        "                'subject_id': subject_id,\n",
        "                'category_group': group_name,\n",
        "                'n_common_categories': len(common_in_group),\n",
        "                'correlation': np.nan,\n",
        "                'n_categories_younger': len([c for c in group_categories if c in cats_younger]),\n",
        "                'n_categories_older': len([c for c in group_categories if c in cats_older])\n",
        "            })\n",
        "            continue\n",
        "        \n",
        "        # Get indices for common categories in this group\n",
        "        common_indices = [ordered_categories.index(cat) for cat in common_in_group]\n",
        "        \n",
        "        # Extract submatrices for this group\n",
        "        rdm_younger_group = rdm_younger[np.ix_(common_indices, common_indices)]\n",
        "        rdm_older_group = rdm_older[np.ix_(common_indices, common_indices)]\n",
        "        \n",
        "        # Get upper triangle (excluding diagonal)\n",
        "        mask = np.triu(np.ones_like(rdm_younger_group, dtype=bool), k=1)\n",
        "        rdm_younger_flat = rdm_younger_group[mask]\n",
        "        rdm_older_flat = rdm_older_group[mask]\n",
        "        \n",
        "        # Filter out NaN values\n",
        "        valid_mask = ~(np.isnan(rdm_younger_flat) | np.isnan(rdm_older_flat))\n",
        "        rdm_younger_valid = rdm_younger_flat[valid_mask]\n",
        "        rdm_older_valid = rdm_older_flat[valid_mask]\n",
        "        \n",
        "        # Compute Spearman correlation\n",
        "        if len(rdm_younger_valid) > 0:\n",
        "            corr, _ = spearmanr(rdm_younger_valid, rdm_older_valid)\n",
        "        else:\n",
        "            corr = np.nan\n",
        "        \n",
        "        category_correlation_data.append({\n",
        "            'subject_id': subject_id,\n",
        "            'category_group': group_name,\n",
        "            'n_common_categories': len(common_in_group),\n",
        "            'correlation': corr,\n",
        "            'n_categories_younger': len([c for c in group_categories if c in cats_younger]),\n",
        "            'n_categories_older': len([c for c in group_categories if c in cats_older])\n",
        "        })\n",
        "\n",
        "category_corr_df = pd.DataFrame(category_correlation_data)\n",
        "category_corr_df.to_csv(output_dir / \"category_group_correlations.csv\", index=False)\n",
        "\n",
        "print(f\"\\nCategory-based correlation analysis:\")\n",
        "print(f\"  Total subject-group combinations: {len(category_corr_df)}\")\n",
        "print(f\"\\nMean correlations by category group:\")\n",
        "for group_name in category_groups.keys():\n",
        "    group_data = category_corr_df[category_corr_df['category_group'] == group_name]\n",
        "    valid_corrs = group_data['correlation'].dropna()\n",
        "    if len(valid_corrs) > 0:\n",
        "        print(f\"  {group_name:15s}: {valid_corrs.mean():.3f} (n={len(valid_corrs)} valid, {len(group_data)} total)\")\n",
        "    else:\n",
        "        print(f\"  {group_name:15s}: No valid correlations (n={len(group_data)} total)\")\n",
        "\n",
        "print(f\"\\nSaved category group correlations to {output_dir / 'category_group_correlations.csv'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Category-Based Correlations\n",
        "\n",
        "Create visualizations to examine how developmental stability (correlation between younger and older RDMs) varies across different semantic category groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize category-based correlations\n",
        "print(\"Creating visualizations for category-based correlations...\")\n",
        "\n",
        "# Filter out NaN correlations for plotting\n",
        "valid_category_corr_df = category_corr_df[category_corr_df['correlation'].notna()].copy()\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "# 1. Box plot comparing correlations across category groups\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "category_order = ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']\n",
        "box_data = [valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation'].values \n",
        "            for group in category_order if group in valid_category_corr_df['category_group'].values]\n",
        "\n",
        "# Filter out empty groups\n",
        "box_data_filtered = []\n",
        "labels_filtered = []\n",
        "for i, group in enumerate(category_order):\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation'].values\n",
        "    if len(group_data) > 0:\n",
        "        box_data_filtered.append(group_data)\n",
        "        labels_filtered.append(group.replace('_', ' ').title())\n",
        "\n",
        "bp = ax1.boxplot(box_data_filtered, labels=labels_filtered, patch_artist=True)\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
        "for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax1.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax1.set_title('Distribution of Correlations by Category Group', fontsize=13, pad=10)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.set_ylim([0, 1])\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# 2. Bar plot of mean correlations by group\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "mean_corrs = []\n",
        "std_corrs = []\n",
        "group_labels = []\n",
        "for group in category_order:\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation']\n",
        "    if len(group_data) > 0:\n",
        "        mean_corrs.append(group_data.mean())\n",
        "        std_corrs.append(group_data.std())\n",
        "        group_labels.append(group.replace('_', ' ').title())\n",
        "\n",
        "bars = ax2.bar(range(len(group_labels)), mean_corrs, yerr=std_corrs, \n",
        "               color=colors[:len(group_labels)], alpha=0.7, capsize=5, edgecolor='black')\n",
        "ax2.set_xticks(range(len(group_labels)))\n",
        "ax2.set_xticklabels(group_labels, rotation=45, ha='right')\n",
        "ax2.set_ylabel('Mean RDM Correlation', fontsize=12)\n",
        "ax2.set_title('Mean Correlations by Category Group', fontsize=13, pad=10)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.set_ylim([0, 1])\n",
        "ax2.axhline(y=valid_category_corr_df['correlation'].mean(), color='red', \n",
        "           linestyle='--', linewidth=2, label=f'Overall mean: {valid_category_corr_df[\"correlation\"].mean():.3f}')\n",
        "ax2.legend()\n",
        "\n",
        "# 3. Heatmap: subjects x category groups\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "pivot_data = valid_category_corr_df.pivot(index='subject_id', columns='category_group', values='correlation')\n",
        "# Reorder columns\n",
        "pivot_data = pivot_data[[col for col in category_order if col in pivot_data.columns]]\n",
        "# Sort subjects by overall correlation (average across groups)\n",
        "pivot_data['mean_corr'] = pivot_data.mean(axis=1)\n",
        "pivot_data = pivot_data.sort_values('mean_corr', ascending=False)\n",
        "pivot_data = pivot_data.drop('mean_corr', axis=1)\n",
        "\n",
        "im = ax3.imshow(pivot_data.values, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "ax3.set_xticks(range(len(pivot_data.columns)))\n",
        "ax3.set_xticklabels([col.replace('_', ' ').title() for col in pivot_data.columns], \n",
        "                    rotation=45, ha='right')\n",
        "ax3.set_yticks(range(len(pivot_data.index)))\n",
        "ax3.set_yticklabels(pivot_data.index, fontsize=8)\n",
        "ax3.set_title('Correlation Heatmap: Subjects × Category Groups', fontsize=13, pad=10)\n",
        "plt.colorbar(im, ax=ax3, label='RDM Correlation')\n",
        "\n",
        "# 4. Violin plot for better distribution visualization\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "violin_data = []\n",
        "violin_labels = []\n",
        "for group in category_order:\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]['correlation'].values\n",
        "    if len(group_data) > 0:\n",
        "        violin_data.append(group_data)\n",
        "        violin_labels.append(group.replace('_', ' ').title())\n",
        "\n",
        "parts = ax4.violinplot(violin_data, positions=range(len(violin_labels)), showmeans=True, showmedians=True)\n",
        "for i, pc in enumerate(parts['bodies']):\n",
        "    pc.set_facecolor(colors[i % len(colors)])\n",
        "    pc.set_alpha(0.7)\n",
        "ax4.set_xticks(range(len(violin_labels)))\n",
        "ax4.set_xticklabels(violin_labels, rotation=45, ha='right')\n",
        "ax4.set_ylabel('RDM Correlation (Spearman)', fontsize=12)\n",
        "ax4.set_title('Distribution of Correlations (Violin Plot)', fontsize=13, pad=10)\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "ax4.set_ylim([0, 1])\n",
        "\n",
        "# 5. Scatter plot: correlation vs number of common categories\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "for group in category_order:\n",
        "    group_data = valid_category_corr_df[valid_category_corr_df['category_group'] == group]\n",
        "    if len(group_data) > 0:\n",
        "        ax5.scatter(group_data['n_common_categories'], group_data['correlation'], \n",
        "                   label=group.replace('_', ' ').title(), alpha=0.6, s=60)\n",
        "\n",
        "ax5.set_xlabel('Number of Common Categories', fontsize=12)\n",
        "ax5.set_ylabel('RDM Correlation', fontsize=12)\n",
        "ax5.set_title('Correlation vs Category Count', fontsize=13, pad=10)\n",
        "ax5.legend(loc='best', fontsize=9)\n",
        "ax5.grid(True, alpha=0.3)\n",
        "ax5.set_ylim([0, 1])\n",
        "\n",
        "# 6. Individual subject trajectories (bar plot for each subject)\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "# Get top 10 subjects by overall correlation for cleaner visualization\n",
        "subject_means = valid_category_corr_df.groupby('subject_id')['correlation'].mean().sort_values(ascending=False)\n",
        "top_subjects = subject_means.head(10).index\n",
        "\n",
        "x_pos = np.arange(len(top_subjects))\n",
        "width = 0.15\n",
        "for i, group in enumerate(category_order):\n",
        "    if group in valid_category_corr_df['category_group'].values:\n",
        "        group_corrs = []\n",
        "        for subj in top_subjects:\n",
        "            subj_group_data = valid_category_corr_df[\n",
        "                (valid_category_corr_df['subject_id'] == subj) & \n",
        "                (valid_category_corr_df['category_group'] == group)\n",
        "            ]\n",
        "            if len(subj_group_data) > 0:\n",
        "                group_corrs.append(subj_group_data['correlation'].values[0])\n",
        "            else:\n",
        "                group_corrs.append(np.nan)\n",
        "        \n",
        "        # Only plot if we have data\n",
        "        if not all(np.isnan(group_corrs)):\n",
        "            ax6.bar(x_pos + i*width, group_corrs, width, \n",
        "                   label=group.replace('_', ' ').title(), alpha=0.7, color=colors[i % len(colors)])\n",
        "\n",
        "ax6.set_xlabel('Subject ID', fontsize=12)\n",
        "ax6.set_ylabel('RDM Correlation', fontsize=12)\n",
        "ax6.set_title('Top 10 Subjects: Correlations by Category Group', fontsize=13, pad=10)\n",
        "ax6.set_xticks(x_pos + width * 2)\n",
        "ax6.set_xticklabels(top_subjects, rotation=45, ha='right', fontsize=8)\n",
        "ax6.legend(loc='upper left', fontsize=8, ncol=2)\n",
        "ax6.grid(True, alpha=0.3, axis='y')\n",
        "ax6.set_ylim([0, 1])\n",
        "\n",
        "plt.suptitle('Category-Based RDM Correlations: Younger vs Older Age Bins', \n",
        "             fontsize=16, y=0.995, fontweight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"category_group_correlations_visualization.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved category correlation visualization to {output_dir / 'category_group_correlations_visualization.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Create a separate detailed heatmap with all subjects\n",
        "fig, ax = plt.subplots(figsize=(10, 14))\n",
        "pivot_data_all = valid_category_corr_df.pivot(index='subject_id', columns='category_group', values='correlation')\n",
        "pivot_data_all = pivot_data_all[[col for col in category_order if col in pivot_data_all.columns]]\n",
        "# Sort by overall mean correlation\n",
        "pivot_data_all['mean_corr'] = pivot_data_all.mean(axis=1)\n",
        "pivot_data_all = pivot_data_all.sort_values('mean_corr', ascending=False)\n",
        "pivot_data_all = pivot_data_all.drop('mean_corr', axis=1)\n",
        "\n",
        "im = ax.imshow(pivot_data_all.values, aspect='auto', cmap='RdYlBu_r', vmin=0, vmax=1)\n",
        "ax.set_xticks(range(len(pivot_data_all.columns)))\n",
        "ax.set_xticklabels([col.replace('_', ' ').title() for col in pivot_data_all.columns], \n",
        "                   rotation=45, ha='right', fontsize=11)\n",
        "ax.set_yticks(range(len(pivot_data_all.index)))\n",
        "ax.set_yticklabels(pivot_data_all.index, fontsize=9)\n",
        "ax.set_title('Category-Based RDM Correlations: All Subjects\\n(Younger vs Older Age Bins)', \n",
        "             fontsize=14, pad=15, fontweight='bold')\n",
        "cbar = plt.colorbar(im, ax=ax, label='RDM Correlation (Spearman)', fraction=0.046, pad=0.04)\n",
        "\n",
        "# Add text annotations for correlation values\n",
        "for i in range(len(pivot_data_all.index)):\n",
        "    for j in range(len(pivot_data_all.columns)):\n",
        "        val = pivot_data_all.iloc[i, j]\n",
        "        if not np.isnan(val):\n",
        "            ax.text(j, i, f'{val:.2f}', ha='center', va='center', \n",
        "                   fontsize=7, color='white' if val < 0.5 else 'black', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"category_group_correlations_heatmap.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved detailed heatmap to {output_dir / 'category_group_correlations_heatmap.png'}\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Developmental Trajectories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating RDM visualizations for all subjects (younger vs older)...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating RDM plots: 100%|██████████| 18/18 [00:36<00:00,  2.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved RDM visualizations for 18 subjects\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create side-by-side RDM visualization for each subject (younger vs older)\n",
        "print(\"Creating RDM visualizations for all subjects (younger vs older)...\")\n",
        "\n",
        "for subject_id in tqdm(subject_age_rdms.keys(), desc=\"Creating RDM plots\"):\n",
        "    bin_rdms = subject_age_rdms[subject_id]\n",
        "    bin_masks = subject_age_rdm_masks[subject_id]\n",
        "    \n",
        "    if 'younger' not in bin_rdms or 'older' not in bin_rdms:\n",
        "        continue\n",
        "    \n",
        "    # Create figure with 2 subplots side by side\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    \n",
        "    # Find global min/max for consistent color scale (excluding NaN)\n",
        "    all_rdm_values = []\n",
        "    for rdm in bin_rdms.values():\n",
        "        valid_values = rdm[~np.isnan(rdm)]\n",
        "        if len(valid_values) > 0:\n",
        "            all_rdm_values.extend(valid_values)\n",
        "    vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "    vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "    \n",
        "    for idx, bin_name in enumerate(['younger', 'older']):\n",
        "        rdm = bin_rdms[bin_name]\n",
        "        mask = bin_masks[bin_name]\n",
        "        available_cats = subject_age_rdm_categories[subject_id][bin_name]\n",
        "        group_boundaries = subject_age_group_boundaries[subject_id][bin_name]\n",
        "        \n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Determine font sizes based on number of categories in predefined order\n",
        "        n_cats_total = len(ordered_categories)\n",
        "        n_cats_available = len(available_cats)\n",
        "        \n",
        "        if n_cats_total <= 50:\n",
        "            label_fontsize = 10\n",
        "            tick_fontsize = 12\n",
        "        elif n_cats_total <= 100:\n",
        "            label_fontsize = 8\n",
        "            tick_fontsize = 10\n",
        "        else:\n",
        "            label_fontsize = 6\n",
        "            tick_fontsize = 8\n",
        "        \n",
        "        # Create masked array for visualization (white cells for missing categories)\n",
        "        rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "        cmap = plt.cm.get_cmap('viridis').copy()  # Get a copy to avoid modifying global colormap\n",
        "        cmap.set_bad(color='white', alpha=1.0)  # White for NA cells\n",
        "        im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "        \n",
        "        # Add visual separators between category groups\n",
        "        for boundary in group_boundaries:\n",
        "            # Draw vertical line\n",
        "            if boundary[\"start\"] > 0:\n",
        "                ax.axvline(x=boundary[\"start\"] - 0.5, color=\"white\", linewidth=1.5, linestyle=\"--\", alpha=0.7)\n",
        "            # Draw horizontal line\n",
        "            if boundary[\"start\"] > 0:\n",
        "                ax.axhline(y=boundary[\"start\"] - 0.5, color=\"white\", linewidth=1.5, linestyle=\"--\", alpha=0.7)\n",
        "        \n",
        "        # Set category names as axis labels (use full predefined order)\n",
        "        ax.set_xticks(range(len(ordered_categories)))\n",
        "        ax.set_yticks(range(len(ordered_categories)))\n",
        "        ax.set_xticklabels(ordered_categories, rotation=90, ha=\"right\", fontsize=tick_fontsize)\n",
        "        ax.set_yticklabels(ordered_categories, fontsize=tick_fontsize)\n",
        "        \n",
        "        # Create title with age range info and category count\n",
        "        if bin_name == 'younger':\n",
        "            title = f\"Younger (≤{overall_median_age:.0f} months)\\n({n_cats_available}/{n_cats_total} categories)\"\n",
        "        else:\n",
        "            title = f\"Older (>{overall_median_age:.0f} months)\\n({n_cats_available}/{n_cats_total} categories)\"\n",
        "        \n",
        "        ax.set_title(title, fontsize=12, pad=10)\n",
        "        \n",
        "        # Add colorbar\n",
        "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    \n",
        "    plt.suptitle(f\"Developmental Trajectory: {subject_id}\\n(Median split at {overall_median_age:.1f} months)\", \n",
        "                 fontsize=14, y=0.995)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "    plt.savefig(output_dir / f\"trajectory_{subject_id}.png\", dpi=200, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "print(f\"\\nSaved RDM visualizations for {len(subject_age_rdms)} subjects\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot RDM Stability Across Development\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved RDM stability analysis to developmental_trajectory_rdms/rdm_stability_analysis.png\n"
          ]
        }
      ],
      "source": [
        "# Plot RDM correlation distribution between younger and older bins\n",
        "# Filter out NaN correlations\n",
        "valid_correlations = trajectory_df['rdm_correlation'].dropna()\n",
        "\n",
        "if len(valid_correlations) > 0:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Histogram of RDM correlations\n",
        "    axes[0].hist(valid_correlations, bins=20, alpha=0.7, edgecolor='black')\n",
        "    mean_corr = valid_correlations.mean()\n",
        "    axes[0].axvline(mean_corr, color='red', linestyle='--', \n",
        "                    label=f'Mean: {mean_corr:.3f}')\n",
        "    axes[0].set_xlabel('RDM Correlation (Spearman)')\n",
        "    axes[0].set_ylabel('Number of Subjects')\n",
        "    axes[0].set_title(f'Distribution of Younger vs Older RDM Correlations\\n(n={len(valid_correlations)} valid)')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Box plot\n",
        "    axes[1].boxplot(valid_correlations, vert=True)\n",
        "    axes[1].set_ylabel('RDM Correlation (Spearman)')\n",
        "    axes[1].set_title(f'RDM Correlation: Younger vs Older\\n(n={len(valid_correlations)} valid)')\n",
        "    axes[1].set_xticklabels(['All Subjects'])\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_dir / \"rdm_stability_analysis.png\", dpi=150, bbox_inches='tight')\n",
        "    print(f\"Saved RDM stability analysis to {output_dir / 'rdm_stability_analysis.png'}\")\n",
        "    plt.close()\n",
        "else:\n",
        "    print(\"Warning: No valid correlations to plot (all are NaN)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary statistics:\n",
            "       median_age_threshold  n_categories  mean_distance  std_distance  \\\n",
            "count                  36.0     36.000000      36.000000     36.000000   \n",
            "mean                   16.0    150.916667       0.961607      0.195848   \n",
            "std                     0.0     12.748950       0.018295      0.010685   \n",
            "min                    16.0     88.000000       0.882214      0.175946   \n",
            "25%                    16.0    149.000000       0.958460      0.188916   \n",
            "50%                    16.0    154.500000       0.965709      0.196768   \n",
            "75%                    16.0    157.000000       0.972139      0.203361   \n",
            "max                    16.0    161.000000       0.983759      0.215448   \n",
            "\n",
            "       min_distance  max_distance  \n",
            "count     36.000000     36.000000  \n",
            "mean       0.051624      1.455407  \n",
            "std        0.021439      0.059208  \n",
            "min        0.017231      1.229801  \n",
            "25%        0.037562      1.432026  \n",
            "50%        0.048999      1.466502  \n",
            "75%        0.070066      1.492405  \n",
            "max        0.102304      1.565295  \n",
            "\n",
            "Saved summary to developmental_trajectory_rdms/summary_statistics.csv\n"
          ]
        }
      ],
      "source": [
        "# Create summary statistics\n",
        "summary_data = []\n",
        "\n",
        "for subject_id, bin_rdms in subject_age_rdms.items():\n",
        "    for bin_name in ['younger', 'older']:\n",
        "        if bin_name not in bin_rdms:\n",
        "            continue\n",
        "            \n",
        "        rdm = bin_rdms[bin_name]\n",
        "        categories = subject_age_rdm_categories[subject_id][bin_name]\n",
        "        \n",
        "        # Use nan-aware functions to handle NaN values (missing categories)\n",
        "        valid_rdm = rdm[~np.isnan(rdm)]\n",
        "        valid_rdm_positive = valid_rdm[valid_rdm > 0]  # Exclude diagonal zeros\n",
        "        \n",
        "        summary_data.append({\n",
        "            'subject_id': subject_id,\n",
        "            'age_bin': bin_name,\n",
        "            'median_age_threshold': overall_median_age,\n",
        "            'n_categories': len(categories),\n",
        "            'mean_distance': float(np.nanmean(rdm)) if len(valid_rdm) > 0 else np.nan,\n",
        "            'std_distance': float(np.nanstd(rdm)) if len(valid_rdm) > 0 else np.nan,\n",
        "            'min_distance': float(valid_rdm_positive.min()) if len(valid_rdm_positive) > 0 else np.nan,\n",
        "            'max_distance': float(np.nanmax(rdm)) if len(valid_rdm) > 0 else np.nan\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df.to_csv(output_dir / \"summary_statistics.csv\", index=False)\n",
        "\n",
        "print(\"Summary statistics:\")\n",
        "print(summary_df.describe())\n",
        "print(f\"\\nSaved summary to {output_dir / 'summary_statistics.csv'}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vislearnlabpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
