{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Individual Subject RDM Analysis\n",
        "\n",
        "This notebook creates Representational Dissimilarity Matrices (RDMs) for each individual subject.\n",
        "Each subject's RDM shows the similarity structure of object categories based on their averaged embeddings.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This analysis:\n",
        "1. Loads normalized age-month level embeddings from notebook 05 (normalized grouped embeddings)\n",
        "2. Aggregates embeddings per subject across all age_mo (simple average across age bins)\n",
        "3. Organizes categories using either a predefined category list (for consistent ordering) or automatic organization by type\n",
        "4. Computes RDM for each subject using cosine distance with consistent category ordering\n",
        "5. Handles missing categories by placing NA values for categories not present for each subject\n",
        "6. Visualizes and saves individual subject RDMs with NA cells blacked out\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Normalized embeddings**: Uses pre-normalized embeddings from notebook 05\n",
        "- **Consistent category ordering**: Supports loading a predefined category list (e.g., from notebook 02) to ensure all subjects' RDMs have the same category order for easy visual comparison\n",
        "- **Missing category handling**: Places NA values for categories not present for each subject, ensuring all RDMs have the same dimensions\n",
        "- **NA visualization**: Blackouts NA cells in RDM visualizations to clearly indicate missing data\n",
        "- **Data density handling**: Subjects with more data get more reliable RDMs, but all RDMs maintain the same structure\n",
        "- **Age-month aggregation**: Averages embeddings across all age_mo bins for each subject-category combination\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, optimal_leaf_ordering\n",
        "from scipy.spatial.distance import squareform\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set matplotlib backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CDI path: ../../data/cdi_words.csv\n",
            "Use clustering: True\n",
            "Use predefined category list: True\n",
            "Predefined category list path: ../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\n"
          ]
        }
      ],
      "source": [
        "# CDI words CSV file (required for category type organization)\n",
        "cdi_path = Path(\"../../data/cdi_words.csv\")\n",
        "\n",
        "# Hierarchical clustering options\n",
        "use_clustering = True  # Enable hierarchical clustering within category groups\n",
        "save_dendrograms = True  # Save dendrogram plots for each category group\n",
        "\n",
        "# Predefined category list for consistent RDM ordering (optional)\n",
        "# Set to None to use automatic organization, or provide path to category order file\n",
        "# This allows comparing RDMs across subjects with the same category ordering\n",
        "USE_PREDEFINED_CATEGORY_LIST = True  # If True, load category order from PREDEFINED_CATEGORY_LIST_PATH\n",
        "PREDEFINED_CATEGORY_LIST_PATH = \"../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\"  # Path to text file with category order (one category per line), or None\n",
        "# Example: PREDEFINED_CATEGORY_LIST_PATH = \"../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt\"\n",
        "\n",
        "print(f\"CDI path: {cdi_path}\")\n",
        "print(f\"Use clustering: {use_clustering}\")\n",
        "print(f\"Use predefined category list: {USE_PREDEFINED_CATEGORY_LIST}\")\n",
        "if USE_PREDEFINED_CATEGORY_LIST and PREDEFINED_CATEGORY_LIST_PATH:\n",
        "    print(f\"Predefined category list path: {PREDEFINED_CATEGORY_LIST_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded!\n"
          ]
        }
      ],
      "source": [
        "def load_category_types(cdi_path):\n",
        "    \"\"\"Load category type information from CDI words CSV\"\"\"\n",
        "    print(f\"Loading category types from {cdi_path}...\")\n",
        "    cdi_df = pd.read_csv(cdi_path)\n",
        "    \n",
        "    category_types = {}\n",
        "    for _, row in cdi_df.iterrows():\n",
        "        category_types[row['uni_lemma']] = {\n",
        "            'is_animate': bool(row.get('is_animate', 0)),\n",
        "            'is_bodypart': bool(row.get('is_bodypart', 0)),\n",
        "            'is_small': bool(row.get('is_small', 0)),\n",
        "            'is_big': bool(row.get('is_big', 0))\n",
        "        }\n",
        "    \n",
        "    print(f\"Loaded type information for {len(category_types)} categories\")\n",
        "    return category_types\n",
        "\n",
        "def load_cdi_category_mapping(cdi_path):\n",
        "    \"\"\"Load CDI category mapping (uni_lemma -> category) for coloring labels\"\"\"\n",
        "    cdi_df = pd.read_csv(cdi_path)\n",
        "    category_map = {}\n",
        "    for _, row in cdi_df.iterrows():\n",
        "        category_map[row['uni_lemma']] = row.get('category', 'unknown')\n",
        "    return category_map\n",
        "\n",
        "def get_category_color(category_name, category_map):\n",
        "    \"\"\"Get color for a category based on its CDI category type\"\"\"\n",
        "    # Define color scheme for CDI categories\n",
        "    category_colors = {\n",
        "        'animals': '#8B4513',  # Brown\n",
        "        'body_parts': '#FF6B6B',  # Red\n",
        "        'food_drink': '#FFA500',  # Orange\n",
        "        'furniture_rooms': '#4169E1',  # Royal Blue\n",
        "        'toys': '#FF69B4',  # Hot Pink\n",
        "        'vehicles': '#32CD32',  # Lime Green\n",
        "        'clothing': '#9370DB',  # Medium Purple\n",
        "        'outside': '#228B22',  # Forest Green\n",
        "        'places': '#4682B4',  # Steel Blue\n",
        "        'small_things': '#FFD700',  # Gold\n",
        "        'action_words': '#DC143C',  # Crimson\n",
        "        'descriptive_words': '#20B2AA',  # Light Sea Green\n",
        "        'sound_effects': '#FF1493',  # Deep Pink\n",
        "        'games_routines': '#00CED1',  # Dark Turquoise\n",
        "    }\n",
        "    \n",
        "    # Get the CDI category for this uni_lemma\n",
        "    cdi_category = category_map.get(category_name, 'unknown')\n",
        "    \n",
        "    # Return color, default to gray if not found\n",
        "    return category_colors.get(cdi_category, '#808080')  # Gray for unknown\n",
        "\n",
        "def cluster_categories_within_group(group_categories, cat_to_embedding, save_dendrogram=False, output_dir=None, group_name=None):\n",
        "    \"\"\"\n",
        "    Perform hierarchical clustering within a group of categories.\n",
        "    \n",
        "    Args:\n",
        "        group_categories: List of category names in the group\n",
        "        cat_to_embedding: Dictionary mapping category names to embeddings\n",
        "        save_dendrogram: Whether to save dendrogram plot (default: False)\n",
        "        output_dir: Output directory for saving dendrogram (required if save_dendrogram=True)\n",
        "        group_name: Name of the group for saving dendrogram (required if save_dendrogram=True)\n",
        "    \n",
        "    Returns:\n",
        "        List of category names reordered according to clustering dendrogram\n",
        "    \"\"\"\n",
        "    if len(group_categories) <= 1:\n",
        "        return group_categories, None\n",
        "    \n",
        "    # Get embeddings for this group\n",
        "    group_embeddings = np.array([cat_to_embedding[cat].flatten() for cat in group_categories])\n",
        "    \n",
        "    # Normalize embeddings (z-score normalization per embedding)\n",
        "    normalized_embeddings = (group_embeddings - group_embeddings.mean(axis=0)) / (group_embeddings.std(axis=0) + 1e-10)\n",
        "    \n",
        "    # Compute distance matrix (1 - cosine similarity)\n",
        "    similarity_matrix = cosine_similarity(normalized_embeddings)\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    np.fill_diagonal(distance_matrix, 0)\n",
        "    \n",
        "    # Convert to condensed form for linkage\n",
        "    condensed_distances = squareform(distance_matrix)\n",
        "    \n",
        "    # Perform hierarchical clustering\n",
        "    linkage_matrix = linkage(condensed_distances, method='ward')\n",
        "    \n",
        "    # Get optimal leaf ordering for better visualization\n",
        "    try:\n",
        "        linkage_matrix = optimal_leaf_ordering(linkage_matrix, condensed_distances)\n",
        "    except:\n",
        "        # If optimal leaf ordering fails, use original linkage\n",
        "        pass\n",
        "    \n",
        "    # Extract the order from the dendrogram\n",
        "    dendro_dict = dendrogram(linkage_matrix, no_plot=True)\n",
        "    leaf_order = dendro_dict['leaves']\n",
        "    \n",
        "    # Reorder categories according to clustering\n",
        "    clustered_categories = [group_categories[i] for i in leaf_order]\n",
        "    \n",
        "    # Save dendrogram if requested\n",
        "    if save_dendrogram and output_dir is not None and group_name is not None:\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        dendrogram(linkage_matrix, \n",
        "                  labels=group_categories,\n",
        "                  leaf_rotation=90,\n",
        "                  leaf_font_size=10)\n",
        "        plt.title(f'Hierarchical Clustering Dendrogram: {group_name.upper()}\\n({len(group_categories)} categories)',\n",
        "                 fontsize=16, pad=20)\n",
        "        plt.xlabel('Category', fontsize=12)\n",
        "        plt.ylabel('Distance', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Save as PNG\n",
        "        output_path_png = output_dir / f'dendrogram_{group_name}.png'\n",
        "        plt.savefig(output_path_png, dpi=300, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_png}\")\n",
        "        \n",
        "        # Save as PDF\n",
        "        output_path_pdf = output_dir / f'dendrogram_{group_name}.pdf'\n",
        "        plt.savefig(output_path_pdf, bbox_inches='tight', pad_inches=0.2)\n",
        "        print(f\"    Saved dendrogram to {output_path_pdf}\")\n",
        "        \n",
        "        plt.close()\n",
        "    \n",
        "    return clustered_categories, linkage_matrix\n",
        "\n",
        "print(\"Helper functions loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized embeddings directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\n",
            "Detected embedding type: clip\n",
            "Output directory: individual_subject_rdms_clip\n",
            "CSV subdirectory: individual_subject_rdms_clip/csv\n",
            "NPY subdirectory: individual_subject_rdms_clip/npy\n",
            "Excluded subject: 00270001\n",
            "Min categories per subject: 10\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "# Path to normalized embeddings from notebook 05 (age-month level normalized embeddings)\n",
        "# These are saved in category folders: {normalized_embeddings_dir}/{category}/{subject_id}_{age_mo}_month_level_avg.npy\n",
        "# normalized_embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/facebook_dinov3-vitb16-pretrain-lvd1689m_grouped_by_age-mo_normalized\")\n",
        "normalized_embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\")\n",
        "\n",
        "# Detect embedding type from path\n",
        "normalized_embeddings_dir_str = str(normalized_embeddings_dir).lower()\n",
        "if \"dinov3\" in normalized_embeddings_dir_str or \"dinov\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"dinov3\"\n",
        "elif \"clip\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"clip\"\n",
        "else:\n",
        "    embedding_type = \"unknown\"\n",
        "\n",
        "# Create output directory with embedding type in name\n",
        "output_dir = Path(f\"individual_subject_rdms_{embedding_type}\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Create subdirectories for organizing files\n",
        "csv_dir = output_dir / \"csv\"\n",
        "npy_dir = output_dir / \"npy\"\n",
        "csv_dir.mkdir(exist_ok=True, parents=True)\n",
        "npy_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Subject to exclude from analyses\n",
        "excluded_subject = \"00270001\"\n",
        "\n",
        "# Minimum categories required per subject to compute RDM\n",
        "min_categories_per_subject = 10\n",
        "\n",
        "print(f\"Normalized embeddings directory: {normalized_embeddings_dir}\")\n",
        "print(f\"Detected embedding type: {embedding_type}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"CSV subdirectory: {csv_dir}\")\n",
        "print(f\"NPY subdirectory: {npy_dir}\")\n",
        "print(f\"Excluded subject: {excluded_subject}\")\n",
        "print(f\"Min categories per subject: {min_categories_per_subject}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Normalized Grouped Embeddings from Notebook 05\n",
        "\n",
        "This section loads normalized age-month level embeddings from notebook 05 and aggregates them to subject level.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading normalized age-month level embeddings from notebook 05...\n",
            "  Source directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\n",
            "  Found 163 category folders\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading category folders: 100%|██████████| 163/163 [00:02<00:00, 65.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Aggregating embeddings per subject (averaging across age_mo)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Aggregating subjects: 100%|██████████| 31/31 [00:00<00:00, 535.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded and aggregated normalized embeddings for 31 subjects\n",
            "  Total unique categories across all subjects: 163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load normalized age-month level embeddings from notebook 05 and aggregate to subject level\n",
        "print(\"Loading normalized age-month level embeddings from notebook 05...\")\n",
        "print(f\"  Source directory: {normalized_embeddings_dir}\")\n",
        "\n",
        "# Get all category folders\n",
        "category_folders = [f for f in normalized_embeddings_dir.iterdir() if f.is_dir()]\n",
        "print(f\"  Found {len(category_folders)} category folders\")\n",
        "\n",
        "# Collect all embeddings by subject and category\n",
        "# Structure: {subject_id: {category: [list of age_mo embeddings]}}\n",
        "subject_category_embeddings = defaultdict(lambda: defaultdict(list))\n",
        "all_categories_set = set()\n",
        "\n",
        "for category_folder in tqdm(category_folders, desc=\"Loading category folders\"):\n",
        "    category = category_folder.name\n",
        "    all_categories_set.add(category)\n",
        "    \n",
        "    # Get all embedding files in this category\n",
        "    embedding_files = list(category_folder.glob(\"*.npy\"))\n",
        "    \n",
        "    for emb_file in embedding_files:\n",
        "        # Parse filename: {subject_id}_{age_mo}_month_level_avg.npy\n",
        "        filename = emb_file.stem  # without .npy\n",
        "        parts = filename.split('_')\n",
        "        \n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        \n",
        "        # Extract subject_id and age_mo\n",
        "        subject_id = parts[0]\n",
        "        age_mo = int(parts[1]) if parts[1].isdigit() else None\n",
        "        \n",
        "        if age_mo is None:\n",
        "            continue\n",
        "        \n",
        "        # Exclude subject if specified\n",
        "        if excluded_subject and subject_id == excluded_subject:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            embedding = np.load(emb_file)\n",
        "            subject_category_embeddings[subject_id][category].append(embedding)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {emb_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Aggregate embeddings per subject: average across age_mo for each category\n",
        "print(f\"\\nAggregating embeddings per subject (averaging across age_mo)...\")\n",
        "subject_embeddings_normalized = {}\n",
        "\n",
        "for subject_id in tqdm(subject_category_embeddings.keys(), desc=\"Aggregating subjects\"):\n",
        "    subject_embeddings_normalized[subject_id] = {}\n",
        "    \n",
        "    for category, age_mo_embeddings in subject_category_embeddings[subject_id].items():\n",
        "        if len(age_mo_embeddings) > 0:\n",
        "            # Average across all age_mo embeddings for this category\n",
        "            # Stack embeddings and compute mean\n",
        "            stacked = np.array([emb.flatten() for emb in age_mo_embeddings])\n",
        "            avg_embedding = stacked.mean(axis=0)\n",
        "            subject_embeddings_normalized[subject_id][category] = avg_embedding\n",
        "\n",
        "print(f\"\\nLoaded and aggregated normalized embeddings for {len(subject_embeddings_normalized)} subjects\")\n",
        "print(f\"  Total unique categories across all subjects: {len(all_categories_set)}\")\n",
        "\n",
        "# Convert to list for easier handling\n",
        "all_categories = sorted(list(all_categories_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Organize Categories (with Predefined List Option)\n",
        "\n",
        "This section organizes categories either by loading a predefined category list (for consistent ordering across subjects) or by automatic organization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Organizing categories...\n",
            "  Loading predefined category order from ../vss-2026/bv_things_comp_12252025/bv_clip_filtered_zscored_hierarchical_163cats/category_order_reorganized.txt...\n",
            "  Loaded 163 categories in predefined order\n",
            "\n",
            "Final ordered category list: 163 categories\n"
          ]
        }
      ],
      "source": [
        "# Organize categories: either load predefined list or organize automatically\n",
        "print(\"Organizing categories...\")\n",
        "\n",
        "if USE_PREDEFINED_CATEGORY_LIST and PREDEFINED_CATEGORY_LIST_PATH is not None:\n",
        "    # Load predefined category list\n",
        "    predefined_path = Path(PREDEFINED_CATEGORY_LIST_PATH)\n",
        "    if not predefined_path.exists():\n",
        "        raise FileNotFoundError(f\"Predefined category list file not found: {predefined_path}\")\n",
        "    \n",
        "    print(f\"  Loading predefined category order from {predefined_path}...\")\n",
        "    with open(predefined_path, 'r') as f:\n",
        "        # Skip comment lines (lines starting with #)\n",
        "        ordered_categories = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]\n",
        "    \n",
        "    # Verify that all categories in predefined list exist in our data\n",
        "    predefined_set = set(ordered_categories)\n",
        "    all_categories_set = set(all_categories)\n",
        "    \n",
        "    if predefined_set != all_categories_set:\n",
        "        missing_in_predefined = all_categories_set - predefined_set\n",
        "        extra_in_predefined = predefined_set - all_categories_set\n",
        "        if missing_in_predefined:\n",
        "            print(f\"  Warning: {len(missing_in_predefined)} categories in data but not in predefined list: {sorted(missing_in_predefined)[:5]}...\")\n",
        "        if extra_in_predefined:\n",
        "            print(f\"  Warning: {len(extra_in_predefined)} categories in predefined list but not in data: {sorted(extra_in_predefined)[:5]}...\")\n",
        "        # Use intersection: only categories that exist in both\n",
        "        ordered_categories = [cat for cat in ordered_categories if cat in all_categories_set]\n",
        "        print(f\"  Using intersection: {len(ordered_categories)} categories\")\n",
        "    \n",
        "    print(f\"  Loaded {len(ordered_categories)} categories in predefined order\")\n",
        "    \n",
        "    # Create dummy organized dict for compatibility (won't be used for visualization boundaries)\n",
        "    organized = {'animals': [], 'bodyparts': [], 'big_objects': [], 'small_objects': [], 'others': []}\n",
        "    \n",
        "else:\n",
        "    # Automatic organization by type (similar to notebook 02)\n",
        "    print(f\"  Organizing categories by type...\")\n",
        "    cdi_path = Path(cdi_path)\n",
        "    \n",
        "    if cdi_path.exists():\n",
        "        category_types = load_category_types(cdi_path)\n",
        "        \n",
        "        # Organize by type\n",
        "        organized = {\n",
        "            'animals': [],\n",
        "            'bodyparts': [],\n",
        "            'big_objects': [],\n",
        "            'small_objects': [],\n",
        "            'others': []\n",
        "        }\n",
        "        \n",
        "        for cat in all_categories:\n",
        "            if cat not in category_types:\n",
        "                organized['others'].append(cat)\n",
        "                continue\n",
        "            \n",
        "            types = category_types[cat]\n",
        "            if types['is_animate']:\n",
        "                organized['animals'].append(cat)\n",
        "            elif types['is_bodypart']:\n",
        "                organized['bodyparts'].append(cat)\n",
        "            elif types['is_big']:\n",
        "                organized['big_objects'].append(cat)\n",
        "            elif types['is_small']:\n",
        "                organized['small_objects'].append(cat)\n",
        "            else:\n",
        "                organized['others'].append(cat)\n",
        "        \n",
        "        print(f\"  Organized into: {len(organized['animals'])} animals, {len(organized['bodyparts'])} bodyparts, \"\n",
        "              f\"{len(organized['big_objects'])} big objects, {len(organized['small_objects'])} small objects, \"\n",
        "              f\"{len(organized['others'])} others\")\n",
        "        \n",
        "        # Apply hierarchical clustering if enabled\n",
        "        if use_clustering:\n",
        "            print(f\"  Applying hierarchical clustering within groups...\")\n",
        "            # Create a representative embedding dict for clustering (use first subject that has all categories)\n",
        "            cat_to_embedding = {}\n",
        "            for subject_id, subject_embeddings in subject_embeddings_normalized.items():\n",
        "                if all(cat in subject_embeddings for cat in all_categories):\n",
        "                    cat_to_embedding = {cat: subject_embeddings[cat] for cat in all_categories}\n",
        "                    break\n",
        "            \n",
        "            # If no subject has all categories, use average across subjects\n",
        "            if not cat_to_embedding:\n",
        "                print(f\"    No subject has all categories, computing average embeddings for clustering...\")\n",
        "                for cat in all_categories:\n",
        "                    cat_embeddings = []\n",
        "                    for subject_embeddings in subject_embeddings_normalized.values():\n",
        "                        if cat in subject_embeddings:\n",
        "                            cat_embeddings.append(subject_embeddings[cat])\n",
        "                    if cat_embeddings:\n",
        "                        cat_to_embedding[cat] = np.array(cat_embeddings).mean(axis=0)\n",
        "            \n",
        "            for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "                if len(organized[group_name]) > 1:\n",
        "                    print(f\"    Clustering {group_name} ({len(organized[group_name])} categories)...\")\n",
        "                    organized[group_name], _ = cluster_categories_within_group(\n",
        "                        organized[group_name],\n",
        "                        cat_to_embedding,\n",
        "                        save_dendrogram=save_dendrograms,\n",
        "                        output_dir=output_dir,\n",
        "                        group_name=group_name\n",
        "                    )\n",
        "        else:\n",
        "            for group_name in organized:\n",
        "                organized[group_name] = sorted(organized[group_name])\n",
        "        \n",
        "        # Create ordered list\n",
        "        ordered_categories = (\n",
        "            organized['animals'] +\n",
        "            organized['bodyparts'] +\n",
        "            organized['big_objects'] +\n",
        "            organized['small_objects'] +\n",
        "            organized['others']\n",
        "        )\n",
        "    else:\n",
        "        print(f\"  Warning: CDI path {cdi_path} not found. Using alphabetical order.\")\n",
        "        organized = {'animals': [], 'bodyparts': [], 'big_objects': [], 'small_objects': [], 'others': all_categories}\n",
        "        ordered_categories = sorted(all_categories)\n",
        "\n",
        "print(f\"\\nFinal ordered category list: {len(ordered_categories)} categories\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Individual Subject RDMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computing RDMs for each subject (with NA for missing categories)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing RDMs: 100%|██████████| 31/31 [00:00<00:00, 160.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computed RDMs for 31 subjects\n",
            "  (Excluded 0 subjects with < 10 categories)\n",
            "\n",
            "Computing group boundaries for visualization...\n",
            "Computed group boundaries for 31 subjects\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def compute_subject_rdm_with_na(subject_embeddings_dict, ordered_categories_list):\n",
        "    \"\"\"\n",
        "    Compute RDM for a single subject with NA for missing categories.\n",
        "    \n",
        "    Args:\n",
        "        subject_embeddings_dict: dict[category] = embedding array (should be normalized)\n",
        "        ordered_categories_list: list of all categories in desired order (may include categories not present for this subject)\n",
        "    \n",
        "    Returns:\n",
        "        rdm: numpy array of shape (n_categories, n_categories) with np.nan for missing categories\n",
        "        mask: boolean array of shape (n_categories, n_categories) where True indicates NA (missing category)\n",
        "        available_categories: list of categories actually present for this subject\n",
        "    \"\"\"\n",
        "    n_categories = len(ordered_categories_list)\n",
        "    \n",
        "    # Find available categories (categories that exist for this subject)\n",
        "    available_categories = [cat for cat in ordered_categories_list if cat in subject_embeddings_dict]\n",
        "    \n",
        "    if len(available_categories) < 2:\n",
        "        # Return RDM full of NaN if not enough categories\n",
        "        rdm = np.full((n_categories, n_categories), np.nan)\n",
        "        mask = np.ones((n_categories, n_categories), dtype=bool)\n",
        "        return rdm, mask, available_categories\n",
        "    \n",
        "    # Build embedding matrix for available categories (already normalized)\n",
        "    embedding_matrix = np.array([subject_embeddings_dict[cat].flatten() for cat in available_categories])\n",
        "    \n",
        "    # Ensure 2D shape: (n_available_categories, embedding_dim)\n",
        "    if embedding_matrix.ndim != 2:\n",
        "        raise ValueError(f\"Expected 2D embedding matrix, got shape {embedding_matrix.shape}\")\n",
        "    \n",
        "    # Compute cosine similarity for available categories\n",
        "    similarity_matrix_available = cosine_similarity(embedding_matrix)\n",
        "    \n",
        "    # Convert to distance (RDM) for available categories\n",
        "    distance_matrix_available = 1 - similarity_matrix_available\n",
        "    np.fill_diagonal(distance_matrix_available, 0)  # Ensure diagonal is 0\n",
        "    \n",
        "    # Make symmetric (in case of numerical errors)\n",
        "    distance_matrix_available = (distance_matrix_available + distance_matrix_available.T) / 2\n",
        "    \n",
        "    # Create full RDM with NaN for missing categories\n",
        "    rdm = np.full((n_categories, n_categories), np.nan)\n",
        "    mask = np.ones((n_categories, n_categories), dtype=bool)\n",
        "    \n",
        "    # Map available categories to their indices in ordered_categories_list\n",
        "    available_indices = [ordered_categories_list.index(cat) for cat in available_categories]\n",
        "    \n",
        "    # Fill in the RDM for available categories\n",
        "    for i, idx_i in enumerate(available_indices):\n",
        "        for j, idx_j in enumerate(available_indices):\n",
        "            rdm[idx_i, idx_j] = distance_matrix_available[i, j]\n",
        "            mask[idx_i, idx_j] = False  # False means not NA (data present)\n",
        "    \n",
        "    return rdm, mask, available_categories\n",
        "\n",
        "# Compute RDMs for each subject using normalized embeddings with NA for missing categories\n",
        "print(\"\\nComputing RDMs for each subject (with NA for missing categories)...\")\n",
        "subject_rdms = {}\n",
        "subject_rdm_masks = {}  # Store masks indicating NA cells\n",
        "subject_rdm_categories = {}  # Store available categories for each subject\n",
        "\n",
        "for subject_id, subject_embeddings in tqdm(subject_embeddings_normalized.items(), desc=\"Computing RDMs\"):\n",
        "    if len(subject_embeddings) < min_categories_per_subject:\n",
        "        continue\n",
        "    \n",
        "    rdm, mask, available_cats = compute_subject_rdm_with_na(subject_embeddings, ordered_categories)\n",
        "    \n",
        "    if rdm is not None and len(available_cats) >= min_categories_per_subject:\n",
        "        subject_rdms[subject_id] = rdm\n",
        "        subject_rdm_masks[subject_id] = mask\n",
        "        subject_rdm_categories[subject_id] = available_cats\n",
        "\n",
        "print(f\"\\nComputed RDMs for {len(subject_rdms)} subjects\")\n",
        "print(f\"  (Excluded {len(subject_embeddings_normalized) - len(subject_rdms)} subjects with < {min_categories_per_subject} categories)\")\n",
        "\n",
        "# Compute group boundaries for visualization (based on ordered_categories)\n",
        "print(\"\\nComputing group boundaries for visualization...\")\n",
        "subject_group_boundaries = {}  # Store group boundaries for visual separators\n",
        "\n",
        "for subject_id in subject_rdms.keys():\n",
        "    # Compute group boundaries based on ordered_categories\n",
        "    group_boundaries = []\n",
        "    current_idx = 0\n",
        "    for group_name in ['animals', 'bodyparts', 'big_objects', 'small_objects', 'others']:\n",
        "        group_cats = [cat for cat in organized[group_name] if cat in ordered_categories]\n",
        "        if len(group_cats) > 0:\n",
        "            group_start = current_idx\n",
        "            group_end = current_idx + len(group_cats)\n",
        "            group_boundaries.append({\n",
        "                'name': group_name,\n",
        "                'start': group_start,\n",
        "                'end': group_end,\n",
        "                'categories': group_cats\n",
        "            })\n",
        "            current_idx = group_end\n",
        "    \n",
        "    subject_group_boundaries[subject_id] = group_boundaries\n",
        "\n",
        "print(f\"Computed group boundaries for {len(subject_rdms)} subjects\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Individual Subject RDMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper function for group boundaries loaded!\n"
          ]
        }
      ],
      "source": [
        "def add_group_boundaries(ax, group_boundaries, linewidth=1.5, alpha=0.7, color='white'):\n",
        "    \"\"\"\n",
        "    Add visual separators for category groups on an RDM plot.\n",
        "    \n",
        "    Args:\n",
        "        ax: matplotlib axis\n",
        "        group_boundaries: list of dicts with 'start' and 'end' keys for each group\n",
        "        linewidth: width of separator lines\n",
        "        alpha: transparency of lines\n",
        "        color: color of separator lines\n",
        "    \"\"\"\n",
        "    n_cats = ax.get_xlim()[1]  # Get number of categories from axis limits\n",
        "    \n",
        "    for boundary in group_boundaries:\n",
        "        start = boundary['start']\n",
        "        end = boundary['end']\n",
        "        \n",
        "        # Add vertical line at group boundary (between groups)\n",
        "        if start > 0:  # Don't draw line at the very start\n",
        "            ax.axvline(x=start - 0.5, color=color, linewidth=linewidth, alpha=alpha, zorder=10)\n",
        "            ax.axhline(y=start - 0.5, color=color, linewidth=linewidth, alpha=alpha, zorder=10)\n",
        "        \n",
        "        # Add vertical line at end of group\n",
        "        if end < n_cats:  # Don't draw line at the very end\n",
        "            ax.axvline(x=end - 0.5, color=color, linewidth=linewidth, alpha=alpha, zorder=10)\n",
        "            ax.axhline(y=end - 0.5, color=color, linewidth=linewidth, alpha=alpha, zorder=10)\n",
        "\n",
        "print(\"Helper function for group boundaries loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating clean RDM visualization (no labels, group boundaries only)...\n",
            "Plotting 31 individual subject RDMs (clean version)...\n",
            "Color scale range: [0.2058, 1.5056]\n",
            "\n",
            "Saved clean RDM visualization to individual_subject_rdms_clip/all_individual_rdms_clean.png\n",
            "Saved clean RDM visualization (coolwarm) to individual_subject_rdms_clip/all_individual_rdms_clean_coolwarm.png\n",
            "\n",
            "Creating reference plot showing category structure...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'cdi_category_map' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 153\u001b[39m\n\u001b[32m    151\u001b[39m     cat_name = label.get_text()\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cat_name:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m         color = get_category_color(cat_name, \u001b[43mcdi_category_map\u001b[49m)\n\u001b[32m    154\u001b[39m         label.set_color(color)\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ax.get_yticklabels():\n",
            "\u001b[31mNameError\u001b[39m: name 'cdi_category_map' is not defined"
          ]
        }
      ],
      "source": [
        "## Visualize All Individual Subject RDMs (Clean Version - No Labels)\n",
        "\n",
        "# Create a cleaner version without axis labels and individual colorbars\n",
        "# Group boundaries are shown as white lines to indicate CDI semantic category structure\n",
        "\n",
        "# Load CDI category mapping for label coloring (needed for reference plot)\n",
        "cdi_category_map = load_cdi_category_mapping(cdi_path)\n",
        "\n",
        "print(\"\\nCreating clean RDM visualization (no labels, group boundaries only)...\")\n",
        "\n",
        "# Plot all individual subject RDMs in a grid\n",
        "n_subjects = len(subject_rdms)\n",
        "subject_ids = list(subject_rdms.keys())\n",
        "\n",
        "# Calculate grid dimensions\n",
        "n_cols = 6  # Number of columns\n",
        "n_rows = int(np.ceil(n_subjects / n_cols))\n",
        "\n",
        "# Create figure with appropriate size\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "axes = axes.flatten() if n_subjects > 1 else [axes]\n",
        "\n",
        "# Find global min/max for consistent color scale across all RDMs (excluding NaN)\n",
        "all_rdm_values = []\n",
        "for rdm in subject_rdms.values():\n",
        "    valid_values = rdm[~np.isnan(rdm)]\n",
        "    all_rdm_values.extend(valid_values)\n",
        "vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "\n",
        "print(f\"Plotting {n_subjects} individual subject RDMs (clean version)...\")\n",
        "print(f\"Color scale range: [{vmin:.4f}, {vmax:.4f}]\")\n",
        "\n",
        "# Get group boundaries for the first subject (all subjects use same category order)\n",
        "# Use the first subject's boundaries as reference\n",
        "reference_subject_id = subject_ids[0]\n",
        "group_boundaries = subject_group_boundaries[reference_subject_id]\n",
        "\n",
        "for idx, subject_id in enumerate(subject_ids):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    mask = subject_rdm_masks[subject_id]\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Create a masked array for visualization\n",
        "    rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "    cmap = plt.cm.get_cmap('viridis').copy()\n",
        "    cmap.set_bad(color='white', alpha=1.0)  # White for NA cells\n",
        "    im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    \n",
        "    # Add group boundaries as white lines\n",
        "    add_group_boundaries(ax, group_boundaries, linewidth=1.5, alpha=0.8, color='white')\n",
        "    \n",
        "    # Remove all axis labels and ticks\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('')\n",
        "    \n",
        "    # Keep only the title with subject ID and category count\n",
        "    ax.set_title(f\"{subject_id}\\n({len(available_cats)}/{len(ordered_categories)})\", \n",
        "                fontsize=9, pad=5)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(n_subjects, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "# Add a single shared colorbar for the entire figure\n",
        "# Position it on the right side of the figure\n",
        "fig.subplots_adjust(right=0.92)\n",
        "cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
        "cbar = fig.colorbar(im, cax=cbar_ax)\n",
        "cbar.set_label('Distance (1 - Cosine Similarity)', fontsize=10, rotation=270, labelpad=15)\n",
        "\n",
        "plt.suptitle(f'All Individual Subject RDMs (n={n_subjects}) - Clean Version\\n(Group boundaries shown as white lines)', \n",
        "            fontsize=14, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 0.92, 0.99])  # Leave space for colorbar\n",
        "plt.savefig(output_dir / \"all_individual_rdms_clean.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"\\nSaved clean RDM visualization to {output_dir / 'all_individual_rdms_clean.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Also create a version with coolwarm colormap\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "axes = axes.flatten() if n_subjects > 1 else [axes]\n",
        "\n",
        "for idx, subject_id in enumerate(subject_ids):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    mask = subject_rdm_masks[subject_id]\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    \n",
        "    rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "    cmap = plt.cm.get_cmap('coolwarm').copy()\n",
        "    cmap.set_bad(color='white', alpha=1.0)\n",
        "    im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    \n",
        "    # Add group boundaries\n",
        "    add_group_boundaries(ax, group_boundaries, linewidth=1.5, alpha=0.8, color='white')\n",
        "    \n",
        "    # Remove all axis labels and ticks\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('')\n",
        "    \n",
        "    ax.set_title(f\"{subject_id}\\n({len(available_cats)}/{len(ordered_categories)})\", \n",
        "                fontsize=9, pad=5)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(n_subjects, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "# Add shared colorbar\n",
        "fig.subplots_adjust(right=0.92)\n",
        "cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.7])\n",
        "cbar = fig.colorbar(im, cax=cbar_ax)\n",
        "cbar.set_label('Distance (1 - Cosine Similarity)', fontsize=10, rotation=270, labelpad=15)\n",
        "\n",
        "plt.suptitle(f'All Individual Subject RDMs (n={n_subjects}) - Clean Version (Coolwarm)\\n(Group boundaries shown as white lines)', \n",
        "            fontsize=14, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 0.92, 0.99])\n",
        "plt.savefig(output_dir / \"all_individual_rdms_clean_coolwarm.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved clean RDM visualization (coolwarm) to {output_dir / 'all_individual_rdms_clean_coolwarm.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Create a reference plot showing category structure with labels\n",
        "# This can be used as a separate reference to understand the group boundaries\n",
        "print(\"\\nCreating reference plot showing category structure...\")\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "\n",
        "# Create a dummy RDM for visualization (just to show the structure)\n",
        "n_cats = len(ordered_categories)\n",
        "dummy_rdm = np.ones((n_cats, n_cats)) * 0.5  # Neutral gray\n",
        "\n",
        "im = ax.imshow(dummy_rdm, cmap='gray', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "# Add group boundaries\n",
        "add_group_boundaries(ax, group_boundaries, linewidth=2, alpha=1.0, color='red')\n",
        "\n",
        "# Add category labels (show all, but smaller font)\n",
        "ax.set_xticks(range(n_cats))\n",
        "ax.set_yticks(range(n_cats))\n",
        "ax.set_xticklabels(ordered_categories, rotation=90, ha='right', fontsize=6)\n",
        "ax.set_yticklabels(ordered_categories, fontsize=6)\n",
        "\n",
        "# Apply colors to labels based on CDI category\n",
        "for label in ax.get_xticklabels():\n",
        "    cat_name = label.get_text()\n",
        "    if cat_name:\n",
        "        color = get_category_color(cat_name, cdi_category_map)\n",
        "        label.set_color(color)\n",
        "for label in ax.get_yticklabels():\n",
        "    cat_name = label.get_text()\n",
        "    if cat_name:\n",
        "        color = get_category_color(cat_name, cdi_category_map)\n",
        "        label.set_color(color)\n",
        "\n",
        "# Add group labels\n",
        "for boundary in group_boundaries:\n",
        "    mid_point = (boundary['start'] + boundary['end']) / 2\n",
        "    ax.text(mid_point, -n_cats*0.05, boundary['name'].replace('_', ' ').title(), \n",
        "           ha='center', va='top', fontsize=10, fontweight='bold',\n",
        "           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
        "    ax.text(-n_cats*0.05, mid_point, boundary['name'].replace('_', ' ').title(), \n",
        "           ha='right', va='center', fontsize=10, fontweight='bold', rotation=90,\n",
        "           bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
        "\n",
        "ax.set_title('Category Structure Reference\\n(Red lines show group boundaries, colored labels show CDI categories)', \n",
        "            fontsize=14, pad=20)\n",
        "ax.set_xlabel('Category Index', fontsize=12)\n",
        "ax.set_ylabel('Category Index', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"category_structure_reference.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved category structure reference to {output_dir / 'category_structure_reference.png'}\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nClean visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Visualize All Individual Subject RDMs\n",
        "\n",
        "# Load CDI category mapping for label coloring\n",
        "cdi_category_map = load_cdi_category_mapping(cdi_path)\n",
        "\n",
        "\n",
        "# Plot all individual subject RDMs in a grid\n",
        "n_subjects = len(subject_rdms)\n",
        "subject_ids = list(subject_rdms.keys())\n",
        "\n",
        "# Calculate grid dimensions\n",
        "n_cols = 6  # Number of columns\n",
        "n_rows = int(np.ceil(n_subjects / n_cols))\n",
        "\n",
        "# Create figure with appropriate size\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "axes = axes.flatten() if n_subjects > 1 else [axes]\n",
        "\n",
        "# Find global min/max for consistent color scale across all RDMs (excluding NaN)\n",
        "all_rdm_values = []\n",
        "for rdm in subject_rdms.values():\n",
        "    valid_values = rdm[~np.isnan(rdm)]\n",
        "    all_rdm_values.extend(valid_values)\n",
        "vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "\n",
        "print(f\"Plotting {n_subjects} individual subject RDMs...\")\n",
        "print(f\"Color scale range: [{vmin:.4f}, {vmax:.4f}]\")\n",
        "\n",
        "for idx, subject_id in enumerate(subject_ids):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    mask = subject_rdm_masks[subject_id]\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Create a masked array for visualization\n",
        "    # Use set_bad() to color NaN/masked values with white (highly visible)\n",
        "    rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "    cmap = plt.cm.get_cmap('viridis').copy()  # Get a copy to avoid modifying global colormap\n",
        "    cmap.set_bad(color='white', alpha=1.0)  # White for NA cells - highly visible\n",
        "    im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    \n",
        "    ax.set_title(f\"{subject_id}\\n({len(available_cats)}/{len(ordered_categories)} cats)\", fontsize=9, pad=5)\n",
        "    ax.set_xlabel('Category', fontsize=7)\n",
        "    ax.set_ylabel('Category', fontsize=7)\n",
        "    ax.tick_params(labelsize=6)\n",
        "    \n",
        "    # Set ticks and labels to show all categories in ordered_categories\n",
        "    ax.set_xticks(range(len(ordered_categories)))\n",
        "    ax.set_yticks(range(len(ordered_categories)))\n",
        "    # Show only every Nth label to avoid overlap\n",
        "    n_cats = len(ordered_categories)\n",
        "    if n_cats <= 50:\n",
        "        tick_step = 1\n",
        "    elif n_cats <= 100:\n",
        "        tick_step = 2\n",
        "    else:\n",
        "        tick_step = max(1, n_cats // 50)  # Show ~50 labels max\n",
        "    \n",
        "    ax.set_xticks(range(0, n_cats, tick_step))\n",
        "    ax.set_yticks(range(0, n_cats, tick_step))\n",
        "    ax.set_xticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                 rotation=90, ha='right', fontsize=8)\n",
        "    # Apply colors to visible labels based on CDI category\n",
        "    for label in ax.get_xticklabels():\n",
        "        cat_name = label.get_text()\n",
        "        if cat_name:\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n",
        "    ax.set_yticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                 fontsize=8)\n",
        "    # Apply colors to y-axis labels\n",
        "    for label in ax.get_yticklabels():\n",
        "        cat_name = label.get_text()\n",
        "        if cat_name:\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(n_subjects, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle(f'All Individual Subject RDMs (n={n_subjects})', fontsize=16, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"all_individual_rdms.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"\\nSaved all individual RDM visualization to {output_dir / 'all_individual_rdms.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Also create a version with coolwarm colormap\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "axes = axes.flatten() if n_subjects > 1 else [axes]\n",
        "\n",
        "for idx, subject_id in enumerate(subject_ids):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    mask = subject_rdm_masks[subject_id]\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Create a masked array for visualization\n",
        "    # Use set_bad() to color NaN/masked values with white (highly visible)\n",
        "    rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "    cmap = plt.cm.get_cmap('coolwarm').copy()  # Get a copy to avoid modifying global colormap\n",
        "    cmap.set_bad(color='white', alpha=1.0)  # White for NA cells - highly visible\n",
        "    im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    \n",
        "    ax.set_title(f\"{subject_id}\\n({len(available_cats)}/{len(ordered_categories)} cats)\", fontsize=9, pad=5)\n",
        "    ax.set_xlabel('Category', fontsize=7)\n",
        "    ax.set_ylabel('Category', fontsize=7)\n",
        "    ax.tick_params(labelsize=6)\n",
        "    \n",
        "    # Set ticks and labels to show all categories in ordered_categories\n",
        "    ax.set_xticks(range(len(ordered_categories)))\n",
        "    ax.set_yticks(range(len(ordered_categories)))\n",
        "    # Show only every Nth label to avoid overlap\n",
        "    n_cats = len(ordered_categories)\n",
        "    if n_cats <= 50:\n",
        "        tick_step = 1\n",
        "    elif n_cats <= 100:\n",
        "        tick_step = 2\n",
        "    else:\n",
        "        tick_step = max(1, n_cats // 50)  # Show ~50 labels max\n",
        "    \n",
        "    ax.set_xticks(range(0, n_cats, tick_step))\n",
        "    ax.set_yticks(range(0, n_cats, tick_step))\n",
        "    ax.set_xticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                 rotation=90, ha='right', fontsize=8)\n",
        "    # Apply colors to visible labels based on CDI category\n",
        "    for label in ax.get_xticklabels():\n",
        "        cat_name = label.get_text()\n",
        "        if cat_name:\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n",
        "    ax.set_yticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                 fontsize=8)\n",
        "    # Apply colors to y-axis labels\n",
        "    for label in ax.get_yticklabels():\n",
        "        cat_name = label.get_text()\n",
        "        if cat_name:\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# Hide unused subplots\n",
        "for idx in range(n_subjects, len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.suptitle(f'All Individual Subject RDMs (n={n_subjects}) - Coolwarm', fontsize=16, y=0.995)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "plt.savefig(output_dir / \"all_individual_rdms_coolwarm.png\", dpi=200, bbox_inches='tight')\n",
        "print(f\"Saved all individual RDM visualization (coolwarm) to {output_dir / 'all_individual_rdms_coolwarm.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Save each individual RDM separately with category names as axis labels\n",
        "print(\"\\nSaving individual RDM plots...\")\n",
        "individual_rdm_dir = output_dir / \"individual_rdm_plots\"\n",
        "individual_rdm_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Find global min/max for consistent color scale (excluding NaN)\n",
        "all_rdm_values = []\n",
        "for rdm in subject_rdms.values():\n",
        "    valid_values = rdm[~np.isnan(rdm)]\n",
        "    all_rdm_values.extend(valid_values)\n",
        "vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "\n",
        "for subject_id in tqdm(subject_rdms.keys(), desc=\"Saving individual RDMs\"):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    mask = subject_rdm_masks[subject_id]\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    # Determine figure size based on number of categories (use ordered_categories for size)\n",
        "    n_cats = len(ordered_categories)\n",
        "    fig_size = max(12, n_cats * 0.4)\n",
        "    \n",
        "    # Set font size for category labels (adaptive)\n",
        "    if n_cats <= 50:\n",
        "        label_fontsize = 12\n",
        "        tick_fontsize = 20\n",
        "    elif n_cats <= 100:\n",
        "        label_fontsize = 10\n",
        "        tick_fontsize = 18\n",
        "    else:\n",
        "        label_fontsize = 8\n",
        "        tick_fontsize = 16\n",
        "    \n",
        "    # Create figure with viridis colormap\n",
        "    fig, ax = plt.subplots(figsize=(fig_size, fig_size))\n",
        "    \n",
        "    # Create a masked array for visualization\n",
        "    # Use set_bad() to color NaN/masked values with white (highly visible)\n",
        "    rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "    cmap = plt.cm.get_cmap('viridis').copy()  # Get a copy to avoid modifying global colormap\n",
        "    cmap.set_bad(color='white', alpha=1.0)  # White for NA cells - highly visible\n",
        "    im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    \n",
        "    # Set category names as axis labels (use ordered_categories for all subjects)\n",
        "    ax.set_xticks(range(len(ordered_categories)))\n",
        "    ax.set_yticks(range(len(ordered_categories)))\n",
        "    # Show only every Nth label to avoid overlap\n",
        "    if n_cats <= 50:\n",
        "        tick_step = 1\n",
        "    elif n_cats <= 100:\n",
        "        tick_step = 2\n",
        "    else:\n",
        "        tick_step = max(1, n_cats // 60)  # Show ~60 labels max for individual plots\n",
        "    \n",
        "    ax.set_xticks(range(0, n_cats, tick_step))\n",
        "    ax.set_yticks(range(0, n_cats, tick_step))\n",
        "    ax.set_xticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                 rotation=90, ha='right', fontsize=max(8, tick_fontsize-2))\n",
        "    ax.set_yticklabels([ordered_categories[j] for j in range(0, n_cats, tick_step)], \n",
        "                                 fontsize=max(8, tick_fontsize-2))\n",
        "    \n",
        "    # Apply colors to visible labels based on CDI category\n",
        "    for label in ax.get_xticklabels():\n",
        "        cat_name = label.get_text()\n",
        "        if cat_name:\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n",
        "    for label in ax.get_yticklabels():\n",
        "        cat_name = label.get_text()\n",
        "        if cat_name:\n",
        "            color = get_category_color(cat_name, cdi_category_map)\n",
        "            label.set_color(color)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save RDMs\n",
        "print(\"Saving individual subject RDMs...\")\n",
        "for subject_id, rdm in tqdm(subject_rdms.items(), desc=\"Saving RDMs\"):\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    # Save as numpy array (includes NaN for missing categories) - save to npy subdirectory\n",
        "    np.save(npy_dir / f\"rdm_{subject_id}.npy\", rdm)\n",
        "    \n",
        "    # Save as CSV with category labels (use ordered_categories for consistent ordering) - save to csv subdirectory\n",
        "    rdm_df = pd.DataFrame(rdm, index=ordered_categories, columns=ordered_categories)\n",
        "    rdm_df.to_csv(csv_dir / f\"rdm_{subject_id}.csv\")\n",
        "    \n",
        "    # Save metadata - save to csv subdirectory\n",
        "    # Compute statistics only on valid (non-NaN) values\n",
        "    valid_rdm = rdm[~np.isnan(rdm)]\n",
        "    valid_rdm_positive = valid_rdm[valid_rdm > 0]\n",
        "    \n",
        "    metadata = {\n",
        "        'subject_id': subject_id,\n",
        "        'n_categories_total': len(ordered_categories),\n",
        "        'n_categories_available': len(available_cats),\n",
        "        'n_categories_missing': len(ordered_categories) - len(available_cats),\n",
        "        'mean_distance': float(np.nanmean(rdm)),\n",
        "        'std_distance': float(np.nanstd(rdm)),\n",
        "        'min_distance': float(valid_rdm_positive.min()) if len(valid_rdm_positive) > 0 else np.nan,\n",
        "        'max_distance': float(np.nanmax(rdm))\n",
        "    }\n",
        "    \n",
        "    metadata_df = pd.DataFrame([metadata])\n",
        "    metadata_df.to_csv(csv_dir / f\"metadata_{subject_id}.csv\", index=False)\n",
        "\n",
        "print(f\"\\nSaved RDMs to {output_dir}\")\n",
        "print(f\"  CSV files: {csv_dir}\")\n",
        "print(f\"  NPY files: {npy_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary dataframe\n",
        "summary_data = []\n",
        "for subject_id, rdm in subject_rdms.items():\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    # Compute statistics only on valid (non-NaN) values\n",
        "    valid_rdm = rdm[~np.isnan(rdm)]\n",
        "    valid_rdm_positive = valid_rdm[valid_rdm > 0]\n",
        "    \n",
        "    summary_data.append({\n",
        "        'subject_id': subject_id,\n",
        "        'n_categories_total': len(ordered_categories),\n",
        "        'n_categories_available': len(available_cats),\n",
        "        'n_categories_missing': len(ordered_categories) - len(available_cats),\n",
        "        'mean_distance': float(np.nanmean(rdm)),\n",
        "        'std_distance': float(np.nanstd(rdm)),\n",
        "        'min_distance': float(valid_rdm_positive.min()) if len(valid_rdm_positive) > 0 else np.nan,\n",
        "        'max_distance': float(np.nanmax(rdm))\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df = summary_df.sort_values('n_categories_available', ascending=False)\n",
        "summary_df.to_csv(csv_dir / \"summary_statistics.csv\", index=False)\n",
        "\n",
        "print(\"Summary statistics:\")\n",
        "print(summary_df.describe())\n",
        "print(f\"\\nSaved summary to {csv_dir / 'summary_statistics.csv'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Sample RDMs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a few sample RDMs\n",
        "n_samples = min(6, len(subject_rdms))\n",
        "sample_subjects = list(subject_rdms.keys())[:n_samples]\n",
        "\n",
        "# Find global min/max for consistent color scale (excluding NaN)\n",
        "all_rdm_values = []\n",
        "for rdm in [subject_rdms[sid] for sid in sample_subjects]:\n",
        "    valid_values = rdm[~np.isnan(rdm)]\n",
        "    if len(valid_values) > 0:\n",
        "        all_rdm_values.extend(valid_values)\n",
        "vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, subject_id in enumerate(sample_subjects):\n",
        "    rdm = subject_rdms[subject_id]\n",
        "    mask = subject_rdm_masks[subject_id]\n",
        "    available_cats = subject_rdm_categories[subject_id]\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Create a masked array for visualization\n",
        "    # Use set_bad() to color NaN/masked values with white (highly visible)\n",
        "    rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "    cmap = plt.cm.get_cmap('viridis').copy()  # Get a copy to avoid modifying global colormap\n",
        "    cmap.set_bad(color='white', alpha=1.0)  # White for NA cells - highly visible\n",
        "    im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "    \n",
        "    ax.set_title(f\"{subject_id}\\n({len(available_cats)}/{len(ordered_categories)} cats)\", fontsize=10)\n",
        "    ax.set_xlabel('Category')\n",
        "    ax.set_ylabel('Category')\n",
        "    plt.colorbar(im, ax=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"sample_rdms.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved sample RDM visualization to {output_dir / 'sample_rdms.png'}\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Density Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze data density across subjects\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Category count distribution\n",
        "axes[0].hist([len(cats) for cats in subject_rdm_categories.values()], bins=20, edgecolor='black')\n",
        "axes[0].set_xlabel('Number of Categories per Subject')\n",
        "axes[0].set_ylabel('Number of Subjects')\n",
        "axes[0].set_title('Data Density: Categories per Subject')\n",
        "axes[0].axvline(min_categories_per_subject, color='red', linestyle='--', label=f'Min threshold ({min_categories_per_subject})')\n",
        "axes[0].legend()\n",
        "\n",
        "# Mean distance vs category count\n",
        "mean_distances = [np.nanmean(subject_rdms[sid]) for sid in subject_rdms.keys()]\n",
        "n_categories = [len(subject_rdm_categories[sid]) for sid in subject_rdms.keys()]\n",
        "axes[1].scatter(n_categories, mean_distances, alpha=0.6)\n",
        "axes[1].set_xlabel('Number of Categories')\n",
        "axes[1].set_ylabel('Mean RDM Distance')\n",
        "axes[1].set_title('RDM Distance vs Data Density')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"data_density_analysis.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved data density analysis to {output_dir / 'data_density_analysis.png'}\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Category Intersection Analysis\n",
        "\n",
        "This section analyzes which categories are shared across subjects and helps determine which subjects and categories to include for intersection-based analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze category intersections across subjects\n",
        "print(\"Analyzing category intersections...\")\n",
        "\n",
        "# Get all subject category sets\n",
        "subject_category_sets = {sid: set(cats) for sid, cats in subject_rdm_categories.items()}\n",
        "\n",
        "# Compute category counts across all subjects (do this once)\n",
        "category_counts = {}\n",
        "for sid, cat_set in subject_category_sets.items():\n",
        "    for cat in cat_set:\n",
        "        category_counts[cat] = category_counts.get(cat, 0) + 1\n",
        "\n",
        "# Compute intersections for different numbers of subjects\n",
        "# For each n, find categories that appear in at least n subjects\n",
        "n_subjects_total = len(subject_category_sets)\n",
        "intersection_analysis = []\n",
        "\n",
        "for n in range(1, n_subjects_total + 1):\n",
        "    # Categories that appear in at least n subjects\n",
        "    intersecting_cats = [cat for cat, count in category_counts.items() if count >= n]\n",
        "    intersection_analysis.append({\n",
        "        'n_subjects': n,\n",
        "        'intersection_size': len(intersecting_cats),\n",
        "        'categories': intersecting_cats\n",
        "    })\n",
        "\n",
        "# Create DataFrame for easier analysis\n",
        "intersection_df = pd.DataFrame(intersection_analysis)\n",
        "\n",
        "print(f\"\\nIntersection Analysis:\")\n",
        "print(f\"  Total subjects: {n_subjects_total}\")\n",
        "print(f\"\\nIntersection sizes by number of subjects:\")\n",
        "for _, row in intersection_df.iterrows():\n",
        "    print(f\"  {row['n_subjects']:2d} subjects: {row['intersection_size']:3d} categories\")\n",
        "\n",
        "# Plot: Number of subjects vs intersection size\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(intersection_df['n_subjects'], intersection_df['intersection_size'], \n",
        "        marker='o', linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Number of Subjects (Minimum)', fontsize=12)\n",
        "ax.set_ylabel('Intersection Size (Number of Categories)', fontsize=12)\n",
        "ax.set_title('Category Intersection Analysis\\n(Number of Categories Shared by at Least N Subjects)', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xticks(range(1, n_subjects_total + 1))\n",
        "\n",
        "# Add annotations for key points\n",
        "for n in [1, n_subjects_total // 2, n_subjects_total]:\n",
        "    if n <= n_subjects_total:\n",
        "        row = intersection_df[intersection_df['n_subjects'] == n].iloc[0]\n",
        "        ax.annotate(f\"{row['intersection_size']} cats\", \n",
        "                   xy=(n, row['intersection_size']),\n",
        "                   xytext=(5, 5), textcoords='offset points',\n",
        "                   fontsize=9, bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"category_intersection_analysis.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"\\nSaved intersection analysis plot to {output_dir / 'category_intersection_analysis.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Save intersection data\n",
        "intersection_df.to_csv(csv_dir / \"category_intersection_analysis.csv\", index=False)\n",
        "print(f\"Saved intersection data to {csv_dir / 'category_intersection_analysis.csv'}\")\n",
        "\n",
        "# Display intersection sizes for different thresholds\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Recommended thresholds for intersection-based analysis:\")\n",
        "print(\"=\"*60)\n",
        "for threshold in [n_subjects_total, int(n_subjects_total * 0.9), int(n_subjects_total * 0.8), \n",
        "                  int(n_subjects_total * 0.7), int(n_subjects_total * 0.5)]:\n",
        "    if threshold <= n_subjects_total:\n",
        "        row = intersection_df[intersection_df['n_subjects'] == threshold].iloc[0]\n",
        "        print(f\"  At least {threshold:2d} subjects ({threshold/n_subjects_total*100:.1f}%): {row['intersection_size']:3d} categories\")\n",
        "\n",
        "# ====================================================================\n",
        "# INVERSE ANALYSIS: For a given number of categories X, find maximum number of subjects N\n",
        "# where all N subjects have all X categories, and N = threshold\n",
        "# ====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INVERSE ANALYSIS: Maximum Subjects for Given Category Count\")\n",
        "print(\"=\"*60)\n",
        "print(\"For each number of categories X, find the maximum number of subjects N\")\n",
        "print(\"where all N subjects have all X overlapping categories.\")\n",
        "print(\"We ensure N = threshold, meaning all X categories appear in exactly N subjects.\\n\")\n",
        "\n",
        "# Get unique category counts from intersection_df\n",
        "unique_category_counts = sorted(intersection_df['intersection_size'].unique(), reverse=True)\n",
        "\n",
        "# Store results\n",
        "inverse_analysis = []\n",
        "inverse_analysis_tight = []  # Cases where N = threshold\n",
        "\n",
        "for n_categories in unique_category_counts:\n",
        "    # Strategy: Find thresholds where we get exactly n_categories\n",
        "    # AND where the number of subjects with all categories equals the threshold\n",
        "    exact_match = intersection_df[intersection_df['intersection_size'] == n_categories]\n",
        "    \n",
        "    best_n_subjects = 0\n",
        "    best_threshold = None\n",
        "    best_categories = None\n",
        "    best_subjects = None\n",
        "    \n",
        "    # Try all thresholds that give us exactly n_categories\n",
        "    for _, row in exact_match.iterrows():\n",
        "        threshold = row['n_subjects']\n",
        "        target_categories = set(row['categories'])\n",
        "        \n",
        "        # Find all subjects that have ALL target_categories\n",
        "        subjects_with_all_cats = []\n",
        "        for subject_id, subject_cats in subject_category_sets.items():\n",
        "            if target_categories.issubset(subject_cats):\n",
        "                subjects_with_all_cats.append(subject_id)\n",
        "        \n",
        "        n_subjects = len(subjects_with_all_cats)\n",
        "        \n",
        "        # Track the best (maximum N)\n",
        "        if n_subjects > best_n_subjects:\n",
        "            best_n_subjects = n_subjects\n",
        "            best_threshold = threshold\n",
        "            best_categories = target_categories\n",
        "            best_subjects = subjects_with_all_cats\n",
        "    \n",
        "    # If no exact match, try to find a subset\n",
        "    if best_threshold is None:\n",
        "        candidate_rows = intersection_df[intersection_df['intersection_size'] >= n_categories]\n",
        "        if len(candidate_rows) > 0:\n",
        "            # Try the threshold with maximum n_subjects that gives us at least n_categories\n",
        "            min_threshold_row = candidate_rows.loc[candidate_rows['n_subjects'].idxmin()]\n",
        "            threshold = min_threshold_row['n_subjects']\n",
        "            all_candidate_cats = min_threshold_row['categories']\n",
        "            # Take first n_categories (this is a heuristic - could be improved)\n",
        "            target_categories = set(all_candidate_cats[:n_categories])\n",
        "            \n",
        "            subjects_with_all_cats = []\n",
        "            for subject_id, subject_cats in subject_category_sets.items():\n",
        "                if target_categories.issubset(subject_cats):\n",
        "                    subjects_with_all_cats.append(subject_id)\n",
        "            \n",
        "            best_n_subjects = len(subjects_with_all_cats)\n",
        "            best_threshold = threshold\n",
        "            best_categories = target_categories\n",
        "            best_subjects = subjects_with_all_cats\n",
        "    \n",
        "    if best_threshold is None:\n",
        "        continue\n",
        "    \n",
        "    # Check if N = threshold (tight match)\n",
        "    is_tight = (best_n_subjects == best_threshold)\n",
        "    \n",
        "    inverse_analysis.append({\n",
        "        'n_categories': n_categories,\n",
        "        'n_subjects': best_n_subjects,\n",
        "        'threshold_used': best_threshold,\n",
        "        'n_equals_threshold': is_tight,\n",
        "        'categories': sorted(list(best_categories)),\n",
        "        'subject_ids': sorted(best_subjects)\n",
        "    })\n",
        "    \n",
        "    if is_tight:\n",
        "        inverse_analysis_tight.append({\n",
        "            'n_categories': n_categories,\n",
        "            'n_subjects': best_n_subjects,\n",
        "            'threshold': best_threshold,\n",
        "            'categories': sorted(list(best_categories)),\n",
        "            'subject_ids': sorted(best_subjects)\n",
        "        })\n",
        "        print(f\"  X={n_categories:3d} categories → N={best_n_subjects:2d} subjects (threshold={best_threshold:2d}) ✓ N=threshold\")\n",
        "    else:\n",
        "        print(f\"  X={n_categories:3d} categories → N={best_n_subjects:2d} subjects (threshold={best_threshold:2d}) [N≠threshold]\")\n",
        "\n",
        "# Create DataFrame\n",
        "inverse_df = pd.DataFrame(inverse_analysis)\n",
        "\n",
        "# Save to CSV\n",
        "inverse_df_expanded = inverse_df.copy()\n",
        "# Convert lists to strings for CSV\n",
        "inverse_df_expanded['categories'] = inverse_df_expanded['categories'].apply(lambda x: ', '.join(x))\n",
        "inverse_df_expanded['subject_ids'] = inverse_df_expanded['subject_ids'].apply(lambda x: ', '.join(x))\n",
        "inverse_df_expanded.to_csv(csv_dir / \"inverse_intersection_analysis.csv\", index=False)\n",
        "print(f\"\\nSaved inverse analysis data to {csv_dir / 'inverse_intersection_analysis.csv'}\")\n",
        "\n",
        "# Show cases where N = threshold (tight matches)\n",
        "if len(inverse_analysis_tight) > 0:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TIGHT MATCHES: Cases where N = threshold\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"These are cases where all X categories appear in exactly N subjects,\")\n",
        "    print(\"and all N subjects have all X categories (N = threshold).\\n\")\n",
        "    \n",
        "    tight_df = pd.DataFrame(inverse_analysis_tight)\n",
        "    print(f\"{'Categories (X)':<15} {'Subjects (N)':<15} {'All subjects have same X categories':<35}\")\n",
        "    print(\"-\"*65)\n",
        "    for _, row in tight_df.iterrows():\n",
        "        print(f\"{row['n_categories']:<15} {int(row['n_subjects']):<15} {'Yes ✓':<35}\")\n",
        "    \n",
        "    # Save tight matches separately\n",
        "    tight_df_expanded = tight_df.copy()\n",
        "    tight_df_expanded['categories'] = tight_df_expanded['categories'].apply(lambda x: ', '.join(x))\n",
        "    tight_df_expanded['subject_ids'] = tight_df_expanded['subject_ids'].apply(lambda x: ', '.join(x))\n",
        "    tight_df_expanded.to_csv(csv_dir / \"inverse_intersection_analysis_tight_matches.csv\", index=False)\n",
        "    print(f\"\\nSaved tight matches (N=threshold) to {csv_dir / 'inverse_intersection_analysis_tight_matches.csv'}\")\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"No tight matches found (N = threshold)\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"For all category counts, the number of subjects with all categories\")\n",
        "    print(\"is less than the threshold used to define those categories.\")\n",
        "\n",
        "# Plot: Number of categories vs maximum number of subjects\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Plot all points\n",
        "ax.plot(inverse_df['n_categories'], inverse_df['n_subjects'], \n",
        "        marker='o', linewidth=2, markersize=6, label='Max subjects with all X categories', alpha=0.5)\n",
        "\n",
        "# Highlight tight matches (N = threshold)\n",
        "tight_mask = inverse_df['n_equals_threshold'] == True\n",
        "if tight_mask.any():\n",
        "    tight_data = inverse_df[tight_mask]\n",
        "    ax.scatter(tight_data['n_categories'], tight_data['n_subjects'], \n",
        "              marker='*', s=200, color='red', label='N = threshold (tight match)', zorder=5)\n",
        "\n",
        "ax.set_xlabel('Number of Overlapping Categories (X)', fontsize=12)\n",
        "ax.set_ylabel('Maximum Number of Subjects (N)', fontsize=12)\n",
        "ax.set_title('Inverse Intersection Analysis\\n(Maximum Subjects N for Given Category Count X)', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend()\n",
        "\n",
        "# Add annotations for key points\n",
        "for idx, row in inverse_df.iterrows():\n",
        "    if row['n_categories'] in [81, 99, 120, 126, 137, 140, 144, 147, 150, 153, 155, 158, 160, 163]:\n",
        "        marker = '✓' if row['n_equals_threshold'] else ''\n",
        "        ax.annotate(f\"N={int(row['n_subjects'])}{marker}\", \n",
        "                   xy=(row['n_categories'], row['n_subjects']),\n",
        "                   xytext=(5, 5), textcoords='offset points',\n",
        "                   fontsize=8, rotation=45, ha='left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"inverse_intersection_analysis.png\", dpi=150, bbox_inches='tight')\n",
        "print(f\"Saved inverse analysis plot to {output_dir / 'inverse_intersection_analysis.png'}\")\n",
        "plt.close()\n",
        "\n",
        "# Create a summary table for easy reference\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Summary: Maximum Subjects for Given Category Counts\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Categories (X)':<15} {'Max Subjects (N)':<18} {'Threshold':<12} {'N=threshold?':<12}\")\n",
        "print(\"-\"*60)\n",
        "for _, row in inverse_df.iterrows():\n",
        "    match_marker = \"✓ Yes\" if row['n_equals_threshold'] else \"No\"\n",
        "    print(f\"{row['n_categories']:<15} {int(row['n_subjects']):<18} {int(row['threshold_used']):<12} {match_marker:<12}\")\n",
        "\n",
        "# Also create a reverse lookup: for common category counts, show max subjects\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Quick Reference: Common Category Counts\")\n",
        "print(\"=\"*60)\n",
        "common_counts = [148, 150, 140, 120, 100, 81]\n",
        "for x in common_counts:\n",
        "    matching = inverse_df[inverse_df['n_categories'] == x]\n",
        "    if len(matching) > 0:\n",
        "        row = matching.iloc[0]\n",
        "        print(f\"  X={x:3d} categories → N={int(row['n_subjects']):2d} subjects\")\n",
        "    else:\n",
        "        # Find closest\n",
        "        closest = inverse_df.iloc[(inverse_df['n_categories'] - x).abs().argsort()[:1]]\n",
        "        if len(closest) > 0:\n",
        "            row = closest.iloc[0]\n",
        "            print(f\"  X={x:3d} categories → N={int(row['n_subjects']):2d} subjects (closest: {int(row['n_categories'])} categories)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RDMs with Intersecting Categories Only\n",
        "\n",
        "This section computes and visualizes RDMs using only the categories that are shared across all (or a specified subset of) subjects, maintaining consistent category ordering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for intersection-based RDMs\n",
        "# Set minimum number of subjects that must have a category for it to be included\n",
        "# Can be a single value or a list of values to iterate through\n",
        "MIN_SUBJECTS_FOR_CATEGORY = list(range(20, n_subjects_total + 1))  # 20+ subjects\n",
        "# Examples:\n",
        "# MIN_SUBJECTS_FOR_CATEGORY = [20, 24, 27, 31]  # Specific thresholds\n",
        "# MIN_SUBJECTS_FOR_CATEGORY = n_subjects_total  # Single value (all subjects)\n",
        "# MIN_SUBJECTS_FOR_CATEGORY = list(range(20, n_subjects_total + 1))  # All thresholds from 20 to total\n",
        "\n",
        "# Convert single value to list for uniform handling\n",
        "if not isinstance(MIN_SUBJECTS_FOR_CATEGORY, list):\n",
        "    MIN_SUBJECTS_FOR_CATEGORY = [MIN_SUBJECTS_FOR_CATEGORY]\n",
        "\n",
        "print(f\"Computing intersection-based RDMs for {len(MIN_SUBJECTS_FOR_CATEGORY)} threshold(s)...\")\n",
        "print(f\"  Thresholds: {MIN_SUBJECTS_FOR_CATEGORY}\")\n",
        "\n",
        "# Store RDMs for each threshold\n",
        "all_intersection_rdms = {}  # {threshold: {subject_id: rdm}}\n",
        "all_intersection_masks = {}  # {threshold: {subject_id: mask}}\n",
        "all_intersection_categories = {}  # {threshold: {subject_id: available_cats}}\n",
        "all_intersection_category_lists = {}  # {threshold: intersecting_categories_ordered}\n",
        "\n",
        "# Iterate through each threshold\n",
        "for min_subjects in MIN_SUBJECTS_FOR_CATEGORY:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing threshold: {min_subjects} subjects\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Get the intersecting categories for this threshold\n",
        "    if min_subjects not in intersection_df['n_subjects'].values:\n",
        "        print(f\"  Warning: Threshold {min_subjects} not found in intersection_df. Skipping.\")\n",
        "        continue\n",
        "    \n",
        "    intersection_row = intersection_df[intersection_df['n_subjects'] == min_subjects].iloc[0]\n",
        "    intersecting_categories = intersection_row['categories']\n",
        "    \n",
        "    print(f\"  Intersecting categories: {len(intersecting_categories)}\")\n",
        "    \n",
        "    # Filter ordered_categories to only include intersecting categories (maintain order)\n",
        "    intersecting_categories_ordered = [cat for cat in ordered_categories if cat in intersecting_categories]\n",
        "    \n",
        "    print(f\"  Intersecting categories (ordered): {len(intersecting_categories_ordered)}\")\n",
        "    \n",
        "    # Compute RDMs using only intersecting categories\n",
        "    subject_rdms_intersection = {}\n",
        "    subject_rdm_masks_intersection = {}\n",
        "    subject_rdm_categories_intersection = {}\n",
        "    \n",
        "    for subject_id in tqdm(subject_rdms.keys(), desc=f\"Computing RDMs (threshold={min_subjects})\"):\n",
        "        # Get available categories for this subject that are in the intersection\n",
        "        # Only include subjects that have ALL intersecting categories\n",
        "        available_cats = [cat for cat in intersecting_categories_ordered \n",
        "                         if cat in subject_rdm_categories[subject_id]]\n",
        "        \n",
        "        # Only include subjects with all intersecting categories\n",
        "        if len(available_cats) < len(intersecting_categories_ordered):\n",
        "            continue\n",
        "        \n",
        "        # Get embeddings for intersecting categories\n",
        "        subject_embeddings = subject_embeddings_normalized[subject_id]\n",
        "        intersection_embeddings = {cat: subject_embeddings[cat] for cat in available_cats}\n",
        "        \n",
        "        # Compute RDM with NA for missing categories in intersection\n",
        "        rdm, mask, _ = compute_subject_rdm_with_na(intersection_embeddings, intersecting_categories_ordered)\n",
        "        \n",
        "        if rdm is not None:\n",
        "            subject_rdms_intersection[subject_id] = rdm\n",
        "            subject_rdm_masks_intersection[subject_id] = mask\n",
        "            subject_rdm_categories_intersection[subject_id] = available_cats\n",
        "    \n",
        "    print(f\"  Computed intersection-based RDMs for {len(subject_rdms_intersection)} subjects\")\n",
        "    print(f\"    (Excluded {len(subject_rdms) - len(subject_rdms_intersection)} subjects without all intersecting categories)\")\n",
        "    \n",
        "    # Check which subjects were excluded\n",
        "    excluded_subjects = set(subject_rdms.keys()) - set(subject_rdms_intersection.keys())\n",
        "    if excluded_subjects:\n",
        "        print(f\"    Excluded subjects: {sorted(excluded_subjects)}\")\n",
        "    \n",
        "    # Store results for this threshold\n",
        "    all_intersection_rdms[min_subjects] = subject_rdms_intersection\n",
        "    all_intersection_masks[min_subjects] = subject_rdm_masks_intersection\n",
        "    all_intersection_categories[min_subjects] = subject_rdm_categories_intersection\n",
        "    all_intersection_category_lists[min_subjects] = intersecting_categories_ordered\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Completed processing {len(all_intersection_rdms)} threshold(s)\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize all intersection-based RDMs for each threshold\n",
        "# Iterate through each threshold\n",
        "for min_subjects in sorted(all_intersection_rdms.keys()):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Visualizing RDMs for threshold: {min_subjects} subjects\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    subject_rdms_intersection = all_intersection_rdms[min_subjects]\n",
        "    subject_rdm_masks_intersection = all_intersection_masks[min_subjects]\n",
        "    subject_rdm_categories_intersection = all_intersection_categories[min_subjects]\n",
        "    intersecting_categories_ordered = all_intersection_category_lists[min_subjects]\n",
        "    \n",
        "    n_subjects_intersection = len(subject_rdms_intersection)\n",
        "    subject_ids_intersection = list(subject_rdms_intersection.keys())\n",
        "    \n",
        "    if n_subjects_intersection > 0:\n",
        "        # Calculate grid dimensions\n",
        "        n_cols = 6\n",
        "        n_rows = int(np.ceil(n_subjects_intersection / n_cols))\n",
        "        \n",
        "        # Create figure with appropriate size\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "        # Handle axes flattening properly (works for both 1D and 2D arrays)\n",
        "        if n_rows == 1:\n",
        "            axes = axes if isinstance(axes, np.ndarray) else [axes]\n",
        "        else:\n",
        "            axes = axes.flatten()\n",
        "        \n",
        "        # Find global min/max for consistent color scale across all RDMs (excluding NaN)\n",
        "        all_rdm_values = []\n",
        "        for rdm in subject_rdms_intersection.values():\n",
        "            valid_values = rdm[~np.isnan(rdm)]\n",
        "            if len(valid_values) > 0:\n",
        "                all_rdm_values.extend(valid_values)\n",
        "        vmin = np.percentile(all_rdm_values, 1) if len(all_rdm_values) > 0 else 0\n",
        "        vmax = np.percentile(all_rdm_values, 99) if len(all_rdm_values) > 0 else 2\n",
        "        \n",
        "        print(f\"Plotting {n_subjects_intersection} intersection-based RDMs...\")\n",
        "        print(f\"Color scale range: [{vmin:.4f}, {vmax:.4f}]\")\n",
        "        print(f\"Categories in intersection: {len(intersecting_categories_ordered)}\")\n",
        "        \n",
        "        for idx, subject_id in enumerate(subject_ids_intersection):\n",
        "            rdm = subject_rdms_intersection[subject_id]\n",
        "            mask = subject_rdm_masks_intersection[subject_id]\n",
        "            available_cats = subject_rdm_categories_intersection[subject_id]\n",
        "            \n",
        "            ax = axes[idx]\n",
        "            \n",
        "            # Create a masked array for visualization\n",
        "            rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "            cmap = plt.cm.get_cmap('viridis').copy()\n",
        "            cmap.set_bad(color='white', alpha=1.0)\n",
        "            im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "            \n",
        "            ax.set_title(f\"{subject_id}\\n({len(available_cats)}/{len(intersecting_categories_ordered)} cats)\", \n",
        "                        fontsize=9, pad=5)\n",
        "            ax.set_xlabel('Category', fontsize=7)\n",
        "            ax.set_ylabel('Category', fontsize=7)\n",
        "            ax.tick_params(labelsize=6)\n",
        "            \n",
        "            # Set ticks and labels to show all intersecting categories\n",
        "            ax.set_xticks(range(len(intersecting_categories_ordered)))\n",
        "            ax.set_yticks(range(len(intersecting_categories_ordered)))\n",
        "            ax.set_xticklabels(intersecting_categories_ordered, rotation=90, ha='right', fontsize=6)\n",
        "            ax.set_yticklabels(intersecting_categories_ordered, fontsize=6)\n",
        "            \n",
        "            # Add colorbar for each subplot\n",
        "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "        \n",
        "        # Hide unused subplots\n",
        "        for idx in range(n_subjects_intersection, len(axes)):\n",
        "            axes[idx].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'Intersection-Based RDMs (n={n_subjects_intersection}, {len(intersecting_categories_ordered)} shared categories, threshold={min_subjects})', \n",
        "                    fontsize=16, y=0.995)\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "        output_filename = f\"all_individual_rdms_intersection_threshold_{min_subjects}.png\"\n",
        "        plt.savefig(output_dir / output_filename, dpi=200, bbox_inches='tight')\n",
        "        print(f\"\\nSaved intersection-based RDM visualization to {output_dir / output_filename}\")\n",
        "        plt.close()\n",
        "        \n",
        "        # Also create a version with coolwarm colormap\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
        "        # Handle axes flattening properly (works for both 1D and 2D arrays)\n",
        "        if n_rows == 1:\n",
        "            axes = axes if isinstance(axes, np.ndarray) else [axes]\n",
        "        else:\n",
        "            axes = axes.flatten()\n",
        "        \n",
        "        for idx, subject_id in enumerate(subject_ids_intersection):\n",
        "            rdm = subject_rdms_intersection[subject_id]\n",
        "            mask = subject_rdm_masks_intersection[subject_id]\n",
        "            available_cats = subject_rdm_categories_intersection[subject_id]\n",
        "            \n",
        "            ax = axes[idx]\n",
        "            \n",
        "            rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "            cmap = plt.cm.get_cmap('coolwarm').copy()\n",
        "            cmap.set_bad(color='white', alpha=1.0)\n",
        "            im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "            \n",
        "            ax.set_title(f\"{subject_id}\\n({len(available_cats)}/{len(intersecting_categories_ordered)} cats)\", \n",
        "                        fontsize=9, pad=5)\n",
        "            ax.set_xlabel('Category', fontsize=7)\n",
        "            ax.set_ylabel('Category', fontsize=7)\n",
        "            ax.tick_params(labelsize=6)\n",
        "            \n",
        "            ax.set_xticks(range(len(intersecting_categories_ordered)))\n",
        "            ax.set_yticks(range(len(intersecting_categories_ordered)))\n",
        "            ax.set_xticklabels(intersecting_categories_ordered, rotation=90, ha='right', fontsize=6)\n",
        "            ax.set_yticklabels(intersecting_categories_ordered, fontsize=6)\n",
        "            \n",
        "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "        \n",
        "        # Hide unused subplots\n",
        "        for idx in range(n_subjects_intersection, len(axes)):\n",
        "            axes[idx].axis('off')\n",
        "        \n",
        "        plt.suptitle(f'Intersection-Based RDMs (n={n_subjects_intersection}, threshold={min_subjects}) - Coolwarm', \n",
        "                    fontsize=16, y=0.995)\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
        "        output_filename = f\"all_individual_rdms_intersection_threshold_{min_subjects}_coolwarm.png\"\n",
        "        plt.savefig(output_dir / output_filename, dpi=200, bbox_inches='tight')\n",
        "        print(f\"Saved intersection-based RDM visualization (coolwarm) to {output_dir / output_filename}\")\n",
        "        plt.close()\n",
        "        \n",
        "        # Save individual intersection-based RDMs\n",
        "        print(f\"\\nSaving individual intersection-based RDM plots for threshold {min_subjects}...\")\n",
        "        intersection_rdm_dir = output_dir / f\"individual_rdm_plots_intersection_threshold_{min_subjects}\"\n",
        "        intersection_rdm_dir.mkdir(exist_ok=True, parents=True)\n",
        "        \n",
        "        for subject_id in tqdm(subject_rdms_intersection.keys(), desc=f\"Saving intersection RDMs (threshold={min_subjects})\"):\n",
        "            rdm = subject_rdms_intersection[subject_id]\n",
        "            mask = subject_rdm_masks_intersection[subject_id]\n",
        "            available_cats = subject_rdm_categories_intersection[subject_id]\n",
        "            \n",
        "            # Determine figure size\n",
        "            n_cats = len(intersecting_categories_ordered)\n",
        "            fig_size = max(10, n_cats * 0.3)\n",
        "            \n",
        "            # Set font size\n",
        "            if n_cats <= 50:\n",
        "                label_fontsize = 12\n",
        "                tick_fontsize = 20\n",
        "            elif n_cats <= 100:\n",
        "                label_fontsize = 10\n",
        "                tick_fontsize = 18\n",
        "            else:\n",
        "                label_fontsize = 8\n",
        "                tick_fontsize = 16\n",
        "            \n",
        "            # Create figure\n",
        "            fig, ax = plt.subplots(figsize=(fig_size, fig_size))\n",
        "            \n",
        "            rdm_masked = np.ma.masked_where(mask, rdm)\n",
        "            cmap = plt.cm.get_cmap('viridis').copy()\n",
        "            cmap.set_bad(color='white', alpha=1.0)\n",
        "            im = ax.imshow(rdm_masked, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
        "            \n",
        "            ax.set_xticks(range(len(intersecting_categories_ordered)))\n",
        "            ax.set_yticks(range(len(intersecting_categories_ordered)))\n",
        "            ax.set_xticklabels(intersecting_categories_ordered, rotation=90, ha='right', fontsize=tick_fontsize)\n",
        "            ax.set_yticklabels(intersecting_categories_ordered, fontsize=tick_fontsize)\n",
        "            \n",
        "            ax.set_xlabel('Category', fontsize=label_fontsize)\n",
        "            ax.set_ylabel('Category', fontsize=label_fontsize)\n",
        "            ax.set_title(f'RDM (Intersection, threshold={min_subjects}): {subject_id}\\n({len(available_cats)}/{n_cats} categories)', \n",
        "                        fontsize=14, pad=10)\n",
        "            \n",
        "            cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "            cbar.set_label('Distance (1 - Cosine Similarity)', fontsize=12)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            \n",
        "            output_path_png = intersection_rdm_dir / f\"rdm_intersection_threshold_{min_subjects}_{subject_id}.png\"\n",
        "            plt.savefig(output_path_png, dpi=200, bbox_inches='tight')\n",
        "            plt.close()\n",
        "        \n",
        "        print(f\"\\nSaved {len(subject_rdms_intersection)} intersection-based RDM plots to {intersection_rdm_dir}\")\n",
        "        \n",
        "        # Save intersection-based RDMs as files\n",
        "        # Get number of overlapping categories for this threshold\n",
        "        n_overlapping_cats = len(intersecting_categories_ordered)\n",
        "        print(f\"\\nSaving intersection-based RDMs to files for threshold {min_subjects} (n_categories={n_overlapping_cats})...\")\n",
        "        for subject_id, rdm in tqdm(subject_rdms_intersection.items(), desc=f\"Saving RDMs (threshold={min_subjects})\"):\n",
        "            available_cats = subject_rdm_categories_intersection[subject_id]\n",
        "            \n",
        "            # Save as numpy array - include threshold and number of overlapping categories in filename\n",
        "            np.save(npy_dir / f\"rdm_intersection_threshold_{min_subjects}_ncat{n_overlapping_cats}_{subject_id}.npy\", rdm)\n",
        "            \n",
        "            # Save as CSV - include threshold and number of overlapping categories in filename\n",
        "            rdm_df = pd.DataFrame(rdm, index=intersecting_categories_ordered, columns=intersecting_categories_ordered)\n",
        "            rdm_df.to_csv(csv_dir / f\"rdm_intersection_threshold_{min_subjects}_ncat{n_overlapping_cats}_{subject_id}.csv\")\n",
        "            \n",
        "            # Save metadata - include threshold and number of overlapping categories in filename\n",
        "            valid_rdm = rdm[~np.isnan(rdm)]\n",
        "            valid_rdm_positive = valid_rdm[valid_rdm > 0]\n",
        "            \n",
        "            metadata = {\n",
        "                'subject_id': subject_id,\n",
        "                'threshold_min_subjects': min_subjects,\n",
        "                'n_categories_total': len(intersecting_categories_ordered),\n",
        "                'n_categories_available': len(available_cats),\n",
        "                'n_categories_missing': len(intersecting_categories_ordered) - len(available_cats),\n",
        "                'mean_distance': float(np.nanmean(rdm)),\n",
        "                'std_distance': float(np.nanstd(rdm)),\n",
        "                'min_distance': float(valid_rdm_positive.min()) if len(valid_rdm_positive) > 0 else np.nan,\n",
        "                'max_distance': float(np.nanmax(rdm))\n",
        "            }\n",
        "            \n",
        "            metadata_df = pd.DataFrame([metadata])\n",
        "            metadata_df.to_csv(csv_dir / f\"metadata_intersection_threshold_{min_subjects}_ncat{n_overlapping_cats}_{subject_id}.csv\", index=False)\n",
        "        \n",
        "        print(f\"Saved intersection-based RDMs (threshold {min_subjects}, n_categories={n_overlapping_cats}) to {output_dir}\")\n",
        "        print(f\"  CSV files: {csv_dir}\")\n",
        "        print(f\"  NPY files: {npy_dir}\")\n",
        "    \n",
        "    else:\n",
        "        print(f\"No subjects have sufficient intersecting categories for threshold {min_subjects}.\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Completed visualization for all thresholds\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vislearnlabpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
