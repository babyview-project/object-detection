{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Category-wise Subject Embedding Correlations\n",
        "\n",
        "This notebook calculates and compares category-wise embedding correlations between subjects.\n",
        "For each category, it computes the correlation between average category embeddings across different subjects.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This analysis:\n",
        "1. Loads normalized age-month level embeddings from notebook 05 (normalized grouped embeddings)\n",
        "2. Aggregates embeddings per subject across all age_mo for each category (simple average across age bins)\n",
        "3. For each category, computes pairwise correlations between all subject pairs\n",
        "4. Creates correlation matrices showing how similar subjects are in their category representations\n",
        "5. Visualizes results with heatmaps and summary statistics\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Category-wise analysis**: Computes correlations separately for each category\n",
        "- **Subject comparisons**: Compares average category embeddings between all pairs of subjects\n",
        "- **Multiple correlation metrics**: Supports Pearson and Spearman correlations\n",
        "- **Visualization**: Creates heatmaps showing subject-subject correlations for each category\n",
        "- **Summary statistics**: Computes mean correlations per category and per subject pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set matplotlib backend\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "print(\"All imports successful!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Paths\n",
        "# Path to normalized embeddings from notebook 05 (age-month level normalized embeddings)\n",
        "# These are saved in category folders: {normalized_embeddings_dir}/{category}/{subject_id}_{age_mo}_month_level_avg.npy\n",
        "normalized_embeddings_dir = Path(\"/data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\")\n",
        "\n",
        "# Detect embedding type from path\n",
        "normalized_embeddings_dir_str = str(normalized_embeddings_dir).lower()\n",
        "if \"dinov3\" in normalized_embeddings_dir_str or \"dinov\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"dinov3\"\n",
        "elif \"clip\" in normalized_embeddings_dir_str:\n",
        "    embedding_type = \"clip\"\n",
        "else:\n",
        "    embedding_type = \"unknown\"\n",
        "\n",
        "# Create output directory with embedding type in name\n",
        "output_dir = Path(f\"category_wise_subject_correlations_{embedding_type}\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Create subdirectories\n",
        "csv_dir = output_dir / \"csv\"\n",
        "plots_dir = output_dir / \"plots\"\n",
        "csv_dir.mkdir(exist_ok=True, parents=True)\n",
        "plots_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Subject to exclude from analyses\n",
        "excluded_subject = \"00270001\"\n",
        "\n",
        "# Correlation method: 'pearson' or 'spearman'\n",
        "correlation_method = 'pearson'\n",
        "\n",
        "# Minimum number of subjects required per category to compute correlations\n",
        "min_subjects_per_category = 2\n",
        "\n",
        "print(f\"Normalized embeddings directory: {normalized_embeddings_dir}\")\n",
        "print(f\"Detected embedding type: {embedding_type}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"CSV subdirectory: {csv_dir}\")\n",
        "print(f\"Plots subdirectory: {plots_dir}\")\n",
        "print(f\"Excluded subject: {excluded_subject}\")\n",
        "print(f\"Correlation method: {correlation_method}\")\n",
        "print(f\"Min subjects per category: {min_subjects_per_category}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized embeddings directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\n",
            "Detected embedding type: clip\n",
            "Output directory: category_wise_subject_correlations_clip\n",
            "CSV subdirectory: category_wise_subject_correlations_clip/csv\n",
            "Plots subdirectory: category_wise_subject_correlations_clip/plots\n",
            "Excluded subject: 00270001\n",
            "Correlation method: pearson\n",
            "Min subjects per category: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Aggregate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load normalized age-month level embeddings from notebook 05 and aggregate to subject level\n",
        "print(\"Loading normalized age-month level embeddings from notebook 05...\")\n",
        "print(f\"  Source directory: {normalized_embeddings_dir}\")\n",
        "\n",
        "# Get all category folders\n",
        "category_folders = [f for f in normalized_embeddings_dir.iterdir() if f.is_dir()]\n",
        "print(f\"  Found {len(category_folders)} category folders\")\n",
        "\n",
        "# Collect all embeddings by subject and category\n",
        "# Structure: {subject_id: {category: [list of age_mo embeddings]}}\n",
        "subject_category_embeddings = defaultdict(lambda: defaultdict(list))\n",
        "all_categories_set = set()\n",
        "\n",
        "for category_folder in tqdm(category_folders, desc=\"Loading category folders\"):\n",
        "    category = category_folder.name\n",
        "    all_categories_set.add(category)\n",
        "    \n",
        "    # Get all embedding files in this category\n",
        "    embedding_files = list(category_folder.glob(\"*.npy\"))\n",
        "    \n",
        "    for emb_file in embedding_files:\n",
        "        # Parse filename: {subject_id}_{age_mo}_month_level_avg.npy\n",
        "        filename = emb_file.stem  # without .npy\n",
        "        parts = filename.split('_')\n",
        "        \n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "        \n",
        "        # Extract subject_id and age_mo\n",
        "        subject_id = parts[0]\n",
        "        age_mo = int(parts[1]) if parts[1].isdigit() else None\n",
        "        \n",
        "        if age_mo is None:\n",
        "            continue\n",
        "        \n",
        "        # Exclude subject if specified\n",
        "        if excluded_subject and subject_id == excluded_subject:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            embedding = np.load(emb_file)\n",
        "            subject_category_embeddings[subject_id][category].append(embedding)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {emb_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Aggregate embeddings per subject: average across age_mo for each category\n",
        "print(f\"\\nAggregating embeddings per subject (averaging across age_mo)...\")\n",
        "subject_embeddings_normalized = {}\n",
        "\n",
        "for subject_id in tqdm(subject_category_embeddings.keys(), desc=\"Aggregating subjects\"):\n",
        "    subject_embeddings_normalized[subject_id] = {}\n",
        "    \n",
        "    for category, age_mo_embeddings in subject_category_embeddings[subject_id].items():\n",
        "        if len(age_mo_embeddings) > 0:\n",
        "            # Average across all age_mo embeddings for this category\n",
        "            # Stack embeddings and compute mean\n",
        "            stacked = np.array([emb.flatten() for emb in age_mo_embeddings])\n",
        "            avg_embedding = stacked.mean(axis=0)\n",
        "            subject_embeddings_normalized[subject_id][category] = avg_embedding\n",
        "\n",
        "print(f\"\\nLoaded and aggregated normalized embeddings for {len(subject_embeddings_normalized)} subjects\")\n",
        "print(f\"  Total unique categories across all subjects: {len(all_categories_set)}\")\n",
        "\n",
        "# Get list of all subjects\n",
        "all_subjects = sorted(list(subject_embeddings_normalized.keys()))\n",
        "print(f\"  Subjects: {all_subjects}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading normalized age-month level embeddings from notebook 05...\n",
            "  Source directory: /data2/dataset/babyview/868_hours/outputs/yoloe_cdi_embeddings/clip_embeddings_grouped_by_age-mo_normalized\n",
            "  Found 163 category folders\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Loading category folders: 100%|██████████| 163/163 [00:02<00:00, 64.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Aggregating embeddings per subject (averaging across age_mo)...\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Aggregating subjects: 100%|██████████| 31/31 [00:00<00:00, 484.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded and aggregated normalized embeddings for 31 subjects\n",
            "  Total unique categories across all subjects: 163\n",
            "  Subjects: ['00220001', '00230001', '00240001', '00320001', '00320002', '00320003', '00340002', '00350001', '00350002', '00360001', '00370001', '00370002', '00390001', '00400001', '00400002', '00400003', '00420001', '00430001', '00430002', '00440001', '00460001', '00490001', '00500001', '00510001', '00510002', '00550001', '00560001', '00590001', '00680001', '00720001', '00820001']\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Category-wise Subject Correlations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# For each category, compute correlations between all subject pairs\n",
        "print(\"Computing category-wise subject correlations...\")\n",
        "\n",
        "# Store results\n",
        "# Structure: {category: {subject1: {subject2: correlation}}}\n",
        "category_subject_correlations = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "# Also store as matrices for easier visualization\n",
        "category_correlation_matrices = {}\n",
        "\n",
        "# Get all unique categories that have data for at least min_subjects_per_category subjects\n",
        "all_categories = sorted(list(all_categories_set))\n",
        "valid_categories = []\n",
        "\n",
        "for category in tqdm(all_categories, desc=\"Processing categories\"):\n",
        "    # Get all subjects that have this category\n",
        "    subjects_with_category = [\n",
        "        subj for subj in all_subjects \n",
        "        if category in subject_embeddings_normalized[subj]\n",
        "    ]\n",
        "    \n",
        "    if len(subjects_with_category) < min_subjects_per_category:\n",
        "        continue\n",
        "    \n",
        "    valid_categories.append(category)\n",
        "    \n",
        "    # Extract embeddings for this category across all subjects\n",
        "    category_embeddings = {}\n",
        "    for subject_id in subjects_with_category:\n",
        "        category_embeddings[subject_id] = subject_embeddings_normalized[subject_id][category]\n",
        "    \n",
        "    # Compute pairwise correlations\n",
        "    correlation_matrix = np.full((len(all_subjects), len(all_subjects)), np.nan)\n",
        "    \n",
        "    for i, subj1 in enumerate(all_subjects):\n",
        "        for j, subj2 in enumerate(all_subjects):\n",
        "            if subj1 == subj2:\n",
        "                # Self-correlation is 1.0\n",
        "                correlation_matrix[i, j] = 1.0\n",
        "                category_subject_correlations[category][subj1][subj2] = 1.0\n",
        "            elif subj1 in category_embeddings and subj2 in category_embeddings:\n",
        "                # Compute correlation between the two embeddings\n",
        "                emb1 = category_embeddings[subj1]\n",
        "                emb2 = category_embeddings[subj2]\n",
        "                \n",
        "                if correlation_method == 'pearson':\n",
        "                    corr, _ = pearsonr(emb1, emb2)\n",
        "                elif correlation_method == 'spearman':\n",
        "                    corr, _ = spearmanr(emb1, emb2)\n",
        "                else:\n",
        "                    # Fallback to cosine similarity\n",
        "                    corr = cosine_similarity([emb1], [emb2])[0, 0]\n",
        "                \n",
        "                correlation_matrix[i, j] = corr\n",
        "                category_subject_correlations[category][subj1][subj2] = corr\n",
        "    \n",
        "    category_correlation_matrices[category] = correlation_matrix\n",
        "\n",
        "print(f\"\\nComputed correlations for {len(valid_categories)} categories\")\n",
        "print(f\"  Categories with sufficient data: {len(valid_categories)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing category-wise subject correlations...\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Processing categories: 100%|██████████| 163/163 [00:12<00:00, 13.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Computed correlations for 163 categories\n",
            "  Categories with sufficient data: 163\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Summary DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a long-format DataFrame with all correlations\n",
        "print(\"Creating summary DataFrames...\")\n",
        "\n",
        "correlation_records = []\n",
        "for category in valid_categories:\n",
        "    for subj1 in all_subjects:\n",
        "        for subj2 in all_subjects:\n",
        "            if subj1 in category_subject_correlations[category] and \\\n",
        "               subj2 in category_subject_correlations[category][subj1]:\n",
        "                corr = category_subject_correlations[category][subj1][subj2]\n",
        "                correlation_records.append({\n",
        "                    'category': category,\n",
        "                    'subject1': subj1,\n",
        "                    'subject2': subj2,\n",
        "                    'correlation': corr\n",
        "                })\n",
        "\n",
        "correlations_df = pd.DataFrame(correlation_records)\n",
        "print(f\"Created correlations DataFrame with {len(correlations_df)} records\")\n",
        "\n",
        "# Compute summary statistics\n",
        "print(\"\\nComputing summary statistics...\")\n",
        "\n",
        "# Mean correlation per category (excluding self-correlations)\n",
        "category_mean_correlations = []\n",
        "for category in valid_categories:\n",
        "    category_corrs = correlations_df[\n",
        "        (correlations_df['category'] == category) & \n",
        "        (correlations_df['subject1'] != correlations_df['subject2'])\n",
        "    ]['correlation'].values\n",
        "    if len(category_corrs) > 0:\n",
        "        category_mean_correlations.append({\n",
        "            'category': category,\n",
        "            'mean_correlation': np.nanmean(category_corrs),\n",
        "            'std_correlation': np.nanstd(category_corrs),\n",
        "            'min_correlation': np.nanmin(category_corrs),\n",
        "            'max_correlation': np.nanmax(category_corrs),\n",
        "            'n_subject_pairs': len(category_corrs)\n",
        "        })\n",
        "\n",
        "category_summary_df = pd.DataFrame(category_mean_correlations)\n",
        "category_summary_df = category_summary_df.sort_values('mean_correlation', ascending=False)\n",
        "print(f\"Created category summary with {len(category_summary_df)} categories\")\n",
        "\n",
        "# Mean correlation per subject pair (across all categories)\n",
        "subject_pair_mean_correlations = []\n",
        "for subj1, subj2 in combinations(all_subjects, 2):\n",
        "    pair_corrs = correlations_df[\n",
        "        (correlations_df['subject1'] == subj1) & \n",
        "        (correlations_df['subject2'] == subj2)\n",
        "    ]['correlation'].values\n",
        "    if len(pair_corrs) > 0:\n",
        "        subject_pair_mean_correlations.append({\n",
        "            'subject1': subj1,\n",
        "            'subject2': subj2,\n",
        "            'mean_correlation': np.nanmean(pair_corrs),\n",
        "            'std_correlation': np.nanstd(pair_corrs),\n",
        "            'min_correlation': np.nanmin(pair_corrs),\n",
        "            'max_correlation': np.nanmax(pair_corrs),\n",
        "            'n_categories': len(pair_corrs)\n",
        "        })\n",
        "\n",
        "subject_pair_summary_df = pd.DataFrame(subject_pair_mean_correlations)\n",
        "subject_pair_summary_df = subject_pair_summary_df.sort_values('mean_correlation', ascending=False)\n",
        "print(f\"Created subject pair summary with {len(subject_pair_summary_df)} pairs\")\n",
        "\n",
        "# Display top categories by mean correlation\n",
        "print(\"\\nTop 10 categories by mean correlation:\")\n",
        "print(category_summary_df.head(10))\n",
        "\n",
        "# Display top subject pairs by mean correlation\n",
        "print(\"\\nTop 10 subject pairs by mean correlation:\")\n",
        "print(subject_pair_summary_df.head(10))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating summary DataFrames...\n",
            "Created correlations DataFrame with 133531 records\n",
            "\n",
            "Computing summary statistics...\n",
            "Created category summary with 163 categories\n",
            "Created subject pair summary with 465 pairs\n",
            "\n",
            "Top 10 categories by mean correlation:\n",
            "    category  mean_correlation  std_correlation  min_correlation  \\\n",
            "42    crayon          0.942488         0.040843         0.756292   \n",
            "74      hand          0.918849         0.048199         0.681343   \n",
            "58    finger          0.918638         0.063157         0.705552   \n",
            "94      nail          0.906610         0.089136         0.579158   \n",
            "150      toe          0.883368         0.101027         0.510595   \n",
            "19    bottle          0.846871         0.158516         0.156854   \n",
            "160    watch          0.844931         0.098908         0.407526   \n",
            "68   glasses          0.841866         0.091491         0.502670   \n",
            "135  slipper          0.839791         0.089918         0.449792   \n",
            "128    shirt          0.832728         0.075015         0.572636   \n",
            "\n",
            "     max_correlation  n_subject_pairs  \n",
            "42          0.992978              930  \n",
            "74          0.986517              930  \n",
            "58          0.990300              930  \n",
            "94          0.992699              930  \n",
            "150         0.989627              930  \n",
            "19          0.985166              930  \n",
            "160         0.978110              930  \n",
            "68          0.980766              930  \n",
            "135         0.980549              930  \n",
            "128         0.963648              930  \n",
            "\n",
            "Top 10 subject pairs by mean correlation:\n",
            "     subject1  subject2  mean_correlation  std_correlation  min_correlation  \\\n",
            "328  00400001  00820001          0.799137         0.174387         0.032701   \n",
            "320  00400001  00500001          0.797480         0.168940         0.007188   \n",
            "113  00320001  00820001          0.789728         0.166095         0.097722   \n",
            "436  00500001  00820001          0.787308         0.176254         0.018029   \n",
            "293  00370002  00820001          0.786715         0.173154        -0.102202   \n",
            "344  00400002  00820001          0.784314         0.184375         0.011432   \n",
            "139  00320002  00820001          0.782730         0.182124         0.112151   \n",
            "277  00370002  00400002          0.781267         0.179248        -0.072175   \n",
            "276  00370002  00400001          0.769426         0.192182        -0.119415   \n",
            "120  00320002  00370002          0.769027         0.184902        -0.002274   \n",
            "\n",
            "     max_correlation  n_categories  \n",
            "328         0.992664           159  \n",
            "320         0.991678           160  \n",
            "113         0.988816           159  \n",
            "436         0.989233           159  \n",
            "293         0.991316           158  \n",
            "344         0.992699           157  \n",
            "139         0.992978           156  \n",
            "277         0.991749           159  \n",
            "276         0.990520           160  \n",
            "120         0.987250           156  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Correlation Matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create heatmaps for correlation matrices\n",
        "print(\"Creating correlation heatmaps...\")\n",
        "\n",
        "# Set up plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 10)\n",
        "\n",
        "# Create heatmaps for top categories (by mean correlation)\n",
        "n_top_categories = min(20, len(category_summary_df))\n",
        "top_categories = category_summary_df.head(n_top_categories)['category'].tolist()\n",
        "\n",
        "for category in tqdm(top_categories, desc=\"Creating heatmaps\"):\n",
        "    corr_matrix = category_correlation_matrices[category]\n",
        "    \n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "    \n",
        "    # Create heatmap\n",
        "    mask = np.isnan(corr_matrix)\n",
        "    sns.heatmap(\n",
        "        corr_matrix,\n",
        "        xticklabels=all_subjects,\n",
        "        yticklabels=all_subjects,\n",
        "        annot=False,\n",
        "        cmap='coolwarm',\n",
        "        center=0,\n",
        "        vmin=-1,\n",
        "        vmax=1,\n",
        "        square=True,\n",
        "        mask=mask,\n",
        "        cbar_kws={'label': f'{correlation_method.capitalize()} Correlation'},\n",
        "        ax=ax\n",
        "    )\n",
        "    \n",
        "    ax.set_title(f'Subject Correlations: {category}\\n(Mean: {category_summary_df[category_summary_df[\"category\"]==category][\"mean_correlation\"].values[0]:.3f})',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Subject', fontsize=12)\n",
        "    ax.set_ylabel('Subject', fontsize=12)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    safe_category_name = category.replace('/', '_').replace(' ', '_')\n",
        "    plt.savefig(plots_dir / f'correlation_heatmap_{safe_category_name}.png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "print(f\"Created {len(top_categories)} heatmaps for top categories\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating correlation heatmaps...\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Creating heatmaps: 100%|██████████| 20/20 [00:07<00:00,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Created 20 heatmaps for top categories\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Summary Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comprehensive Category Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create comprehensive visualizations showing all categories\n",
        "print(\"Creating comprehensive category visualizations...\")\n",
        "\n",
        "# 1. All categories sorted bar plot (full view)\n",
        "fig, ax = plt.subplots(figsize=(14, max(20, len(category_summary_df) * 0.3)))\n",
        "sorted_cats = category_summary_df.sort_values('mean_correlation', ascending=True)\n",
        "colors = ['coral' if corr < category_summary_df['mean_correlation'].median() else 'steelblue' \n",
        "          for corr in sorted_cats['mean_correlation']]\n",
        "ax.barh(range(len(sorted_cats)), sorted_cats['mean_correlation'], edgecolor='black', color=colors)\n",
        "ax.set_yticks(range(len(sorted_cats)))\n",
        "ax.set_yticklabels(sorted_cats['category'], fontsize=6)\n",
        "ax.set_xlabel('Mean Correlation (across subject pairs)', fontsize=12)\n",
        "ax.set_title('All Categories Sorted by Mean Correlation', fontsize=14, fontweight='bold')\n",
        "ax.axvline(category_summary_df['mean_correlation'].median(), color='red', \n",
        "           linestyle='--', linewidth=2, label=f'Median: {category_summary_df[\"mean_correlation\"].median():.3f}')\n",
        "ax.axvline(category_summary_df['mean_correlation'].mean(), color='orange', \n",
        "           linestyle='--', linewidth=2, label=f'Mean: {category_summary_df[\"mean_correlation\"].mean():.3f}')\n",
        "ax.legend()\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'all_categories_sorted_by_correlation.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 2. Heatmap showing all categories with their correlation statistics\n",
        "print(\"Creating category statistics heatmap...\")\n",
        "category_stats_matrix = category_summary_df[['mean_correlation', 'std_correlation', \n",
        "                                              'min_correlation', 'max_correlation']].values\n",
        "category_stats_df = pd.DataFrame(\n",
        "    category_stats_matrix,\n",
        "    index=category_summary_df['category'],\n",
        "    columns=['Mean', 'Std', 'Min', 'Max']\n",
        ")\n",
        "category_stats_df = category_stats_df.sort_values('Mean', ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(max(20, len(category_stats_df) * 0.3), 6))\n",
        "sns.heatmap(\n",
        "    category_stats_df.T,\n",
        "    annot=False,\n",
        "    cmap='RdYlBu_r',\n",
        "    center=category_summary_df['mean_correlation'].mean(),\n",
        "    cbar_kws={'label': 'Correlation Value'},\n",
        "    ax=ax,\n",
        "    yticklabels=['Mean Correlation', 'Std Dev', 'Min', 'Max'],\n",
        "    xticklabels=False  # Don't show all labels initially\n",
        ")\n",
        "ax.set_xlabel('Category', fontsize=10)\n",
        "ax.set_ylabel('Statistic', fontsize=12)\n",
        "ax.set_title('All Categories: Correlation Statistics\\n(Sorted by Mean Correlation)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "\n",
        "# Set x-axis ticks to show every nth category to avoid overcrowding\n",
        "n_categories = len(category_stats_df)\n",
        "if n_categories > 50:\n",
        "    # Show every 5th category label\n",
        "    step = max(1, n_categories // 50)\n",
        "    tick_positions = list(range(0, n_categories, step))\n",
        "    tick_labels = [category_stats_df.index[i] for i in tick_positions]\n",
        "    ax.set_xticks(tick_positions)\n",
        "    ax.set_xticklabels(tick_labels, rotation=90, fontsize=6, ha='right')\n",
        "else:\n",
        "    # Show all labels if not too many\n",
        "    ax.set_xticks(range(n_categories))\n",
        "    ax.set_xticklabels(category_stats_df.index, rotation=90, fontsize=6, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'all_categories_statistics_heatmap.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 3. Heatmap showing categories vs subject pairs (sample for visualization)\n",
        "# This could be very large, so we'll create a version with top/bottom categories\n",
        "print(\"Creating category vs subject pair heatmap (top and bottom categories)...\")\n",
        "n_sample_cats = 40  # Show top 20 and bottom 20\n",
        "top_sample = category_summary_df.head(n_sample_cats // 2)\n",
        "bottom_sample = category_summary_df.tail(n_sample_cats // 2)\n",
        "sample_categories = pd.concat([top_sample, bottom_sample])\n",
        "\n",
        "# Create a matrix: categories (rows) x subject pairs (columns)\n",
        "# Sample subject pairs for visualization (top correlated pairs)\n",
        "n_sample_pairs = min(30, len(subject_pair_summary_df))\n",
        "sample_pairs = subject_pair_summary_df.head(n_sample_pairs)\n",
        "\n",
        "category_pair_matrix = np.zeros((len(sample_categories), len(sample_pairs)))\n",
        "for i, (_, cat_row) in enumerate(sample_categories.iterrows()):\n",
        "    category = cat_row['category']\n",
        "    for j, (_, pair_row) in enumerate(sample_pairs.iterrows()):\n",
        "        subj1 = pair_row['subject1']\n",
        "        subj2 = pair_row['subject2']\n",
        "        # Get correlation for this category and subject pair\n",
        "        corr_data = correlations_df[\n",
        "            (correlations_df['category'] == category) &\n",
        "            (correlations_df['subject1'] == subj1) &\n",
        "            (correlations_df['subject2'] == subj2)\n",
        "        ]\n",
        "        if len(corr_data) > 0:\n",
        "            category_pair_matrix[i, j] = corr_data['correlation'].values[0]\n",
        "        else:\n",
        "            category_pair_matrix[i, j] = np.nan\n",
        "\n",
        "# Create heatmap\n",
        "pair_labels = [f\"{row['subject1']}-{row['subject2']}\" for _, row in sample_pairs.iterrows()]\n",
        "fig, ax = plt.subplots(figsize=(max(16, len(sample_pairs) * 0.5), max(12, len(sample_categories) * 0.3)))\n",
        "mask = np.isnan(category_pair_matrix)\n",
        "sns.heatmap(\n",
        "    category_pair_matrix,\n",
        "    xticklabels=False,  # Set to False initially, then set manually below\n",
        "    yticklabels=False,  # Set to False initially, then set manually below\n",
        "    annot=False,\n",
        "    cmap='coolwarm',\n",
        "    center=0,\n",
        "    vmin=-1,\n",
        "    vmax=1,\n",
        "    square=False,\n",
        "    mask=mask,\n",
        "    cbar_kws={'label': f'{correlation_method.capitalize()} Correlation'},\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_xlabel('Subject Pairs', fontsize=10)\n",
        "ax.set_ylabel('Category', fontsize=10)\n",
        "ax.set_title(f'Category Correlations: Top {n_sample_cats//2} & Bottom {n_sample_cats//2} Categories\\nvs Top {n_sample_pairs} Subject Pairs', \n",
        "             fontsize=12, fontweight='bold')\n",
        "\n",
        "# Set tick positions and labels manually\n",
        "ax.set_xticks(range(len(pair_labels)))\n",
        "ax.set_xticklabels(pair_labels, rotation=90, fontsize=6, ha='right')\n",
        "ax.set_yticks(range(len(sample_categories)))\n",
        "ax.set_yticklabels(sample_categories['category'].values, fontsize=7)\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'category_vs_subject_pair_heatmap.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 4. Violin plot showing distribution of correlations per category (sample)\n",
        "print(\"Creating correlation distribution violin plot...\")\n",
        "# Sample categories for violin plot (too many would be unreadable)\n",
        "n_violin_cats = min(30, len(category_summary_df))\n",
        "sample_cats_violin = category_summary_df.head(n_violin_cats // 2).append(\n",
        "    category_summary_df.tail(n_violin_cats // 2)\n",
        ")\n",
        "\n",
        "violin_data = []\n",
        "for _, cat_row in sample_cats_violin.iterrows():\n",
        "    category = cat_row['category']\n",
        "    cat_corrs = correlations_df[\n",
        "        (correlations_df['category'] == category) &\n",
        "        (correlations_df['subject1'] != correlations_df['subject2'])\n",
        "    ]['correlation'].values\n",
        "    for corr in cat_corrs:\n",
        "        violin_data.append({'category': category, 'correlation': corr})\n",
        "\n",
        "violin_df = pd.DataFrame(violin_data)\n",
        "violin_df = violin_df.sort_values('correlation', ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "sns.violinplot(data=violin_df, x='category', y='correlation', ax=ax, inner='box')\n",
        "ax.set_xlabel('Category', fontsize=10)\n",
        "ax.set_ylabel('Correlation', fontsize=12)\n",
        "ax.set_title(f'Distribution of Correlations: Top {n_violin_cats//2} & Bottom {n_violin_cats//2} Categories', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=7, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'correlation_distribution_violin_plot.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(\"Comprehensive visualizations created!\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating comprehensive category visualizations...\n",
            "Creating category statistics heatmap...\n",
            "Creating category vs subject pair heatmap (top and bottom categories)...\n"
          ]
        },
        {
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create summary visualizations\n",
        "print(\"Creating summary visualizations...\")\n",
        "\n",
        "# 1. Distribution of mean correlations per category\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.hist(category_summary_df['mean_correlation'], bins=30, edgecolor='black', alpha=0.7)\n",
        "ax.set_xlabel('Mean Correlation (across subject pairs)', fontsize=12)\n",
        "ax.set_ylabel('Number of Categories', fontsize=12)\n",
        "ax.set_title('Distribution of Mean Category Correlations', fontsize=14, fontweight='bold')\n",
        "ax.axvline(category_summary_df['mean_correlation'].mean(), color='red', \n",
        "           linestyle='--', linewidth=2, label=f'Mean: {category_summary_df[\"mean_correlation\"].mean():.3f}')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'distribution_mean_category_correlations.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 2. Distribution of mean correlations per subject pair\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.hist(subject_pair_summary_df['mean_correlation'], bins=30, edgecolor='black', alpha=0.7)\n",
        "ax.set_xlabel('Mean Correlation (across categories)', fontsize=12)\n",
        "ax.set_ylabel('Number of Subject Pairs', fontsize=12)\n",
        "ax.set_title('Distribution of Mean Subject Pair Correlations', fontsize=14, fontweight='bold')\n",
        "ax.axvline(subject_pair_summary_df['mean_correlation'].mean(), color='red', \n",
        "           linestyle='--', linewidth=2, label=f'Mean: {subject_pair_summary_df[\"mean_correlation\"].mean():.3f}')\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'distribution_mean_subject_pair_correlations.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 3. Top categories bar plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "top_n = min(30, len(category_summary_df))\n",
        "top_cats = category_summary_df.head(top_n)\n",
        "ax.barh(range(len(top_cats)), top_cats['mean_correlation'], edgecolor='black')\n",
        "ax.set_yticks(range(len(top_cats)))\n",
        "ax.set_yticklabels(top_cats['category'], fontsize=8)\n",
        "ax.set_xlabel('Mean Correlation', fontsize=12)\n",
        "ax.set_title(f'Top {top_n} Categories by Mean Correlation', fontsize=14, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'top_categories_by_correlation.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 3b. Bottom categories bar plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "bottom_n = min(30, len(category_summary_df))\n",
        "bottom_cats = category_summary_df.tail(bottom_n)\n",
        "ax.barh(range(len(bottom_cats)), bottom_cats['mean_correlation'], edgecolor='black', color='coral')\n",
        "ax.set_yticks(range(len(bottom_cats)))\n",
        "ax.set_yticklabels(bottom_cats['category'], fontsize=8)\n",
        "ax.set_xlabel('Mean Correlation', fontsize=12)\n",
        "ax.set_title(f'Bottom {bottom_n} Categories by Mean Correlation', fontsize=14, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'bottom_categories_by_correlation.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 4. Overall correlation matrix (average across all categories)\n",
        "print(\"Creating overall average correlation matrix...\")\n",
        "overall_corr_matrix = np.zeros((len(all_subjects), len(all_subjects)))\n",
        "overall_corr_matrix[:] = np.nan\n",
        "\n",
        "for i, subj1 in enumerate(all_subjects):\n",
        "    for j, subj2 in enumerate(all_subjects):\n",
        "        if subj1 == subj2:\n",
        "            overall_corr_matrix[i, j] = 1.0\n",
        "        else:\n",
        "            # Get all correlations for this pair across all categories\n",
        "            pair_corrs = correlations_df[\n",
        "                (correlations_df['subject1'] == subj1) & \n",
        "                (correlations_df['subject2'] == subj2)\n",
        "            ]['correlation'].values\n",
        "            if len(pair_corrs) > 0:\n",
        "                overall_corr_matrix[i, j] = np.nanmean(pair_corrs)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "mask = np.isnan(overall_corr_matrix)\n",
        "sns.heatmap(\n",
        "    overall_corr_matrix,\n",
        "    xticklabels=all_subjects,\n",
        "    yticklabels=all_subjects,\n",
        "    annot=True,\n",
        "    fmt='.3f',\n",
        "    cmap='coolwarm',\n",
        "    center=0,\n",
        "    vmin=-1,\n",
        "    vmax=1,\n",
        "    square=True,\n",
        "    mask=mask,\n",
        "    cbar_kws={'label': f'Mean {correlation_method.capitalize()} Correlation (across categories)'},\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_title('Overall Subject Correlation Matrix\\n(Averaged across all categories)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Subject', fontsize=12)\n",
        "ax.set_ylabel('Subject', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / 'overall_subject_correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(\"Summary visualizations created!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating summary visualizations...\n",
            "Creating overall average correlation matrix...\n",
            "Summary visualizations created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save all results to CSV files\n",
        "print(\"Saving results to CSV files...\")\n",
        "\n",
        "# Save full correlations DataFrame\n",
        "correlations_df.to_csv(csv_dir / 'all_category_subject_correlations.csv', index=False)\n",
        "print(f\"Saved full correlations to: {csv_dir / 'all_category_subject_correlations.csv'}\")\n",
        "\n",
        "# Save category summary\n",
        "category_summary_df.to_csv(csv_dir / 'category_summary_statistics.csv', index=False)\n",
        "print(f\"Saved category summary to: {csv_dir / 'category_summary_statistics.csv'}\")\n",
        "\n",
        "# Save subject pair summary\n",
        "subject_pair_summary_df.to_csv(csv_dir / 'subject_pair_summary_statistics.csv', index=False)\n",
        "print(f\"Saved subject pair summary to: {csv_dir / 'subject_pair_summary_statistics.csv'}\")\n",
        "\n",
        "# Save overall correlation matrix\n",
        "overall_corr_df = pd.DataFrame(\n",
        "    overall_corr_matrix,\n",
        "    index=all_subjects,\n",
        "    columns=all_subjects\n",
        ")\n",
        "overall_corr_df.to_csv(csv_dir / 'overall_subject_correlation_matrix.csv')\n",
        "print(f\"Saved overall correlation matrix to: {csv_dir / 'overall_subject_correlation_matrix.csv'}\")\n",
        "\n",
        "print(\"\\nAll results saved successfully!\")\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total categories analyzed: {len(valid_categories)}\")\n",
        "print(f\"  Total subjects: {len(all_subjects)}\")\n",
        "print(f\"  Total subject pairs: {len(subject_pair_summary_df)}\")\n",
        "print(f\"  Mean correlation across all categories: {category_summary_df['mean_correlation'].mean():.4f}\")\n",
        "print(f\"  Mean correlation across all subject pairs: {subject_pair_summary_df['mean_correlation'].mean():.4f}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving results to CSV files...\n",
            "Saved full correlations to: category_wise_subject_correlations_clip/csv/all_category_subject_correlations.csv\n",
            "Saved category summary to: category_wise_subject_correlations_clip/csv/category_summary_statistics.csv\n",
            "Saved subject pair summary to: category_wise_subject_correlations_clip/csv/subject_pair_summary_statistics.csv\n",
            "Saved overall correlation matrix to: category_wise_subject_correlations_clip/csv/overall_subject_correlation_matrix.csv\n",
            "\n",
            "All results saved successfully!\n",
            "\n",
            "Summary:\n",
            "  Total categories analyzed: 163\n",
            "  Total subjects: 31\n",
            "  Total subject pairs: 465\n",
            "  Mean correlation across all categories: 0.6012\n",
            "  Mean correlation across all subject pairs: 0.6208\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vislearnlabpy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}